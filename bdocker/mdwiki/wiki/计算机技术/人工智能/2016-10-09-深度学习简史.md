---
layout: post
title: 深度学习简史
lead: 人工智能革命：为什么深度学习会突然改变你的生活？
date: 2016-10-09T00:00:00.000Z
categories: 人工智能
tagline: 机器学习
tags:
  - 机器学习
  - 神经网络
  - 深度学习
  - 人工智能
---

# 深度学习

[深度学习](http://baike.baidu.com/view/9964678.htm)的概念源于[人工神经网络](http://baike.baidu.com/view/19743.htm)的研究。含多隐层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。

深度学习的概念由Hinton等人于2006年提出。基于深度置信网络(DBN)提出非监督贪心逐层训练算法，为解决深层结构相关的优化难题带来希望，随后提出多层自动编码器深层结构。此外Lecun等人提出的卷积神经网络是第一个真正多层结构学习算法，它利用空间相对关系减少参数数目以提高训练性能。

深度学习是机器学习研究中的一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本。

同[机器学习](http://baike.baidu.com/view/7956.htm)方法一样，深度机器学习方法也有监督学习与无监督学习之分．不同的学习框架下建立的学习模型很是不同．例如，[卷积神经网络](http://baike.baidu.com/item/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)（Convolutional neural networks，简称CNNs）就是一种深度的监督学习下的机器学习模型，而深度置信网（Deep Belief Nets，简称DBNs）就是一种无监督学习下的机器学习模型。

## 基础概念

### 深度

从一个输入中产生一个输出所涉及的计算可以通过一个[流向图](http://baike.baidu.com/item/%E6%B5%81%E5%90%91%E5%9B%BE)(flow graph)来表示：流向图是一种能够表示计算的图，在这种图中每一个节点表示一个基本的计算以及一个计算的值，计算的结果被应用到这个节点的子节点的值。考虑这样一个计算集合，它可以被允许在每一个节点和可能的图结构中，并定义了一个函数族。输入节点没有父节点，输出节点没有子节点。

这种流向图的一个特别属性是[深度](http://baike.baidu.com/subview/549611/8063251.htm)(depth)：从一个输入到一个输出的最长路径的长度。

传统的[前馈神经网络](http://baike.baidu.com/view/1986922.htm)能够被看做拥有等于层数的深度(比如对于输出层为隐层数加1)。SVMs有深度2(一个对应于核输出或者特征空间，另一个对应于所产生输出的线性混合)。

人工智能研究的方向之一，是以所谓 "专家系统" 为代表的，用大量 "如果-就" (If - Then) 规则定义的，自上而下的思路。[人工神经网络](http://baike.baidu.com/view/19743.htm) ( Artifical Neural Network)，标志着另外一种自下而上的思路。神经网络没有一个严格的正式定义。它的基本特点，是试图模仿大脑的神经元之间传递，处理信息的模式。

### 解决问题

需要使用深度学习解决的问题有以下的特征：

- 深度不足会出现问题。
- 人脑具有一个深度结构。
- 认知过程逐层进行，逐步抽象。

#### 深度不足会出现问题

在许多情形中深度2就足够表示任何一个带有给定目标精度的函数。但是其代价是：图中所需要的节点数(比如计算和参数数量)可能变的非常大。理论结果证实那些事实上所需要的节点数随着输入的大小指数增长的函数族是存在的。

我们可以将深度架构看做一种因子分解。大部分随机选择的函数不能被有效地表示，无论是用深的或者浅的架构。但是许多能够有效地被深度架构表示的却不能被用浅的架构高效表示。一个紧的和深度的表示的存在意味着在潜在的可被表示的函数中存在某种结构。如果不存在任何结构，那将不可能很好地泛化。

#### 大脑有一个深度架构

例如，视觉皮质得到了很好的研究，并显示出一系列的区域，在每一个这种区域中包含一个输入的表示和从一个到另一个的信号流(这里忽略了在一些层次并行路径上的关联，因此更复杂)。这个特征层次的每一层表示在一个不同的抽象层上的输入，并在层次的更上层有着更多的抽象特征，他们根据低层特征定义。

需要注意的是大脑中的表示是在中间紧密分布并且纯局部：他们是稀疏的：1%的[神经元](http://baike.baidu.com/subview/36428/13236988.htm)是同时活动的。给定大量的神经元，仍然有一个非常高效地(指数级高效)表示。

#### 认知过程逐层进行，逐步抽象

人类层次化地组织思想和概念；

人类首先学习简单的概念，然后用他们去表示更抽象的；

工程师将任务分解成多个抽象层次去处理；

学习/发现这些概念(知识工程由于没有反省而失败？)是很美好的。对语言可表达的概念的反省也建议我们一个稀疏的表示：仅所有可能单词/概念中的一个小的部分是可被应用到一个特别的输入(一个视觉场景)。

## 核心思想

把学习结构看作一个网络，则深度学习的核心思路如下：

1. [无监督学习](http://baike.baidu.com/view/3552442.htm)用于每一层网络的pre-train；
2. 每次用无监督学习只训练一层，将其训练结果作为其高一层的输入；
3. 用自顶而下的监督算法去调整所有层

## 成功应用

### 计算机视觉

- **ImageNet Classification with Deep Convolutional Neural Networks**, Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, NIPS 2012.
- **Learning Hierarchical Features for Scene Labeling**, Clement Farabet, Camille Couprie, Laurent Najman and Yann LeCun, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013.
- **Learning Convolutional Feature Hierarchies for Visual Recognition**, Koray Kavukcuoglu, Pierre Sermanet, Y-Lan Boureau, Karol Gregor, Michaël Mathieu and Yann LeCun, Advances in Neural Information Processing Systems (NIPS 2010), 23, 2010.

### 语音识别

微软研究人员通过与hinton合作，首先将RBM和DBN引入到语音识别声学模型训练中，并且在大词汇量语音识别系统中获得巨大成功，使得语音识别的错误率相对减低30%。但是，DNN还没有有效的并行快速算法，很多研究机构都是在利用大规模数据语料通过GPU平台提高DNN声学模型的训练效率。

在国际上，IBM、google等公司都快速进行了DNN语音识别的研究，并且速度飞快。

国内方面，[阿里巴巴](http://baike.baidu.com/subview/2296/4818544.htm)，科大讯飞、百度、中科院自动化所等公司或研究单位，也在进行深度学习在语音识别上的研究。

### 自然语言处理等其他领域

很多机构在开展研究，2013年Tomas Mikolov,Kai Chen,Greg Corrado,Jeffrey Dean发表论文Efficient Estimation of Word Representations in Vector Space建立word2vector模型，与传统的词袋模型（bag of words）相比，word2vector能够更好地表达语法信息。深度学习在自然语言处理等领域主要应用于机器翻译以及语义挖掘等方面。

# 深度学习简史

编者按：过去4年，大家无疑已经注意到大范围的日常技术在质量方面已经取得了巨大突破。这背后基本上都有深度学习的影子。到底什么是深度学习？深度学习是如何发展到今天的？这一路上它都经历了哪些关键时刻？Roger Parloff的这篇[深度学习简史](http://fortune.com/ai-artificial-intelligence-deep-machine-learning/)可以让我们全面了解。

过去4年，读者无疑已经注意到大范围的日常技术在质量方面已经取得了巨大突破。

其中最明显就是我们智能手机上的语音识别，它的功能已经比过去好得多了。当我们用语音命令打电话给配偶时已经能联系上对方了。因为接线的不是美国铁路局或者一头愤怒的公牛。

实际上，我们现在越来越只需跟计算机讲话就能实现互动，对方也许是Amazon的Alexa，苹果的Siri，微软的Cortana或者Google的众多语音响应功能。百度称，过去18个月其客户语音接口的使用量已经增至原来的3倍。

机器翻译等其他形式的语言处理也变得更加令人信服，Google、微软、Facebook和百度每月都会get√新的技能。Google翻译现在为32个语言对提供语音翻译，为103种语言提供文本翻译，其中不乏宿务语、伊博语、祖鲁语等略微生僻的语言。Google的收件箱现在已经为所有来信准备了3种回复。

然后还有图像识别方面的进展。上述4家公司都有无需识别标签即可让你搜索或者自动组织相片集的功能。你可以要求把有狗、有雪的照片都显示出来，甚至连拥抱这样相当抽象的概念也难不倒它。这些公司还都在做类似的产品原型，可以在数秒钟之内生成句子长度的照片描述。

想想吧。要想收集有狗的照片，app必须识别很多种狗，从吉娃娃到德国牧羊犬，而且无论照片是倒置还是部分模糊，无论是在左边还是右边，不管是大雾还是下雪，是阳光普照还是在林荫底下，app都不应该识别不出小狗。与此同时还得排除掉狼和猫等。光靠像素的话这怎么可能做到呢？

[![img](https://fortunedotcom.files.wordpress.com/2016/09/lrn-10-01-16-neural-networks-e1474990995824.png)](https://fortunedotcom.files.wordpress.com/2016/09/lrn-10-01-16-neural-networks-e1474990995824.png)

> 人工神经网络如何识别照片中的小狗。

> 1. 训练阶段：提供大量带标签的各种动物图像给神经网络，让其学会进行分类；
> 2. 输入层：提供一张不带标签的图片给经过训练的神经网络；
> 3. 底层：神经元对不同的简单形状如边缘进行响应；
> 4. 中间层：神经元对更复杂的结构进行响应；
> 5. 顶层：神经元对我们会识别为不同动物的高度复杂、抽象的概念进行响应；
> 6. 输出层：神经网络根据训练结果给出最接近的识别结果。

图像识别的进展远不仅限于那些看起来很酷的社交app上。医疗初创企业宣布它们很快就可以用计算机来读X光片、MRI（核磁共振图像）以及CT扫描，而且跟放射科医生相比，它们不仅速度更快结果还更加精确，可以更早创伤更少地诊断癌症，并且加速拯救生命的药物的寻找工作。更好的图像识别对于机器人学、无人机以及无人车（福特、Tesla、Uber、百度、Google等都在路测自己的无人车原型）等方面的技术改进至关重要。

但大多数没有意识到的是，**所有这些突破在本质上其实都是同一个突破**。它们都是靠一组热门人工智能技术取得的，这种技术的名字叫做深度学习，但大多数科学家更愿意用它最初的学术名称：==深度神经网络==。

神经网络最引人瞩目的点是计算机并没有经过任何的人工编程即可实现上述功能。当然，实际上也没有人能够通过编程来实现那些功能。程序员只是给计算机提供了一种学习算法，让它观察上TB的数据----也就是训练计算机，让它自行找出如何识别所需对象、单词或者句子的办法。

简而言之，现在这些计算机可以自学了。Nvidia CEO 黄仁勋说："==基本上这相当于写软件的软件==。" Nvidia是图形处理器的市场领导，在5年前开始大规模押注于深度学习。

神经网络并不是什么新事物。这一概念最早可以追溯到1950年代，而许多的关键算法突破试着1980年代和1990年代才取得的。变的是现在的计算机科学家终于**有了海量的计算能力，以及庞大的数据仓库**----互联网上充斥着各种图像、视频、音频以及文本文件----结果表明，这些东西对于跑好神经网络必不可少。VC机构A16Z的合伙人Frank Chen说："这就是**深度学习的寒武纪大爆发**。"他用大部分较为高等的动物突然出现的地质时代来类比深度学习取得的进展。

**这一飞速发展激发了一系列活动爆发**。据CB Insughts的数据，上季度对AI初创企业的股权融资达到了10亿美元的历史新高。2016年Q2共进行了121轮相关初创企业融资，相比之下2011年同期只有21起。在此期间，AI方面的投资超过了75亿美元----其中超过601亿美元是2014年以来进行的。（9月末，AI的5大巨头----Amazon、Faebook、Google、IBM以及微软成立了[非盈利的AI组织](http://36kr.com/p/5053809.html)，旨在推动公众对该话题的理解，并就相关的道德和最佳实践开展研究）

2012年时Google开展的深度学习项目只有2个。据一位发言人表示，现在它正在推进的相关项目已超过1000个，涵括了包括搜索、Android、Gmail、翻译、地图、YouTube以及无人车在内的所有主流产品范畴。IBM的Watson也应用AI，但它2011年击败两位Jeopardy智力竞赛人类冠军时用的不是深度学习。不过据Watson CTO Rob High说，现在Watson几乎所有30项服务都已经增加了深度学习能力。

5年前几乎还不知道深度学习是什么的VC，现在个个对没有这项技能的初创企业都非常谨慎。Chen观察到："我们已经处在这样一个时代，即开发复杂软件应用已经成为必须。"他说大家很快就会需要软件这样："'**你的自然语言处理版（软件）在哪里**？''==我怎么才能跟你的app对话==？**因为我不想通过菜单点击**。'"

一些公司已经在把深度学习集成进自己的日常流程当中。微软研究院负责人Peter Lee说："我们的销售团队正在利用神经网络推荐该联络哪一位潜在客户，或者作出什么样的产品推荐。"

**硬件界已经感受到这种震动**。让所有这一切成为可能的计算能力发展不仅仅是得益于摩尔定律的延续，而且还有2000年代末Nvidia做出图形处理器的帮忙----这种强大的芯片原本是为了给玩家提供丰富的3D视觉体验----但大家意外发现，在深度学习计算方面，其效率要比传统CPU高出20到50倍。今年8月，Nvidia宣布其数据中心业务的季度收入与去年同比已经翻了一番多，达1.51亿美元。其CFO告诉投资者"**目前为止绝大部分增长来自于深度学习**。"在时长83分钟的电话会当中，"深度学习"这个词就出现了81次。

芯片巨头英特尔也没有闲着。过去2个月它一口气（以超过4亿美元）收购了Nervana Systems和Movidius（价格未披露），这两家公司的技术都是**针对不同阶段的深度学习计算量身定制的**。

至于Google，今年5月，它披露了自己已经秘密采用自行设计的定制芯片TPU（Tensor Processing Unit）一年多了，这种芯片正是给经深度学习训练的应用使用的。（Tensor是类似矩阵一样的数组，在深度计算中往往要进行相乘运算）

的确，**企业可能已经到达了另一个拐点**。百度首席科学家吴恩达说："**在过去，许多标普500强CEO希望自己能早点意识到互联网战略的重要性。我想从现在开始的今后5年也会有一些标普500强CEO后悔没有早点思考自己的AI战略**。"

其实在吴恩达看来，互联网这个比喻已经不足以形容AI及深度学习的隐含意义。他说："**AI就是新的电力**。仅仅100年前电力变革了一个又一个行业，现在AI也会做同样的事情。"

可以把深度学习视为一个子集的子集。"人工智能"涵括的技术范围很广----比如传统的逻辑学、基于规则的系统----这些能帮助计算机和机器人至少用类似思考的方式解决问题。在这个领域里面还有一个更小一点的类别叫做机器学习，这是一整个神秘但又重要的数学技术工具箱的总称，它可以帮助机器改进需要经验的任务表现。最后，在机器学习这个门类当中还有一个更小的子集叫做深度学习。

吴恩达说，我们可以把深度学习看做是"从A到B的映射。你可以输入一段音频剪辑然后输出脚本。这就是语音识别。"他强调，只要你有可以训练软件的数据，就有无限可能："你可以输入电子邮件，而输出可以是：这是否垃圾邮件吗？"输入贷款申请，输出可能是目标客户偿还贷款的可能性。输入车队的使用模式，输出可以是发车去到哪里的建议。

> # 人工智能术语表

> ## 人工智能

> AI是个广义概念，用于任何让计算机模仿人类智能、利用逻辑、假定规则、决策树以及机器学习（含深度学习）的技术

> ### **机器学习**

> 含有深奥的统计技术的AI子集。这种统计技术可让机器改进需要经验的任务。深度学习属于机器学习。

> #### **深度学习**

> 机器学习子集包括了让软件可以训练自己执行任务（如云和图像识别）的算法，手段是让多层神经网络接受海量数据。

在这样的愿景下，深度学习几乎可以变革任何行业。Google Brain项目负责人Jeff Dean说："**将会发生的根本性改变是现在计算机视觉真正可以工作了**。"或者用他的话说："==现在计算机已经睁开了它们的眼睛==。"

这是否意味着是时候拥抱"奇点"了呢？（所谓奇点是指这样的一个假设时刻，到那时超智机器将可以在无需人类干预的情况下自我改进，从而引发一个逃逸周期，导致进化缓慢的人类被抛开得越来越远，产生恐怖的后果）

还没有。**神经网络擅长模式识别----有时候表现得跟我们人类一样好甚至更佳**。==但它们不懂推理==。

即将发生的革命的第一个火花是在2009年开始闪烁的。那年夏天，微软研究院邀请了神经网络先驱，多伦多大学的Geoffrey Hinton前往参观。由于对他的研究感到印象深刻，Lee的团队开始试验用神经网络进行语音识别。Lee说："我们被结果惊到了。我们用非常早期的原型就实现了精确度提高30%。"

据Lee说，2011年，微软把深度学习技术引入到自己的商用语音识别产品上。2012年，Google开始跟进。

但是真正的转折点发生了2012年10月。在意大利佛罗伦萨的一场研讨会上，斯坦福AI实验室负责人，著名的计算机视觉竞赛ImageNet创始人李飞飞宣布，Hinton的两位学生已经发明了一种软件，这种软件识别对象的精确率几乎是最接近对手的2倍。Hinton认为"**这是一个非常惊人的结果，令此前许多对此表示质疑的人都信服了**。"（去年的竞赛上一家深度学习的参赛选手已经超越了人的识别率。）

攻破图像识别打响第一枪，这激起了一场人才争夺战。Google把Hinton和赢得那场竞赛的两名学生都请了过来。Facebook签下了法国的深度学习创新者Yann LeCun，他在1980年代和1990年代是赢得ImageNet竞赛的某种算法的先驱。而百度则抢下了吴恩达。吴曾是前斯坦福AI实验室的负责人，2010年曾帮助推出并领导了以深度学习为核心的Google Brain项目。

此后这场人才争夺战开始变本加厉。微软研究院的Lee说，今天"**这个领域正在上演一场抢夺人才的血腥战争**。"他说这方面顶级人才的报价"堪比一线的NFL选手。"

现年68岁的Geoffrey Hinton是在1972年的时候第一次听说神经网络的，当时他正在爱丁堡大学做人工智能方向的毕业设计。在剑桥大学学习了实验心理学之后，Hinton开始狂热地恋上了==神经网络，这是一种灵感源自大脑神经元工作方式的软件设计==。在当时，神经网络还没有得宠。他说："每个人都认为这种想法疯了。"但Hinton仍然坚持他的努力。

神经网络有望让计算机像小孩一样从经验而不是通过人工定制编程的繁杂指令来学习。他回忆道："那时候大部分的AI都是逻辑启发的。但逻辑是大家很晚才学会的东西。2、3岁的小孩是不懂逻辑的。所以在我看来，就智能的工作方式而言，相对于逻辑，神经网络是一种要好得多的范式。"

在1950和1960年代，神经网络在计算机科学家当中非常流行。1958年，康奈尔大学心理研究学家Frank Rosenblatt在一个项目中首次搭建了神经网络原型，他把这个得到海军资助的项目叫做Perceptron。项目使用的穿孔卡片计算机体型巨大，占满了整整一个房子。经过50次试验之后，它学会了区分在左右侧做记号的卡片。当时的《纽约时报》是这么报道此事的："海军披露了一台电子计算机的雏形，将来这台计算机预期可以走路、说话、写字以及复制自己，并且能意识到自己的存在。"

结果证明，软件只有一层神经元式节点的Perceptron能力有限。但是研究人员认为，如果是多层，或者叫做深度神经网络的话就可以实现更多的东西。

[![LRN.10.01.16-1](https://fortunedotcom.files.wordpress.com/2016/09/lrn_1.jpg?w=1024&h=461)](https://fortunedotcom.files.wordpress.com/2016/09/lrn_1.jpg)

> 1958至1986，深度学习的关键时刻：

> - 1958年，Frank Rosenblatt披露了单层神经网络Perceptron
> - 1969年，AI大牛，MIT的Marvin Minsky合著了一本书，对神经网络的可行性提出质疑，神经网络开始失宠。
> - 1986年，神经网络先驱Geoffrey Hinton等人找到了训练多层神经网络纠正错误的办法，重新点燃了业界对此的热情。

Hinton是这样解释神经网络的基本思路的。假设一个神经网络正在解析一幅有几只鸟在里面的摄影图像。"那么输入就是像素的形式，而第一层单元就会检测边缘。边缘的一边是黑的，另一边是亮的。而下一层神经元则会对第一层发送过来的数据进行分析，学会检测"像棱角这样的东西，也就是两个边缘合成了一个角度。"比方说，这些神经元的其中一个可能会对鸟嘴的角做出强烈响应。

下一层"可能会寻找更复杂的结构，比如围成圆圈的一组边缘。"这一层的神经元可能会对鸟的头部做出响应。再高一层的神经元可能会在类似头部的圆圈附近检测鸟嘴状的角。Hinton说如果发现的话"这可能是鸟头相当好的线索。"每一个更高层的神经元都会对更复杂抽象的概念做出响应，直到最顶层相当于我们"鸟类"概念的其中一个神经元给出答案。

然而，要想学习的话，深度神经网络需要的不仅仅是按照这种方式在各层间传递消息。它还需要想办法看看自己是否在顶层获得了正确的答案，如果没有的话，就要向下返回消息，以便低层的类神经元单元可以调整自己的激活状态来改进结果。学习就是这样发生的。

1980年代早期时，Hinton正在对此问题进行攻关。同样在努力的还有一位法国的研究人员，他的名字叫做Yann LeCun，当时他刚在巴黎开始自己的毕业设计。LeCun无意间发现了Hinton1983年的一篇论文，里面谈的正是多层神经网络。LeCun 回忆道："那些术语都没有正式提及，因为在当时要是提到'神经元'或者'神经网络'的话论文都很难发表。所以他用一种比较含糊的方式写了那篇论文，好通过评委审查。不过我认为那篇论文超级有趣。"2年后2人见面并一拍即合。

[![LRN.10.01.16-2](https://fortunedotcom.files.wordpress.com/2016/09/lrn_2.jpg?w=1024&h=477)](https://fortunedotcom.files.wordpress.com/2016/09/lrn_2.jpg)

> 深度学习史的关键时刻，1989至1997:

> - 1989年，当时在贝尔实验室的法国研究学者Yann LeCun开始了一种神经网络的基础性工作，这种神经网络后来成为了图像识别的关键；
> - 1991年，德国研究学者Sepp Hochreiter和Jürgen Schmidhuber开创了一种带记忆功能的神经网络，后来证明这种神经网络用于自然语言处理尤其出色；
> - 1997年，IBM的深蓝超级计算机用传统AI技术击败了国际象棋世界冠军卡斯帕罗夫。

1986年，Hinton与两位同事写出了一篇原创性的论文，他们在论文中给出了错误修正问题的算法解决方案。LeCun说："他的论文基本上奠定了第二波神经网络浪潮的基础。"此文再次点燃了对该领域的兴趣。

1988年，师从Hinton攻读完博士后之后，LeCun跑到了贝尔实验室，此后10年，他完成的基础性工作至今仍为大多数的图像识别任务使用。在1990年代，当时还是贝尔实验室子公司的NCR把一台采用神经网络的设备给商用化了，该设备在银行得到了广泛应用，据LeCun说，它可以识别支票上的手写数字。与此同时，两位德国的研究学者，现在在林茨大学的Sepp Hochreiter以及瑞士AI实验室主任Jürgen Schmidhuber独立做出了一种不同的算法，这一算法在20年后的今天成为了自然语言处理应用的关键。

尽管取得了所有这些跃进，但到了1990年代中期，因为受制于当时的计算能力，神经网络又再度失宠，被其他更高效的机器学习工具抢走了风头。这一情况持续了将近10年，直到计算能力又提升了3到4个数量级以及研究人员发现了GPU加速的秘密之后才开始改观。

[![LRN.10.01.16-3](https://fortunedotcom.files.wordpress.com/2016/09/lrn_3.jpg?w=1024&h=428)](https://fortunedotcom.files.wordpress.com/2016/09/lrn_3.jpg)

> 深度学习史的关键时刻，1990年代至2011年：

> - 1990年代中期，神经网络被其他机器学习技术抢走了风头；
> - 2007年，李飞飞创立了ImageNet，开始汇编一个带标记图像多达1400万的数据库用于机器学习研究；
> - 2011年，微软引入神经网络来进行语音识别；
> - IBM的Watson用AI击败了2位Jeopardy智力竞赛冠军。

但还缺了一样东西：数据。尽管互联网充斥着各种数据，但大部分数据----尤其是图像数据----都没有标记，而标记是训练神经网络之需。幸好有斯坦福AI教授李飞飞的适时介入。她在一次接受采访时说："我们的愿景是大数据将改变机器学习的运作方式。数据驱动学习。"

2007年，她推出了ImageNet，这个免费数据库涵括了超过1400万张带标签的图片。2009年ImageNet上线，次年她创立了一项一年一度的竞赛来激励并发布计算机视觉方面的突破。

到了2012年10月，当Hinton的两位学生赢得该项竞赛时，情况已经变得了然：深度学习来了。

[![LRN.10.01.16-4](https://fortunedotcom.files.wordpress.com/2016/09/lrn_4.jpg?w=1024&h=486)](https://fortunedotcom.files.wordpress.com/2016/09/lrn_4.jpg)

> 深度学习史的关键时刻，2012至2013年：

> - 2012年6月，Google Brain发布了"猫实验"的结果，它的一个神经网络在观察了1000万张不打标签的YouTube图像之后，自我训练出识别猫的本领；
> - 8月，Google引入神经网络进行语音识别；10月，Hinton的2位学生设计的神经网络以绝对优势赢得了ImageNet竞赛胜利；
> - 2013年5月，Google用神经网络改进了照片搜索功能。

此时公众也多少听说过一点深度学习的事情了，不过原因是另一个事件。2012年6月，Google Brain发布了一个略为怪异的项目的结果，这个项目也就是现在俗称的"猫实验"。实验结果在公众当中引起了有趣的共鸣，一下子在社交网络中流行起来。

这个项目实际上探索了深度学习的一个悬而未决的问题，即所谓的"无监督学习"。目前商用的几乎所有深度学习产品采用的都是"有监督学习"，这意味着神经网络是利用带标签数据（比如ImageNet汇编的那些图像）来训练的。相反"无监督学习"模式下，神经网络拿到的是不带标签的数据，它要通过观察来寻找重复模式。研究人员将来肯定想掌握无监督学习，因为到那时候机器就可以通过目前无用的海量数据来自行了解世界----也就是说几乎仅凭一己之力来弄懂世界，就像婴儿一样。

[![LRN.10.01.16-5](https://fortunedotcom.files.wordpress.com/2016/09/lrn_5.jpg?w=1024&h=486)](https://fortunedotcom.files.wordpress.com/2016/09/lrn_5.jpg)

> 深度学习史的关键时刻，2014至2016年：

> - 2014年1月，Google以6亿美元收购了DeepMind，一家结合了深度学习与强化学习的初创企业；
> - 2015年12月，微软的一个团队利用神经网络在ImageNet挑战中胜过了人类；
> - 2016年3月，DeepMind的AlphaGo利用深度学习以4胜1负的战绩击败了围棋世界冠军李世石。

在猫实验中，研究人员给一个大规模的神经网络（超过1000台计算机组成）展示了从YouTube视频随机截取的的1000万张未打标签的图像，然后就让软件自己折腾。等一切尘埃落定时，他们检查了最高层的神经网络，发现其中一个对猫的图片做出了强烈响应。当时是Google Brain项目领导的吴恩达说："**我们还发现一个神经元对人脸做出了非常强烈的响应**。"

但是结果也令人困惑。比方说，"我们并没有发现有神经元对车做出强烈响应，还有大量神经元我们没法分配英语单词。所以这事儿挺难的。"

这次实验引起了轰动。**但无监督学习仍然没有解决**----==这个挑战被留给未来==。

不奇怪的是，迄今为止大部分商用的深度学习应用都是Google、微软、Facebook、百度以及Amazon这样的大公司的----这些公司掌握了深度学习计算必须的海量数据。许多公司在试着开发更现实且有帮助作用的"聊天机器人"，一种自动化的客服代表。

> # 深度关注深度学习的四大巨头

> ## GOOGLE

> 2011年Google推出了聚焦深度学习的Google Brain项目，并在2012年中引入神经网络用于语音识别产品，2013年3月，他们招来了神经网络的先驱Geoffrey Hinton。现在Google进行中的相关项目超过了1000个，范围涵括搜索、Android、Gmail、照片、地图、翻译、YouTube以及无人车。2014年，Google收购了DeepMind，今年3月，其深度强化学习项目AlphaGo击败了围棋世界冠军李世石，这是人工智能的一次里程碑事件。

> ## 微软

> 2011年上半年，微软把深度学习引入到自己的商用语音识别产品里面，其中包括了Bing语音搜索以及X-Box语音命令。该公司的搜索排名，照片搜索、翻译系统等现在都用上了神经网络。Lee说："很难用语言表达出它所产生的普遍影响。"去年微软赢得了一项关键的图像识别竞赛胜利，今年9月，微软实现了有史以来最低的语音识别错误率：6.3%。

> ## FACEBOOK

> 2013年12月，Facebook聘任法国神经网络创新者Yann LeCun来领导其新的AI研究实验室。Faebook利用神经网络来翻译每天超过40种语言的约20亿帖子，并称它的翻译每天有8亿用户使用。（约一半Facebook用户不讲英语）Facebook还利用神经网络进行照片搜索和组织，目前还在攻关一项功能，替视力受损者生成未标记照片的语音标题。

> ## 百度

> 2014年5月，百度挖来了Google Brain项目负责人吴恩达领导自己的研究实验室。百度的语音识别、翻译、照片搜索以及无人车项目都利用了神经网络。在中国这个移动优先且汉语难以输入的国度里，语音识别是关键。百度称，过去18个月语音接口的使用量已经增加到原来的3倍。

像IBM、微软这样的公司也在帮助商业客户在自身业务中采用有深度学习支持的应用----比如语音识别接口和翻译服务，而像AWS这样的云服务则提供了廉价的GPU驱动的深度学习计算服务----比如Caffe，Google的TensorFlow，以及Amazon的DSSTNE，这些给创新过程起到了润滑剂的作用，因为基于开放发表的规范做法，许多研究人员不等同行评审通过就马上在一个数据库上发布结果了。

许多最令人兴奋的深度学习应用尝试发生在医疗领域。A16Z负责生物投资的Vijay Pande说，我们已经知道神经网络非常擅长图像识别，"而医生做的很多事情都跟图像识别有关，无论是放射科、皮肤科、眼科等等都得看片。"

> # 深度学习与医疗

> 初创企业Enlitic利用深度学习分析X光照片、CT以及MRI扫描结果。其CEO Igor Barani实前加州大学放射肿瘤学教授，他说在检测和区分肺结节是良性还是恶性方面，Enlitic的算法表现比4位放射科医生都要好。

> Merck 试图利用深度学习加速药物发现，旧金山初创企业Atomwise也有相同的想法。神经网络能检查3D图像（这些图像里面有成千上万的分子可能可以成为药物的候选），并且预测它们在阻断病原体机制的适合度。这些公司正在利用神经网络来改进人所做的事情；有的甚至能做人所不能为。27岁的计算生物学博士Gabriel Otte创办了Freenome，旨在通过血样诊断癌症。它会在血液中检查死亡后被细胞喷出的DNA片段。他利用深度学习让计算机找到脱细胞DNA与某些癌症之间的关联。Otte说："我们看到了一些此前癌症生物学家尚未归类的新颖特征。"

> 当A16Z正在考虑是否对Freenome进行投资时，A16Z的Pande给Otte提供了5份盲样，其中2份是正常的，而另外3份则是癌性的。结果Otte 5份都答对了。于是他们决定进行投资。

放射科医生一生可能会看成千上万张X光片，但计算机的观看量却可以百万计。Pande说："计算机能更好地解决这一图像问题并不难以想象，因为它们消化吸收的数据比人多太多了。"

其潜在优势不仅仅是精确度更好分析更快，还包括分析的大众化。随着技术成为标准，最终所有病人都将受益。

当深度学习以尚未想到的方式集成到其他人工智能技术的整个工具箱时，我们也许就能感受到它的最大影响。比方说，Google得到DeepMind通过结合深度学习和强化学习就已经取得了令人吃惊的结果。这两者结合的产物AlphaGo在2016年3月击败了围棋世界冠军李世石，被广泛认为是人工智能里程碑式的成就。AlphaGo跟1997年击败国际象棋冠军卡斯帕罗夫的IBM深蓝不一样，它既没有决策树方面的编程，也没有如何评估棋盘位置的方程式，或者是假定的规则。DeepMind CEO Demis Hassabis 说："AlphaGo基本上是靠左右手互搏和观察职业棋局来下棋。"（训练期间AlphaGo跟自己下了100万盘棋）

游戏也许看起来像是一种人为设置。但Hassabis认为同样的技术可以运用到现实世界问题上。实际上，今年7月Google报告称，通过利用类似AlphaGo的技术，DeepMind[把Google数据中心的能效提升了15%](http://36kr.com/p/212400.html) 。Hassabis说："数据中心可能有120个不同的变量。你可以改变风扇、打开窗户、改变计算机系统，这些都是耗电的地方。你从传感器、温度计等获得数据。这就像围棋一样。通过试错，你可以学会怎么走才对。"

"所以这是很好的。你每年可以节省上千万美元，而且对环境也很好。全球的数据中心消耗了大量电能。现在我们打算进一步铺开。甚至应用到国家电网这种规模。"

聊天机器人当然也不错。但那只是一个很酷的app罢了。

本文来自翻译：[fortune.com](http://fortune.com/ai-artificial-intelligence-deep-machine-learning/)，如若转载，请注明出处：<http://36kr.com/p/5054042.html>



# 这11个观点可能会让你和深度学习擦肩而过

==深度学习有可能会是“人类最后一个发明”==

我大部分走路的时间还有睡梦中的潜意识里都会琢磨着Deep Learning 的问题。Peter Thiel 有一个很有名的说法——“最后一个公司的优势”。意思是==你可能不需要具备“第一启动的优势”，但是你一定要成为你行业里最后一个站着的公司==。就像Google有可能是最后一个搜索引擎公司，Amazon有可能是最后一个做电商的, Facebook希望不是最后一个社交网络公司等。但是让我夜里辗转反侧的是——深度学习有可能会是“人类最后一个发明”(Last Invention of Man)。

但是，咱们先别想那么远。不管怎样，Kurzweil在他《奇点临近( Singularity)》一书中预计在2045年实现的设想也是30年之后的事情。我们现在要做的就是在这30年里弄清楚想生活在像电影《极乐（Elysium）》中那样，还是什么别的不知名的腐烂废水里。

因此，我提出“专家”团队可能会让你和深度学习带来的重要改革擦肩而过的11个理由，供大家参考。

## 这仅仅是机器学习（Machine Learning）

从业人员接触神经网络一般都是从线性回归的介绍然后再到逻辑回归。这是因为人工神经网络（ANN）用的数学公式是一样的。所以这里瞬间产生偏见，导致人们认为经典的机器学习方式在深度学习的世界里也可行。最后，对于DL最天真的解释就是它是多层的ANN。

当然，我们也有其他种类的机器学习方式，他们是用和DL不同的公式。但是，ML所有方法最基本的目标和一般概念都是曲线拟合。意思就是如果你能找到一个合数据吻合的模型，它就是个好答案。但在DL系统里，因为模型的参数太多，这些系统会默认过度拟合数据，这就足够证明DL和ML是完全不同的系统了。

## 这仅仅是优化

DL系统有一个损失函数（loss function），它会测量预测和输入的数据吻合有多好。经典的优化问题也有损失函数，也称为“目标函数”（objective functions）。这两个系统会使用不同的启发式方法（heuristics）去探索在很大的配置空间里的最优点。以前人们认为DL 系统的 solution surface 已经很复杂，并且是不可能找到答案的。但神奇的是，一个很简单的优化方法——==随机梯度下降法（Stochastic Gradient Descent ）==就可以得到很好的结果。

这就告诉我们其实这里还有别的事情，和我们认识的优化完全不同的东西。

## 这是个黑盒子

很多数据科学家都不太喜欢DL，因为它的预测缺少很多可解释性——这不仅是DL也是ML都有的特征。数据科学家更喜欢使用概率方法，因为他们有更多模型的控制。这个导致他们的系统会用最少量的参数做预测。这一切的推动力量都是源于对“**简单化**或‘**奥卡姆剃刀原理(Occam's Razor)’**是对所有事物最好的解释”的信念。

但概率方法在判断图形、语音甚至文字上其实是没有竞争力的，这是因为DL方法比人类还能更好的找到模型。只是我们的大脑更信任穷举法。其实没有任何数据科学家找到过可以很好判断图形的主要因素，也没有任何DL实验依据证明简约模型（parsimonious models）比交互模型（entangled models）效果更好。对于那些真的需要解析的案例，现在有些新的DL方法可以对其提供可解释性和不确定性提供帮助。如果一个DL系统可以提供图像说明，那它也很可能可以生成对预测的解释。

## 太早了，太快了

这是一个自然的偏见，一个只有5年历史并且急速进化且易变的科技太不可信。我们当时也是这么说微型处理器、互联网、网络和移动技术的。对于大部分人来说，先等等看是安全的方法。对于没有花很多时间分析细节的那些人来说，这的确是一个合理的方式。但这也是一个有风险的策略，不去关注有可能是暂时的安全，但是别的公司抢你的饭碗可能意味的你的灭绝。

## 太多泡沫

有很多现在DL能干的是在两年前都觉得是完全不可能的。没有人预见到电脑能在围棋上战胜人类；没有人预见到现在会有无人车；没有人预见到我们能有星际迷航那样的翻译能力。这些都那么不可思议并且肯定有夸张的成分在。不好意思，我在这里要戳破你回避的“泡泡”，DL真的存在，并且你每次用手机都在使用它。

## AI 的冬季会回来的

我们经历过太多次因AI的前景所带来的失望结果。这个说法走得很远，因为这在以前经常发生，所以它早晚会再次发生。这个问题是，尽管那些失望存在，但AI的研究带来了很多软件功能的飞跃，而且这些功能我们现在都自然而然地使用着，并且从来都没有察觉到他们的存在。“优秀的老式人工智能”(Good Old-Fashioned AI)已经嵌入在很多今日的系统里。

现在对DL 的开发正在加速进行，而且我们也有很多大问题需要解决。需要大量数据和缺少无监督的训练是其中的两个问题。但这不代表我们今天的成果没有价值。DL已经可以开车了，如果现在再来一个冬季，就这一点就足够证明现有阶段已经十分有用了。

## 我们没有足够的理论解释它怎么工作

目前，研究团队还没有扎实的理论来解释为什么DL这么有效。我们想过为什么多层神经网络比少几层的更有效，但是==我们还不能理解收敛性如何发生，或者好的泛化如何实现==。DL现在就是一个实验品，我们还在学习这类系统的特征。同时，虽然没有扎实的理论理解，这些工程师一样在前进。

研究员们正在利用他们的直觉和受过教育的猜测建立更好的模型。换句话说，他们不会为了等待更好的理论而暂停他们的发展。这和生物科技领域的研究一样，他们测试很多种组合然后遇到他们不能解释的新发现。科学和科技的发展的确有些不确定的混乱，但是你不应该因为这而放弃它的优点。

## 这不来源于生物灵感

DL和我们大脑里的神经元差异很大。DL 的学习方式（比如SGD）是不能用我们大脑里的什么结构去类比的。但这里的论据是，==如果它不和大脑类似，它就不能执行大脑能做到的推理和学习==。这当然不是很有力的论据。可飞机虽然长得不想鸟，但是它一样会飞呀。

## 我不是这里的专家

自己没有专业知识不是逃避不去外面找专业知识的借口。并且，这也不应该成为阻止你的专家团队去学习这个新技术的理由。但是，如果你的专家是教条死板的那种，这就说明你应该去寻求第二个没有偏见的意见。

## 这在我的问题上不适用

一个企业有很多业务流程。如果你没有去检查哪些流程是可以被现有的DL自动化的，那你就没有权力去说DL对你不适用。其次，你可能会发现现在没有的、但是可以用DL实现的流程或商业机会。你真的不能回答这个问题，直到你在这方面做了尽职的调查工作。

## 我没有资源

Google、Facebook等很多大公司挖走了很多DL的 天才。 这些企业没有兴趣和小公司合作，去发现它们具体的需求和机会。但所幸这些大公司还允许它的研究员公开他们的研究成果。所以我们可以看到它们最新的发展成果，并且可以提取它们学到的知识，应用在你的场景里。还有些公司比如Intuition Machine，加入它们会让你取得在DL 技术上的竞争优势。













