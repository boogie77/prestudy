# AlphaGo



柯洁不敌AlphaGo，这是没什么悬念的结果，因为AlphaGo几乎集中了人类所有的棋谱。但更重要的是，在这台机器中，所有棋谱永远都处于激活状态，它不需要休息，一切都在恒定的机器属性中平稳运行，不管是遇到了什么情况，对于机器来说，都只是在已知的棋谱中翻找对策而且。只要有电能的驱遣，机器就没有疲倦的时候，它可以快速地搜索，并且不受任何人类氛围或心理的影响，它的每一次运算，都是一次不知疲惫的新起点，从这个角并来说，它是不可战胜的。



## AlphaGo「理解」围棋吗？

**AlphaGo理解围棋，而且AlphaGo比人类对围棋的理解高一个层次。**

> 你或许还是不能接受AlphaGo这个样子，我想这是因为，人们下围棋，一定要先理解“围棋”什么东西，下面才可以操作。但是AlphaGo却是在不知道(或者没有被提供数据)“围棋是一种2个人的，而且两个人面对面做的，对抗的，零和的，棋盘19*19的，棋盘是方的，上面是打格子的，格子也是方的，有黑白两个子的，黑子先下的，两个轮流下的，要下在格点而不是格子中间的，有限时要求的，棋子数量足够的，一个棋子不会占超过一格的，棋子是圆的，两边凸起的，中国古代发明的，一种博弈游戏”中的任何一点的时候，可以战胜人类。

计算机围棋界有基于中国规则的Tromp-Taylor规则（[Tromp-Taylor Rules](https://senseis.xmp.net/%3FTrompTaylorRules)）。

> Tromp-Taylor规则定义，围棋是一个在19*19格点上进行，两个玩家“小黑”、“小白”，轮流分别把棋盘上的某一个格点染成黑色或白色的游戏。再加上提子和禁循环的规则，以及终局判断，就是完整的Tromp-Taylor规则。



**围棋是世界上最复杂的游戏之一**。所谓“==一着不慎，满盘皆输==”，每一步棋都可能左右全局的结果。一般来说，一手棋的决策分两步。第一步，“选点”：凭经验或感觉给出几个候选的点；第二步，“判断”：分别对这几个点做形式判断，并进行比较。这两步，说来容易，但要做到笑傲众生的水平，对于天赋和勤勉的要求，不亚于一个优秀数学家所需要的。

从初学者成长为大师，棋手需要先学会基本的布局理论、掌握基本的死活、对杀常识，然后熟记数百个定式及掌握其主要分支（飞刀）、练习数万死活题，同时在大量对局中磨练。有些外行据此认为，围棋只是复杂一点的“体力劳动”。

**“体力劳动”让天赋平平者能够成为业余高手，但山巅最美的风景只属于天才**。

我们再说“判断”。判断很难吗？在中国象棋或者国际象棋中，形势判断对于程序来说并非难事：只需观察双方子力的差距就可以大致判断出形式的好坏。当年战胜卡斯帕罗夫的“深蓝”，其形式判断算法大致就是如此，非常简洁。而==围棋的形势判断是个真正的难题==。**围棋的胜负由终局时双方控制地盘的多寡决定**。然而棋局进行到一半，双方的地盘都尚未封闭，怎么判断形势呢？

职业棋手采用的算法是估算双方的目数（地盘大小）差距。那如果地盘的边界没有完全确定怎么办呢？如果有先手官子就判给先手方，如果是双方后手官子就算一人一半。如果有一些模糊的地方，比如说一块厚势折算成几目呢？这时候就只能凭经验感觉了。**职业棋手之间微妙的水平差异，很多时候也体现在模糊判断能力上**。

对于高手来说，除了十几年日复一日训练的积累以外，**灵感和天赋也是必不可少的**。在复杂局面下，棋手的选点需要灵光一现，而模糊判断的准确性，离不开棋手的天赋。

围棋自古以来与琴、书、画并称君子四艺，现在我们仍然这么提。但是，围棋终究是一个游戏。如果你对博弈论有所涉猎，大概会知道，==围棋是一种“完全信息”博弈==。更懂行一点的读者知道，根据**策梅洛定理**，像围棋这样的二人、完全信息、无运气成分、有限回合、且不存在和棋的游戏，对局的其中一方是有必胜策略的。（这里有必要解释一下“有限回合”和“不存在和棋”。围棋的中国规则中，有“禁循环”一条，这就杜绝了棋局无限制进行下去的可能。另外，如果严格执行“禁循环”规则，三劫循环、长生等特殊棋型，相当于打一个普通的劫争，不必判和棋。现实中将三劫循环判和，只是一种权宜之计，相信未来可能会改变。）

那么，既然必胜策略一定存在，为什么围棋手不去研究必胜策略，搞什么选点、判断？为什么围棋手不能踏踏实实用逻辑推理解决战斗，是不是他们在故弄玄虚，或者说装逼？

当然不是。**因为围棋太难了。**

1950年，“信息论之父”克劳德·香农在论文“Programming a Computer for Playing Chess” 中给出了国际象棋复杂度的一个下限。香农写道，一盘象棋一般有40个回合，平均每回合的变化总量大约在$10^3$这个数量级，那么国际象棋的变化总数至少是$10^{120}$这个数量级。后人把$10^{120}$这个数称作“香农数(Shannon Number)”。香农用此计算说明，利用纯暴力搜索破解国际象棋是不现实的。

如果我们估计一下围棋的香农数呢？19路围棋盘上，一盘棋大约是120个回合（240手），平均每回合的变化数总量在$10^5$以上，这样算下来，围棋的变化总数不少于$10^{600}$。可观测宇宙的原子总量$10^{80}$，相形之下，真是小巫见大巫。刘慈欣的小说《诗云》中写道，就算把宇宙中的每一个原子都做成储存器，而且技术先进到一个原子能储存一比特信息，也只能存下很小一部分的棋局。

诚然，计算，或者说单纯的逻辑推理，是围棋技艺的基础。不过，当计算量远远超出人脑的能力之时，减少计算量的技巧，选点、判断，就必须出场了。经验性的选点，让棋手快速将有限的计算力集中到几个重要分支上；而准确的判断，能够让棋手在优势局面下鸣金收兵，避免复杂计算，减小风险；或者在劣势局面下放弃幻想，奋力一搏。当然，选点、判断时的模糊性，在逻辑上难免不严谨，有一定风险，这就要求棋手权衡利弊，合理分配时间。



人类棋手的思维方式，是根据输入的局面，输出候选招法和形势判断，综合以后给出最终输出。AlphaGo的大框架与此非常相似。AlphaGo的策略网络，大致对应人类“选点”的决策；AlphaGo的价值网络，大致对应人类“判断”的决策。

在此基础上，蒙特卡洛搜索树算法将策略网络和价值网络串联起来，形成完整的决策系统。

AlphaGo基于蒙特卡洛搜索树的单次决策过程，附有我的诠释。进行此循环多次以后，AlphaGo选择在过程中**重复次数最多**的分支为最终落子点。

AlphaGo以4:1战胜李世乭，又化名Master在快棋中横扫职业棋手，实力无疑超过所有人类棋手。然而，还有更恐怖的事情。棋手们在这一年多以来，一直在向AlphaGo学习。在具体招法上，也有了不少心得。**但是，AlphaGo的判断力是人类永远没法学习或者模仿的。**

**人类“数地盘”式的判断常有失灵之时**。除了模糊判断可能带来的误差以外，对于某一块地盘归属的错判也是经常发生的。

**AlphaGo在复杂局面下的形势判断，比职业棋手的判断更精准**。

更重要的是，==AlphaGo基于概率的形势判断，比人类棋手比较地盘多寡的判断，更接近围棋的本质==。学棋的时候，老师常说，赢半目和赢一百目没有区别。围棋十诀第一条就是“不得贪胜”。说明人类棋手都认同，保住胜利果实，比拿到更多地盘更重要（也许藤泽秀行棋圣是个例外）。**然而，具体操作中，人类的形势判断算法并不能实现这一目标**。

**AlphaGo有能力精确地估算胜率，人类棋手不能。因此我说，AlphaGo对围棋的理解，比人类高一个境界。**



## 傅盛观点

> 赛前有预测观点指出，此次AlphaGo2.0有望放弃监督学习脱离人类经验，也就是今天主流机器学习不可避免的核心条件。随后这一观点被猎豹移动CEO否定，他预测AlphaGo目前版本并未做脱离监督学习，如果能做到，新版本的技术突破其实不亚于第一版AlphaGo的意义。**从零开始训练，意味着利用增强学习从零开始演化，纯粹靠对局最后的Reward（胜负）来学习**。“用RL模型在初始没有监督的情况下想要收敛到接近最优解还是一个很开放的问题，哪怕对于红白机的一些游戏也不能完全做到。如果AlphaGo 2能够完成从零开始学习，很可能意味着对于增强学习算法本身有比较重大的突破，而这种突破可能不仅用于围棋，也有大量对其他应用的可能，所以意义会不亚于AlphaGo 1的横空出世。”
>
> 傅盛([微博](http://t.qq.com/fusheng#pref=qqcom.keyword))的观点在赛后得以认证，AlphaGo的核心作者之一Aja Huang(黄士杰)在首战后声明“此次AlphaGo是单机版，但仍有人类知识的训练。”
>
> “AlphaGo 2.0并没有本质突破，我们期待的无监督学习并没有到来。Deepmind作为世界最顶尖的深度学习机构，引领着人类在深度学习上的探索。但一年的时间，AlphaGo 2.0本质上只优化了算法，提升了运算能力。这也提醒广大的AI从业者，不要仅仅寄希望于爆炸性的技术突破，落脚当下应该聚焦AI与应用相结合”傅盛说。

傅盛曾多次公开指出==深度学习的机会在于和应用的集合而不仅仅是技术输出==。他认为深度学习是算法革命，本质上降低了技术壁垒。由于基本算法模型的固定化，算法的驱动力已经大大地降低了，算法驱动变成了数据驱动。因此，深度学习的核心是数据驱动，虽然有模型调参的机构会有自己的优势，但更多的数据调参会很快拉平优势。

从深蓝到阿法狗，棋牌类游戏一直被用来检验人类与人工智能的差距，追溯原因，一方面棋类历史悠久，人类有足够的积累，围棋拥有的变化足够多，暴力搜索不能解决问题，必须要让AI有＂直觉＂；另一方面在博弈中属于完全信息博弈（Complete information），其实是最方便拿来验证AI能力。傅盛预测，==未来AI所扮演的是助手的角色，而不是对抗的角色，将是人机共存的时代==。



## 配对赛和团体赛组队刷AlphaGo

人机大战今日开启“花样虐狗”的环节，国内几大高手通过不同的规则与AlphaGo过招，包括配对赛和团体赛，其中团体赛堪称“群殴”。

### 配对赛：古力+AlphaGo VS 连笑+AlphaGo 双人围棋

古力九段 & AlphaGo 执黑对战连笑八段 & AlphaGo，最终连笑与 AlphaGo 组合执白获胜。

这个比赛的本质是双人围棋赛，是一种历史悠久的赛制，典型的双人围棋赛是**混双围棋赛**，即==一男一女两位棋手组队轮流下棋。比赛期间同队的男女棋手严禁任何语言交流==。

**用时规则**：每方1小时自由思考时间，用完以后60秒一步读秒。

**特点**：既然双方一人一手轮流下棋，同时严禁语言交流，双人围棋赛的竞技水平**取决于两位棋手配合默契、或者说相互理解对方想法的程度**。因为围棋比赛中一个战斗下来需要若干手棋，每一手之间是有联系的，两个棋手如果默契不够，就会出现一方落子以后另一个队友没能把后续手段下出来的情况。这样就会错失机会甚至造成失误。

组队的两个棋手水平越接近，组队效果越好。水平差距大的情况下，水平较差的一方不能理解水平较高一方所下的棋，不能把队友的好棋的后续手段施展出来，好棋也变成坏棋。换句话说，**双人围棋符合木桶理论原则**。

组队的两个棋手在水平接近的情况下，相互之间风格越接近，越容易理解对方的想法，棋的连贯性越强。

配对赛的比赛过程中，出现了很有喜感的一幕：由于古力的失误，棋局处于下风，和古力配合的AlphaGo表示要认输，古力却拒绝认输，继续下棋，然后AlphaGo就开始乱下，几手之后古力也举牌同意认输。

下午的比赛，由五人组队“群殴”Alphago，五人包括：时越、芈昱廷、唐韦星、陈耀烨和周睿羊，这五名棋手集体讨论研究进行对局，合力对抗Alphago。五人团队持黑先走。 

### 团队赛：时越、芈昱廷、唐韦星、陈耀烨和周睿羊5人 VS AlphaGo 相谈棋

由来自中国的五个顶尖棋手芈昱廷、唐韦星、周睿羊、时越、陈耀烨组成团队，来对战 AlphaGo；AlphaGo 虽然只有一个，但由于它的自我学习和对弈能力，其本身相当于两个或多个。

**相谈棋**指**几名棋手集体讨论研究进行对局，在职业棋界不算是正式比赛，但作为一种联谊交流的手段曾经多次采用**。

**用时规则**：每方2.5小时自由思考时间，用完以后60秒一步读秒。

**特点**：围棋作为个人竞技项目，并不是人多力量就大的。相谈棋如果组合的不好，很可能发挥的水平还不如单个选手，相谈棋要想发挥出最大威力，有如下几个方面的要点：组队选手年龄、身份相近，关系友好，可充分展开讨论；组队选手的棋风差异不能过大；组队选手之间要有明确的分工协作。

“相谈棋”虽然人多，但实际上也有一定的弊端；因为在现场对战中，需要花费大量时间来讨论；这就要求团队成员的棋风要相近。

实际的情况是，五个棋手分为对比鲜明的两派，芈昱廷和唐韦星属于短兵相接，针锋相对的类型；而周睿羊、时越、陈耀烨属于大局派。

在五位棋手中，周睿羊是队长，起拍板作用；这是教练和队员们推选的结果，而周睿羊也被称为“阿尔法羊”，因为周睿羊是对 AlphaGo 了解最深的一个，他在过去的下棋中也多次利用 AlphaGo 的下法。但是从现场情况来看，大局派的周睿羊似乎并没有起到队长的作用。

柯洁曾经自告奋勇要为棋手团队执子，担任“机械臂”，但因棋手团队担心“柯式机械臂”自作主张而作罢。

五大围棋高手用时一个小时的时候，AlphaGo 用时 16 分钟。





## Siri创始人：人工智能领域正面临这4大机遇窗口

- 自然语言识别和理解是现在大公司一个主攻的方向。
- 另外一个机遇窗口是计算机视觉。
- 下一个阶段的大应用就是在物联网，人工智能会有很广泛的应用。
- 再接下来就是智能机器人。




















---