# 人工智能各种观点



## 深度神经网络（DNN）是否模拟了人类大脑皮层结构？

[深度神经网络（DNN）是否模拟了人类大脑皮层结构？](https://www.zhihu.com/question/59800121/answer/174198192?utm_campaign=rss&utm_medium=rss&utm_source=rss&utm_content=title)

==部分是==。

1. 一开始提出时，显然是借鉴人脑的，**权值更新规则是著名的生物学上的Hebb's rule(经常一起激活的神经元连接会加强)**。但是，==Hebb's rule 不能训练多层网络==，实际上训练深度网络的是BP算法，而**BP算法在生物学上很牵强(虽然一直有人argue说存在，但是并没有真正让人信服的结论)**
2. LeCun在提CNN的时候提到了借鉴人脑。==人脑视觉处理确实是分层的，并且非常重要的是CNN产生了和人脑非常一致的激活模式==。但是，**人脑处理公认一般也就4到5层(初级视皮层V1-V5)**，但是你看次现在效果奇好的Residual，可以上千层。。。
3. 非常重要的一点，==人脑神经元传递信号是脉冲形式的，有“时序和频率”的概念==，而不是像神经网络一样不更新就是定值。**脉冲形式也是能耗低和鲁棒性高的重要保证**。
4. ==强化学习被认为和人脑的多巴胺系统有非常重要的联系==。多巴胺系统似乎能够传递强化学习中的td信号。实验有初步认证，但是仍待观察。但是提问中问的是大脑皮层Orz.
5. ==神经元相比神经网络中的人工神经元复杂的多，神经元有很多“内态”，多种效用不同的神经递质和激活模式==。这点上看两者又是差异很大的。
6. 一些边缘的类似，比如说**注意力模型**等。这些可能有关系（比如人脑确实是使用神经元以和DNN类似的模式来控制注意力的），但目前说不清。



## 机器阅读技术目前的水平

[机器阅读技术发展得如何？能达到什么水平？有哪些应用？](https://www.zhihu.com/question/59280791/answer/172957407?utm_campaign=rss&utm_medium=rss&utm_source=rss&utm_content=title)

做机器阅读理解研究的学者想必对由斯坦福大学自然语言计算组发起的SQuAD（Stanford Question Answering Dataset）文本理解挑战赛并不陌生，它也被誉为“**机器阅读理解界的[ImageNet](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzAwMTA3MzM4Nw%3D%3D%26mid%3D400607098%26idx%3D1%26sn%3D933c7328221cfec90e358314be8602e3%23rd)**”。诸多来自全球学术界和产业界的研究团队都积极地参与其中，目前微软亚洲研究院的自然语言计算研究组**持续稳居榜首**，与包括艾伦研究院、IBM、Salesforce、Facebook、谷歌以及CMU（卡内基·梅隆大学）、斯坦福大学等在内的全球自然语言处理领域的研究人员，共同推动着自然语言理解的进步。 

2017年5月8日SQuAD排名和结果截图，其中微软亚洲研究院的集成模型（ensemble）和单模型（single model）分列各自排名首位

那么，SQuAD机器阅读理解挑战赛是怎样进行的呢？SQuAD通过众包的方式构建了一个大规模的机器阅读理解数据集（包含10万个问题），即将一篇几百（平均100，最多800）词左右的短文给标注者阅读，随后让标注人员提出最多5个基于文章内容的问题并提供正确答案。SQuAD向参赛者提供训练集用于模型训练，以及一个规模较小的数据集作为开发集，用于模型的测试和调优。与此同时，他们提供了一个开放平台供参赛者提交自己的算法，并利用测试集对其进行评分，评分结果将实时地在SQuAD官网上进行更新。

得益于SQuAD所提供的庞大数据规模，参与该项挑战赛的选手不断地对成绩进行刷新，SQuAD挑战赛也逐步成为行业内公认的机器阅读理解标准水平测试。在今年的ACL大会（自然语言处理领域最顶尖的会议之一）的投稿里，有非常多的论文就是关于这项挑战赛的研究，其影响力可见一斑。从ACL 2017论文主题的可视分析中可以看到，“**reading comprehension（阅读理解）**”是今年ACL录取论文中最热门的关键词和任务，广受自然语言处理领域研究人员的关注。

“虽然偶尔有一两天其它团队超过了我们的成绩，但我们也有最新的算法能够很快地进行更新，并取得更好的成绩，对于这一点我们的团队始终十分自信。”机器阅读理解研究的主要负责人、微软亚洲研究院自然语言计算研究组主管研究员韦福如表示。

### 机器阅读理解，自然语言计算领域皇冠上的明珠

如今，我们在图像识别、机器翻译和语音识别等研究领域已经看到了机器学习带来的显著成果。例如图像识别技术对[癌细胞病理切片](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzAwMTA3MzM4Nw%3D%3D%26mid%3D2649439019%26idx%3D1%26sn%3Db55d1cbe682bafb174eae8497e45bbca%26chksm%3D82c0d2afb5b75bb92dad651b3daf70d5b9135840beef4aaa2c36652a10329956d71b91705ccc%23rd)的识别能力已逐步超过人类，目前[机器围棋棋手](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzAwMTA3MzM4Nw%3D%3D%26mid%3D2649439163%26idx%3D1%26sn%3D8581cfe463b69b9e612753c09f7af73e%26chksm%3D82c0d23fb5b75b29d9fec5b75138302537d77ef1840567faeec24838895aeaa27d48f846ae7c%23rd)的棋力已经几乎无人能敌……狂热过后，当我们重新审视人工智能这个问题时，一个最基本的问题可能尚未解决：[计算机能够理解多少我们的语言了？](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAwMTA3MzM4Nw%3D%3D%26mid%3D206644835%26idx%3D1%26sn%3D7755ec2a345088b9e9b9bde186e8bb81%26scene%3D21%23wechat_redirect)

计算语言学协会（ACL， Association for Computational Linguistics）候任主席，微软亚洲研究院副院长周明博士认为：“自然语言处理的基本研究包括**分词、断句、句法语义分析**等等。而机器阅读理解就是自然语言计算领域皇冠上的明珠。”

一般来说，人们在读完一篇文章之后就会在脑海里形成一定的印象，例如这篇文章讲的是什么人，做了什么事情，出现了什么，发生在哪里等等。人们能够很轻而易举地归纳出文章中的重点内容。机器阅读理解的研究就是赋予计算机与人类同等的阅读能力，即让计算机阅读一篇文章，随后让计算机解答与文中信息相关的问题。这种对人类而言轻而易举的能力，对计算机来说却并非如此。

很长一段时间以来，自然语言处理的研究都是基于句子级别的阅读理解。例如给计算机一句话，理解句子中的**主谓宾、定状补**，谁做了何事等等。但长文本的理解问题一直是研究的一个难点，因为这涉及到句子之间的**连贯、上下文和推理**等更高维的研究内容。

大数据的发展让学者们看到了这一研究方向的曙光。可获取的**越来越大的文本数据，加上深度学习的算法以及海量的云计算资源**，使得研究者们可以针对长文本做点对点的学习，即对句子、短语、上下文进行建模，这其中就隐藏了一定的推理能力。所以，目前自然语言处理领域就把基于篇章的理解提上研究的议事日程，成为目前该领域的研究焦点之一。而针对上文提及的相关难点，微软亚洲研究院自然语言计算研究组正在进行下一步的研究和探索。

### 做顶尖的机器阅读理解研究

正如前文所说，机器阅读理解的研究之路始终充满着许多困难和挑战。

首先是**数据问题**。目前基于统计方法（尤其是深度学习模型）的机器阅读理解的研究离不开大量的、人工标注的数据。在SQuAD数据集推出之前，数据集常常面临规模较小，或是质量不佳（因为多是自动生成）的问题，而SQuAD无论是在数据规模还是数据质量上都有一个很大的提升。在基于深度学习方法的研究背景下，数据量不够就很难做出有效、或是有用的模型，更难对模型进行合理、标准的测试。

另一方面则是**算法问题**。之前自然语言处理在做阅读理解或者是自动问答研究的时候，会把这个研究问题视作一个系统的工程，因而把这个问题分成许多不同的部分。例如先去理解用户的问题；再去找答案的候选；再将候选答案进行精挑细选、互相比较；最后对候选答案进行排序打分，挑选出最可能的答案或者生成最终的答案。而这个繁复的过程中，似乎其中的每一步都是可以优化的。

但它相应地也会带来一些问题。第一，当你分步去优化这其中的每一个过程的时候，你会去研究如何更好地理解这个问题，或是研究如何更好地把答案做对，这些分目标研究结果的整合未必能和“如何将阅读理解的答案正确找出来”这个目标完全吻合。第二，如果想做局部的优化，就意味着每一个局部过程都需要相应的（标注）数据，这使得阅读理解的研究进展缓慢。如果只使用问题-答案作为训练数据，中间模块的优化得到的监督信息不那么直接，因而很难有效。

结合了上述问题，微软亚洲研究院自然语言计算研究组的机器阅读理解研究团队**采用的则是一个端到端的深度学习模型的解决方案**，区别于上述的每一个细化环节的具体优化过程，他们采取的方法是把中间环节尽可能的省去，使得整体的过程能够得到最优效果。

实际上，SQuAD的挑战赛形式就是让系统在阅读完一篇几百词左右的短文之后再回答5个基于文章内容的问题。这个问题可能比大家熟知的高考英文阅读理解，或是托福阅读考试都要难得多。人们参加的这些考试往往是一个答案被限定住范围的选择题。

但是在SQuAD的数据集中，问题和答案具有非常丰富的多样性。这五个问题中可能涉及文章中的某一个人，某一个地点，或是某一个时间等等实体；也有可能会问一些为什么（Why）、怎么样（How）的问题。后者的答案可能实际上是一句话，甚至是一小段话，因此解决这个问题只会更加棘手。

另外，在SQuAD数据集中，除了问题的多样性之外，研究员们发现还有更多的挑战。比如语言（包括词级别和句子级别）的歧义性，对于同一个意思，问题和短文会用不同的词语或者句型表述（在标注指南中就明确要求标注者尽可能使用不同的表述）。另一个很有难度的挑战是对于有些问题，找到正确答案需要用到整篇短文中的不同句子的信息，进而对这些信息进行聚合和比较才能最终得出正确的答案。当然，也有一部分问题需要用到比较复杂的推理、常识和世界知识，面对这类问题就更是难以处理。下表是发布SQuAD数据集一文中给出的总结。

目前SQuAD挑战赛采用两个评价标准来对参与系统的结果进行评测。由人工标注的答案作为标准，系统自动依据**准确性和相似度**两个不同的维度进行打分，较客观地保证了评分系统的公平性。微软亚洲研究院团队在这两个不同维度的评价标准上均取得了最优的成绩，其准确度达到了**76.922%**，相似度达到了**84.006%**，高出第二名近两个百分点。



## **R-NET: 基于神经网络的端到端系统**

为了研究机器阅读理解的问题，包括韦福如和杨南等在内的研究团队试图去建模人做阅读理解的过程。他们采用了R-NET，一个多层的网络结构，分别从四个层面对整个阅读理解任务的算法进行了建模。

我们在做阅读理解的过程中，一个常见的顺序是这样的：首先阅读整篇文章，对文章有一个初步理解之后再去审题，从而对问题也有了一定认知。第二步，可能就需要将问题和文中的部分段落和内容做一些关联。例如题干中出现的某些关键已知信息（或证据）的，找出一些候选答案，举例来说：如果问题问的信息是时间，那么文中出现的与时间相关的信息就可能是候选答案。第三步，当我们将候选答案与问题进行对应之后，我们还需要综合全文去看待这些问题，进行证据的融合来辅证答案的正确性。最后一步，就是针对自己挑出的答案候选进行精筛，最终写下最正确的答案。

有鉴于此，研究组提出的模型也就分为这样的四层。最下面的一层做表示学习，就是给问题和文本中的每一个词做一个表示，即深度学习里的向量。这里研究组使用的是**多层的双向循环神经网络**。第二步，就是将问题中的向量和文本中的向量做一个比对，这样就能找出那些问题和哪些文字部分比较接近。接下来，将这些结果放在全局中进行比对。这些都是通过**注意力机制（attention）**达到的。最后一步，针对挑出的答案候选区中的每一个词汇进行预测，哪一个词是答案的开始，到哪个词是答案的结束。这样，系统会挑出可能性最高的一段文本，最后将答案输出出来。**整个过程就是一个基于以上四个层面的神经网络的端到端系统**（见下图）。

微软亚洲研究院提出的R-NET算法的网络结构图。其中最为独特的部分是第三层文章的自匹配网络（Self-Matching Networks），更多细节请参考论文**：R-NET: Machine Reading Comprehension with Self-matching Networks**

SQuAD数据集于2016年9月份发布了正式版。一经推出，微软亚洲研究院自然语言计算研究组就敏锐地判断这是一个非常重要的数据集，将会极大地推动机器阅读理解的研究，并将在研究界和工业界产生积极深远的影响。10月，研究团队就第一次提交了他们的研究成果，并且取得了第一名的好成绩，而后续几个月的数次提交，则是在不断地刷新着自己的成绩。对于研究团队来说，这其实是一个试错的过程，团队每天都会讨论总结当天的试错成果，有新的想法就不断尝试。

## **未来的应用方向**

提及机器阅读理解未来值得探索的方向，韦福如分享了他的三点看法。他认为一方面**基于深度学习的算法和模型还有很大的空间**，适合机器阅读理解的网络结构值得在SQuAD类似的数据集上进一步尝试和验证。具体来说，通过对R-NET目前处理不好的问题的进一步分析，能否提出可以对复杂推理进行有效建模，以及能把常识和外部知识（比如知识库）有效利用起来的深度学习网络，是目前很有意义的研究课题。另外，目前基于深度学习的阅读理解模型都是黑盒的，很难直观地表示机器进行阅读理解的过程和结果，因而可解释性的深度学习模型也将是很有趣的研究方向。

其次，人类理解文本的能力是多维度的，**结合多任务**（尤其是阅读理解相关的任务，例如阅读理解之后进行摘要和问答）**的模型非常值得关注和期待**。更进一步，虽然SQuAD提供了比较大的人工标注数据集，如何有效且高效地使用未标注的数据也是非常值得期待的研究课题和方向。最后从任务上看，目前SQuAD的任务定义中答案是原文的某个子片段，而实际中人可能读完文章之后需要进行更复杂的推理、并组织新的文字表达出来。

“目前我们的算法基本都是抽取型的方式，未来**生成型的算法**也值得更多的探索和研究。另外，目前机器阅读理解关注的都是理解客观信息的能力，未来机器理解文字里面所表达出来的主观信息（例如情感）也是非常有趣并值得关注的方向。“韦福如说道。

### SQuAD简介

SQuAD 是由 Rajpurkar 等人提出的一个最新的阅读理解数据集。该数据集包含 10 万个（问题，原文，答案）三元组，原文来自于 536 篇维基百科文章，而问题和答案的构建主要是通过众包的方式，让标注人员提出最多 5 个基于文章内容的问题并提供正确答案，且答案出现在原文中。SQuAD 和之前的完形填空类阅读理解数据集如 CNN/DM[2]，CBT[3]等最大的区别在于：SQuAD 中的答案不在是单个实体或单词，而可能是一段短语，这使得其答案更难预测。SQuAD 包含公开的训练集和开发集，以及一个隐藏的测试集，其采用了与 ImageNet 类似的封闭评测的方式，研究人员需提交算法到一个开放平台，并由 SQuAD 官方人员进行测试并公布结果。





























---

