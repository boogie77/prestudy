---
layout: post
title: 人工智能
lead: 人工智能的最新突破
date: 2016-10-18T00:00:00.000Z
categories: 人工智能
tagline: 机器学习
tags:
  - 机器学习
  - 神经网络
  - 深度学习
  - 人工智能
---

模式识别：是目的，就是通过计算机用数学技术方法来研究模式的自动处理和判读。

机器学习：是一种方法，是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。

数据挖掘：是一种方法，从大量数据中自动搜索隐藏于其中的有着特殊关系性的信息的过程。

人工智能：是指由人工制造出来的系统所表现出来的智能。

# 深度学习：人工智能的最新突破

## 什么是人工智能（Artificial Intelligence）？

机器通过**学习而非编程**获得人类的视、听、触觉等功能，甚至进行记忆、推理、规划、决策、知识学习及思考等，即**习而知之**。

人工智能（AI）有一个定义，即把人工智能视为**研究与设计智能体**，这个智能体要能**感知环境**，要能**采取行动**，并**使自己成功的机会最大化**。所以它包括三个方面的内容：一是**感知**，二是决策----决策也就是**认知**，三是**行动**。首先很明确，现在人工智能是通过学习，而不是编程来实现的。

人的大脑里面肯定没程序，我们一定是通过学习，来获得视、听觉的能力，还有记忆、推理、规划、决策、知识学习与思考等，这些认知能力也都是通过学习而非编程得到的。总之就是所谓的**习而识之**。

人工智能的分类：

1. **感知智能**，即对人类**直觉（intuition）行为**的模拟，主要涉及人的视觉、听觉、触觉等，属于感知（perception）部分；
2. **认知智能**，即对人类**深思熟虑（deliberative）行为**的模拟，主要涉及人的记忆、推理、规划、决策与知识学习等高级智能行为；
3. **创造性智能**，包括人的**灵感和顿悟**，这一块显然还没有开始这方面的研究。

人工智能是一个影响面极广的**关键共性科学问题**，也是一个**战略前沿技术**，其任何实质性的进展均可推动人类社会及其现代化文明的整体进步，因此人工智能的研究意义与重要性，可媲美人类迄今进行的任何一项伟大的科学工程。

1950，计算机科学的先驱----**阿兰图灵**提出"**Can machines think?**"

## 人工神经网络

人工神经网络本身可看成是对生物神经系统的模拟或者近似。

两种不同的方式：

- 从**内部结构与生物实现机理**进行模拟，它涉及理论神经科学、神经生物学、神经解剖学、神经生理学、生物物理学、生物化学、认知科学与心理学等多个基础学科；
- 从**外部功能**加以近似，使其从输入输出角度获得与生物神经系统相近的某些功能，如检测、定位、识别、记忆、推理、规划、决策与知识学习等。

人工神经网络的发展里程可归结为"三起两落"

- MP模型（McCulloch and Pitts, 1943），目前的大部分神经网络都还在使用这种人工神经元模型。
- Hebb规则（Hebb, 1949）
- Perceptron感知机（Rosenblatt, 1957），这是第一种人工神经网络，因此Rosenblatt也被称之为"人工神经网络之父"。所以说，人工神经网络至今只有59年历史，而人工智能是60年历程。
- Adaline（Widrow, 1960）
- Cognitron认知机（Fukushima【日】福岛邦彦, 1975）
- NeoCognitron神经认知机（Fukushima【日】福岛邦彦, 1980）
- Hopfield（Hopfield et al., 1984,1986）
- BP（Rumelhart et al., 1985）
- Boltzmann机及高阶Boltzmann机（Hinton, 1984,1985）
- SOM（Kohonen, 1984）
- RBF（Sanner and Slotine, 1984）
- ART（Grossberg et al., 1986）
- FNN（Jang, 1993,1995）
- CNN卷积神经网络（LeCun and Bengio, 1995）
- LSTM（Hochreiter et al., 1997）
- ESN（Jaeger, 2004）

1970、2000年前后**人工神经网络置身寒冬**，在人工智能领域中是被边缘化的。

20世纪80年代出现的掀起第二次人工神经网络研究热潮的Hopfield网络和BP网络。在20世纪80年代中后期、90年代初期，人工神经网络也如同现在一样，那个时候非常热，也有无限美好的憧憬。当时各行各业都去做神经网络，不过与现在不太一样，都仅限于学术圈和研究机构，企业参与很少。后来发现这些神经网络并非想象那样，能力不行，做不了多少事情，因此神经网络研究一下又跌入严冬。

- 2006，深度神经网路取得突破性进展，**人工神经网络**的研究进入第三次复兴；
- 2012，以深度神经网络为主要标志的(弱)人工智能的最新进展，引起全球瞩目。因为和**大数据**结合，又考虑了**GPU硬件加速**这个计算引擎，所以真正取得了全球的瞩目。
- 2013，国际科技巨头**高强度深度**介入，这是人工神经网络前两次研究热潮中从没发生过的。

现在大家几乎天天都能看到各种人工智能的新闻，许多IT巨头都决心用人工智能重塑企业的产品线，实现企业产品结构的转型升级。未来2到5年，人工智能还将给我们这个世界带来更多深刻的改变和惊喜。

## 深度神经网路

2006年取得突破性进展，**人工神经网络**的研究进入第三次复兴

深度神经网络主要包括：

- 深度卷积神经网络（Deep Convolutional Neural Network, Deep CNN）
- 深度信念网络（Deep Belief Network, DBN）
- 深度自动编码器（Deep Auto-encoder）

现在这一轮复兴，跨国企业，比如目前做得比较好的Google（DeepMind、Brain）、Facebook、微软、IBM Watson、Amazon、百度等，全都进来了。还有一个趋势比较明显，就是企业逐渐成为人工智能研究的第一梯队，产业与学术研究的距离不断缩短，国内外都这样，非常明显。我举一个例子，现在许多公认的顶级国际会议论文都出自于Google、Facebook、微软这样的跨国企业，而并非高校和政府科研机构。

除了企业以外，还有两大国际学术研究中心，一个是以Geoff Hinton教授为领军人物的加拿大多伦多大学，另一个是以Yann LeCun教授为领军人物的纽约大学。事实上，人工智能领域有一个以Hinton为首的人工神经网络学派，主要包括**Geoffrey Hinton、Yann LeCun和Yoshua Bengio**，是全球深度学习研究的**三大灵魂人物**。

- Google（DeepMind, Brain）
- Facebook（FAIR）
- Microsoft（）
- IBM（Watson）
- Amazon（）
- 百度（大脑）
- 加拿大多伦多大学
- 纽约大学

具有完全监督学习能力的深度卷积神经网络发展至今，**Yann LeCun**居功甚伟。1987年LeCun取得博士学位，曾是Hinton的博士后，在AT&T贝尔实验室工作了14年，2013年12月9日受聘于Facebook，创建了著名的Facebook人工智能研究院（FAIR）。深度神经网络主要就是指**深度卷积神经网络（CNN）**，这是目前在某些垂直细分领域惟一能够达到人类水平的神经网络计算模型，其他如深度信念网络（DBN）和深度自动编码器，都达不到这样的高水平。

卷积神经网络的最初版本实际是由日本人福岛邦彦提出来的，当时叫认知机与神经认知机，20世纪70年代就有这个模型，目前卷积神经网络中的卷积、池化、感受野、ReLU等概念与激发函数在这些模型中就有了。1989年LeCun将误差反向传播引入神经认知机，使后者获得了监督学习能力。1995年和Bengio将其命名为卷积神经网络，2006年叫深度神经网络。他还创建了手写体数字识别数据集MNIST，2006年做到了0.39%的错误识别率，性能超过传统计算机视觉方法很多。

深度CNN具有强大的**分层特征表达能力**，而且特征是**自动学习**得到的，不是人工设计的，包括底层、中层、高层特征，而且通过感受野的提高可同时获得局部和全局特征。就某个特定的应用场景，结合大数据和人工智能硬件引擎，既然它的分类识别精度能够达到人类的水平，自然就可以进行工程产品的开发了。

深度CNN标志性的突破出现在2012年，Hinton带领他的两位博士生，在2012年的ILSVRC 比赛中获得了冠军。ILSVRC 比赛相当于什么呢？可以理解为计算机视觉物体识别中的"世界杯足球赛"，每年都举行。其训练与测试数据集ImageNet有1500万幅图片，涉及22000种物体的分类（2011年秋版本），如猫、狗、大象等等。他们当时使用了2块GPU加速，训练了一周，取得了15.3%的Top-5错误率。而传统视觉方法的最好结果是26.2%，2016年这个结果已经下降到**3.08%**，比人类的**5.1%**好了不少。创新之处就是**将深度卷积神经网络与大数据（1500万幅图片）和GPU Cuda并行编程结合**起来了。可以说由此++揭开了深度学习在计算机视觉、语音识别和自然语言理解中大规模研究的序幕++。

2013年开始产业界真正高强度深度介入。很多标志性的事件，比如说，

- 2013年3月**Hinton受聘于Google**（包括Google收购其3人初创企业DNNresearch）。
- 2013年12月9日**LeCun获邀受聘于Facebook**，创建并执掌Facebook的人工智能研究院。
- 2014年1月Google以5亿多美元收购Demis Hassabis的人工智能创业公司**DeepMind**，2年后该公司推出了引起全社会高度关注的**AlphaGo**。
- 2014年5月**吴恩达受聘于百度**，担任百度首席科学家等。

# 大数据驱动下的感知智能产品研发

**大数据驱动下感知智能产业的框架结构**：

- 一是应用层，也就是==人工智能+细分领域==，比如说无人驾驶、机器视觉或者语音识别；
- 二是技术层，==涉及模型/算法==（ConvNet），开源代码；
- 三是基础层，就是==大数据，计算引擎/深度学习芯片==。

**深度学习的市场图谱**，包括四个方面：

- 技术巨头
- 开源代码
- 大学研究
- 半导体公司----芯片，计算引擎

## 大数据

**大数据**：或称巨量资料，指的是数据规模巨大到**不能**通过目前的**i.i.d平稳随机分析方法**，在合理时间内达到撷取、管理与处理，并归纳成为数据应用与辅助决策的信息；**整体关联关系**而非因果关系；数据的统计分析或数据挖掘。

**什么是大数据**？我就说一个观点。我们说大数据通常体量巨大，一般不能用常规的统计学与平稳随机过程方法来处理，因为已经不满足i.i.d独立同分布假设了。而且通常只关注整体的关联关系，而不是因果关系。从这个角度来说，现在很多所谓的大数据分析都是炒概念，其实就是常规的统计分析或者说数据挖掘，不是真正含义上的大数据分析。

大数据是最近IT界最常用的术语之一。然而对大数据的定义也不尽相同，所有已知的论点例如结构化的和非结构化、大规模的数据等等都不够完整。大数据系统通常被认为具有数据的五个主要特征，通常称为数据的5 Vs。分别是==大规模，多样性，高效性、准确性和价值性==。

## 大数据的5V基本特征

1. **Volume大规模**：==数据体量巨大，从TB级别上升到PB级别==；"在本(地)机数据采集和处理技术能力不足以为用户带来商业价值"。
2. **Varitety多样性**：==数据类型众多==；"高度变异的信息资产，在生产和消费时不进行严格定义的包括多种形式、类型和结构的组合。同时还包括以前的历史数据，由于技术的变革历史数据同样也成为多样性数据之一"。
3. **Velocity高效性**：==处理速度快，1秒定律，与传统数据挖掘技术本质不同==，；"高速的数据流I/O(生产和消费)，但主要聚焦在一个数据集内或多个数据集之间的数据生产的速率可变上"。
4. **Veracity准确性**：==真实、正确、准确、精确==。"要做出正确的商业决策，当务之急是在数据上进行的所有分析必须是正确和准确(精确)的"。
5. **Value价值性**：==价值密度低，但商业价值高==；"像电信，金融，电子商务，社交媒体等，已经认识到他们的数据是一个潜在的巨大的商机。他们可以预测用户行为，并推荐相关产品，提供危险交易预警服务，等等"。

**真正意义上的大数据分析是什么呢**？五个V特别重要，数据体量巨大，从TB级别上升到PB级别；数据类型众多；价值密度低，但商业价值高，也就是数据中大量都是垃圾，垃圾里面找金矿，很少很少，去找这个东西，这个是不能用传统方法处理的，因为大部分是非结构化和半结构化数据。事实上，结构化数据用传统数据挖掘手段就可以处理，现在很多人其实干的是这件事情。与其他IT系统一样，性能是大数据系统获得成功的关键。

对深度学习来说有很多开源代码框架和工具集，比如谷歌的TensorFlow，加州伯克利的Caffe，Bengio的Theano，Facebook的Torch，微软的CNTK，都开源了，目的就是为了==形成一个人工智能产业生态==。

ImageNet有1500多万张照片，还有Caltech-101，Caltech-256，CIFAR-10，CIFAR-100，MNIST，US-PS，SVHN，还有人脸识别库LFW等等，这些都是公开的，而且公开的数据集也逐渐增多，但它们是属于研究性质的。

真正有价值的**私有大数据**，其重要性如同原油一样属于**战略资源**，被跨国企业拥有和贪婪追求，这个重要性特别大，国内外的差距在不断加大。

我们知道，深度卷积神经网络**采集与喂食的大数据越多，越能获得更好的直觉模拟**。现在需要更大的数据，这个模型真正的进展，数据越多越好，这个是以前完全不能想象的事情。举个例子，Google的无人驾驶汽车它的总行驶里程已超过241万km，还有特斯拉六个月就采集了超过7500万km的大数据，每天都在大量采集数据。

对算法公司来讲，无论是采用以前的传统计算机视觉还是现在的深度学习方法，企业最大的优势之一，就是它拥有的**大数据优势**，例如做ADAS产品的以色列标杆企业Mobileye。既然要做大数据，就要对它进行**清洗和标签**。为此一定要选择一个特定的应用场景，或者说一定要做一个非常细的划分，垂直领域里面还要有细分领域，这样才有可能得到各种工况、各种情形下的**完整大数据**，才可以进行标签等等。

在移动互联网时代，大数据的采集可以采用"**众集**"的方法，标签可以采取"**众包**"的方法，比如说现在Google有54辆车，已经开始考虑到大数据中潮湿情况怎么办，多雨情况怎么办，还有高温、多尘等等，商业化进程不断推进。

目前使用的**完全监督学习**的深度卷积神经网络有一个缺点，要求配合使用大数据。换句话说，要认识飞机，必须将全世界所有飞机的照片都给他看，包括不同气候条件下，不同时间段，不同地方与背景、姿态等等，都要给它看；做无人驾驶则必须要考虑到各种天气、各种道路、各种时间段的大数据等等。这是现在这个方法的缺点。==**人可不是这么干的**==。人要认识一个东西很简单，要他看两、三架飞机他就把所有的飞机都认得了。这就是小样本学习或者说是"**举一反三**"。

在大数据和计算引擎的驱动下，基于深度学习方法的视觉物体识别能力，在许多Benchmark评测中，正在达到或超过人类的水平，语音识别再过2-5年也能达到人的水平，文本理解也比过去飞速进步了许多，许多确实可以进行工程产品的开发了。

我们举几个例子，2012年以后深度学习成为**视觉物体识别**的主流方法，2014年以来，又成为**人脸识别**的主流方法；同时大数据成为性能提升的关键。在ILSVRC 比赛中，从2013年开始就再也没有传统机器视觉方法了，全部是深度学习方法；就这个问题，人的水平是5.1%，微软去年初的4.94%第一次超过人类的水平，去年底该比赛的冠军也是微软，错误率降低为3.57%，目前全世界最好的记录是Google的3.08%，都是企业取得的成绩，这种趋势非常明显，因为这些科技巨头才拥有高效的研发团队和计算资源。

人脸识别也是这么一个故事。针对LFM人脸识别数据集，**深度CNN超过了人类的识别能力**，香港中文大学的汤晓鸥团队第一次超过了人类97.53%的正确率。百度现在做的最好，99.77%，第二名是腾讯的优图，99.65%，第三是谷歌的99.63%，已经超过人不少了。

至于**基于深度学习的视觉物体检测与定位**，目前也可以做到**像素水平的分割**。例如，这是长颈鹿、斑马，进行像素水平的物体分割，再分类识别；**分类做的很好了，比人做的还好**。

还有一个标志性结果就是**把深度卷积神经网络与再励学习结合**起来，应用于**神经动态规划问题**。AlphaGo学术上就叫神经动态规划问题，这个问题很多年以前就有研究。现在唯一的区别就是有了大数据，有了深度卷积神经网络，所以叫**深度再励学习**。其实在AlphaGo之前，在去年2月份，Google的DeepMind就有了深度再励学习的结果，发表在《自然》杂志上，只不过没有引起那么大的社会关注。利用深度再励学习发展的深度Q-网络，用于玩Atari像素游戏。49种游戏里面，不是靠编程，而是靠学习的方法去建立深度Q-网络；这49种游戏，包括太空入侵者、功夫大师等等，学49种游戏，一个职业选手在那玩，它就在边上学，看屏幕上的像素和评分，输出是一个虚拟的游戏操纵杆；看像素怎么运动，打多少分？学完以后49种游戏里面，29种超过职业选手水平；这条线是人类水平，假设是100分"智商"，计算机的评分最高达到2500多，比人还玩得好很多，它完全通过学习的方法，这是与IBM深蓝不同的。AlphaGo这个也是发表在《自然》上，也是封面论文。这个事情我就不说了，因为全社会都在热烈讨论。把人类战胜了，而且以后看起来人类也很难再战胜它，因为它可以学习，每天都在学，很可怕。

总之，**深度卷积神经网络在量级上开始与生物神经系统，比如说皮层上的功能柱接近了**。已经有几十万个神经元，训练样本几亿、几十亿，未来可能还能达到上百亿的大数据，这个需要很强的计算硬件支撑。**神经网络的突触连接权最多已达到10亿**，微软的ResNet网络，深度为152层，甚至可以做到1000层；2万多种物体都可以识别出来，狗、猫都能认出来，叫出名字来，以后可以有更多种类的物体可以被识别，**实现更宽垂直领域的通用人工智能**。

现在看来，神经网络的发展历经"三起两落"，1970年、2000年前后是寒冬，什么事都做不了，在人工智能领域中被边缘化。现在一枝独秀，应该说主要是时代进步了，因为互联网时代我们才有可能**采集大数据**，然后**采用"众包"的方法做标签**。另外就是由于游戏的超速发展出现了强有力的GPU，**采用GPU分布式集群系统**后，才能为深度学习提供超强的计算硬件引擎。

深度卷积神经网络为什么那么好呢？因为它首先是一种**仿生模型**。但是必须指出，深度卷积神经网络，现在的方法是**完全监督学习的，这个跟人脑是不相同的**。人的大脑视觉皮层有两个通路，一个是腹侧通路管分类的，一个背侧通路是管定位的，应该说它们的学习是**半监督**的，LGN、V1等可塑性几乎没有。

另外，美国MIT麦戈文脑科学研究所用电极阵列完成的**猕猴高级视皮层实验**表明，生物系统的V4、IT皮层的特征映射图，与深度卷积神经网络非常接近，令人叹为观止。总之，作为一种感知智能模型，深度卷积神经网络迄今最好地模拟了生物视觉通路，在大数据和深度学习芯片的强力支撑下，具有强大的**自动分层特征学习**能力，在上述列举的细分领域超过了人类的识别能力。大数据下的感知智能的发展为环境理解与自然人机交流、人机协作和人机共融的进步，带来了历史性的机遇与挑战。

"**大数据+深度CNN**"，这是实实在在的进步，确实可以鼓吹大家着手进行以完全监督深度CNN为核心的人工智能产品开发了。它**具有的达到人类水平的分类识别能力**，前面已经说了很多例子了，比如谷歌DeepMind的AlphaGo与DQN，谷歌ImageNet，IBM Watson，微软同声传译，百度IDL集成模型（人脸识别）和Deep Speech 2（语音识别）等等，都见证了深度CNN的强大能力，极有可能催生一场**弱人工智能革命**，重塑很多产业。

AI成为目前全球最热的投资风口，像无人驾驶、自动驾驶、消费类机器人、VR/AR、认知商业、聊天机器人、智能个人助理等等。总而言之，人工智能技术与产业开始扮演着基础性、关键性和前沿性的核心角色，但我们叫"**弱人工智能+**"，可以加很多东西进去。"弱"是因为**必须考虑特定的应用场景**，人工智能离全面达到人类的水平还差得远。

# 举一反三的认知智能前沿研究

认知智能前沿研究。这可能意义更大，但目前不适合进行工程应用。我们前面说过必须要用大数据把所有飞机给**深度监督学习模型**看，它才会认识飞机。我们人是小样本学习或者叫"举一反三"，看到两三辆汽车就知道这是什么东西了。

"**大数据+深度CNN**"的感知智能的方法，我们叫"**举三反一**"，或者叫**数据驱动的方法**。但是感知智能的进步，我觉得这个是实现智能模拟的一个基石。我们人为什么会有智能呢？我们一张开眼，眼前的一切物体都分类了，没有这种**"模式"识别能力**就谈不上进一步的**认知智能**。

以前的人工智能研究就卡在这里，这个叫**语义鸿沟**，一直跨不过去。感知问题没突破，数据到语义之间没有突破，只是在符号层次研究逻辑、推理等**"专家系统"**。从今以后，我们可以在这个基础之上，在新的起点上再做**语义水平的认知智能**研究了，所以现在相关的研究非常之多，也是非常激动人心的。

不过需要提醒的是，现在还是**前沿研究阶段**，未到做产品研发阶段。例如高考人工智能机器人、智能金融、智能医疗、智能新闻写作等等。还有IBM的沃森医生等认知商业。还有**想法向量**，更多种类的物体识别，比如说这是狗，各种各样的狗我都能认识，哪怕有遮挡，姿态发生变化，不同背景等。然后再把各种"概念"或想法向量联系起来，也是通过学习的方法进行时空递归，进行**长短期记忆和与记忆的交互式学习**等，不是通过编程。再加上注意力机制、记忆整合、通道整合等，还包括知识蒸馏、知识迁移。现在比较火的还有**长短期记忆网络（LSTM）**，这个网络是端到端的序列学习，它里面也有非常好的模拟，例如具有学习能力的神经元门控机制的模拟。

学习方法有三种：**监督学习**、**再励学习**和**无监督学习**。再励学习（reinforcement learning）也称强化学习或称增强学习，"再励"这个术语最初来自于心理学。你做出决策后跟环境交互，最后的结局你失败了或成功了，失败就要受惩罚，成功就要受奖励。人和动物的局部行为学习方式，就是这样的。这方面的研究很早就有了。

现在看来，**深度卷积神经网和再励学习**，这两个是成功的，它们的结合更成功。深度监督学习，大数据一定要有标签，选定细分领域这是有可能的，如果领域选大之后很难做到。AlphaGo有深度监督学习，也有深度再励学习，就是自己跟自己对弈学习，自己跟环境交互得到惩罚或者奖励。这样**通过与环境反复的交互，重演"长记性"**。

最重要的是==深度无监督学习==，这个现在还没有成功，这个也是大家最感兴趣的，更像人类"举一反三"的学习方式。如果这个突破以后，我们也许就不需要那么多的大数据了。大数据成本太高，而且很多情况下得不到。我们很多**技巧性或过程性的东西靠经验或与记忆进行交互式学习**，这种经验学习就是深度无监督学习研究的内容。

深度无监督学习是人工智能的=="黑科技"==。一个人看几辆火车，你从语义上告诉他这个东西名字叫火车，他就知道了，他就马上联系起来，全世界的火车他都认识了。实际上，你不会告诉他火车是什么什么物理特性，是什么什么外部描述，你告诉他火车这个"名称"就行了，所以它首先要进行无监督学习，然后才是跟语义结合起来，从而轻松地获得技巧和常识。

_不幸的是，这些研究结果都没有像深度卷积神经网络一样，具有一定的==脑科学基础==。_

==深度无监督学习、深度递归神经网络，包括长短期记忆网络（LSTM），在脑科学上都没有理论与实验依据==，所以很难说短时间内会出现**强人工智能**。我想一定是这样的趋势，先做弱人工智能，做图象识别、语音识别或者文本理解，再逐步把垂直领域扩大，变成一个通用人工智能，再扩大到全方位，此时什么能力都比人强了，它可以看懂、听懂，同时还可以替你做决策，替你做情感分析与交流，完全代替人，这种强人工智能，现在看来相当长一段时间之内完全不太可能实现。

另外，关于**人工智能是否能让机器拥有意识？**其实人脑是有奖赏机制或有这样的功能模块的。你做一件事情感到很愉悦、很幸福、很成功，这就是一个评价机制，这部分我就不展开了。总之，大脑里肯定是没有编程、没有符号、没有灵魂的，神经信息的载体是神经元的发放序列，同时它是通过学习而不是编程获得的感知与认知能力。

# 支撑人工智能应用的硬件引擎

最后再介绍一下**人工智能芯片**。前面已反复指出，大数据和人工智能芯片是两个基础点，可以说支撑了人工智能技术与产业的迅猛发展。前面的报告介绍了Hadoop、Spark和Petuum等高性能分布式CPU/GPU集群系统的研究。

作为支撑人工智能应用的硬件引擎，我想强调如下三个方面的应用：

- 一是**基于超级GPU或者TPU集群的离线训练**，这是必不可少的。比如说训练1000个小时、2000个小时，用了这个超算系统后10分钟可能就解决问题了，这是一定要有的，但这块主要依赖于GPU和TPU，功耗太高、成本太贵。例如2000块GPU大致需要1个亿的投入。
- 二是**基于云平台的在线应用**，这可以用FPGA来做，既可以降低成本，也可以大幅减少功耗。
- 三是**直接进行终端应用**。

在超级GPU或者TPU集群服务器方面，英伟达（Nvdia）的**深度学习芯片Tesla P100**，具有150亿个晶体管，运算速度达到21.2万亿次，研发预算超过20亿美元。利用P100构建的超级计算机DGX-1速度达到170万亿次。因为卷积神经网络本质上是张量（Tensor）处理，Google数据中心研发的**张量处理器（TPU）**，是它的秘密武器。它对CPU计算能力要求不高，是专门为深度学习定制的ASIC。无论是GPU还是TPU，我们中国企业的机会不多，技术门槛太高。实际上，GPU或TPU的成本太贵，功耗太高。**我们的机会就在FPGA上面**，也就是进行==基于FPGA的深度学习芯片（DPU）==的研发。相对于GPU。不但灵活度更高，成本很低，而且其能耗比可提升至少1000倍。对于基于云平台的在线应用或者移动端应用，拿FPGA来做，它的成本、功耗、体积都有很大的优势，==这或许是我们唯一能够做的事情==。

还有一类功耗更低，且更有前瞻性的是类脑芯片。包括两种类型：

- 一是利用传统CMOS工艺进行生物突触模拟，就是用几个晶体管去模拟突触连接权；
- 二是直接使用新型忆阻器件去模拟生物突触。 IBM的TrueNorth和高通的Zeroth是前一类神经形态芯片的典型代表。

IBM的TrueNorth，2014年8月发表在《科学》杂志上。它有什么特点呢？这个芯片里面有100万个发放神经元，模拟了2.56亿突触连接。人脑的神经元就是发放的，可以理解为很多个脉冲。以前觉得发放神经元没有什么用，现在发现由它组成的神经网络，功耗很低，**TrueNorth类脑芯片**才只有63个毫瓦！我们知道人脑的全部功耗只有区区20瓦，但皮层神经元的个数却有140亿。IBM最近还有一个实验，它使用48块TrueNorth芯片构建了一个小型数字化鼠脑，相当于有4800万个发放神经元，这个数字化的鼠脑可以进行深度学习，可以识别图片和语音，也可理解一些自然语言，还可通过在线增量学习以适应新环境。

除此之外，还有一个更新的、比IBM和高通类脑芯片功耗更低的**基于忆阻器的类脑芯片**。忆阻器也叫记忆电阻，是硬件模拟生物突触的理想方式。简单说，忆阻器随流经的电荷的变化其阻值就会发生变化，而且在断流时还具有阻值记忆功能。1971年提出忆阻器设想，2008年的时候惠普用纳米薄膜把它制备成功了。最新的结果是2015年加州大学等研制了一款**基于Crossbars的忆阻类脑芯片**，发表在2015年5月的《自然》杂志上。它的特点是集成度更高，读写速度更快，尤其是功耗会更低更低。当然前面和后面这两类人工智能芯片，技术门槛特别高，我们能做的事情可能不多。

# 结语

- 第一，==弱人工智能的产业发展正处于爆发期==，大家可以开始做工程化的应用产品开发了，深度卷积神经网络确实是非常大的进步，尤其是得到大数据和超强计算能力的支撑。
- 第二，**即使是深度卷积神经网络的一点点进步，也会给人类社会进步带来巨大的变革**。
- 第三，==**私有大数据和深度学习芯片是制胜的关键和法宝。**==

# 这是一场启蒙运动

**文艺复兴：改变人与人的关系**

- 人与人之间是平等的
- 解放人类思想，文化发展更具多样性
- 推进封建社会向资本主义社会的演进

**AlphaGo胜利：改变人与机器的关系**

- 人与机器之间是平等的
- 技术的突破，社会的发展具有无限的可能
- 推进人类与机器相互融入的新社会形态的形成

大多数医生看片子准确率是40%，专家到70%

# 人工智能的三个层次

- 将传统方法交给机器。
- 将答案交给机器记忆学习。
- 将目标给机器自我学习。

从移动时代走向人工智能的时代

其实最早的专家系统就是第一个，我们把规则交给机器，就是把计算机世界变成一个逻辑，告诉机器，这是原来的阶段。但是这个阶段里面重大的问题，我们自己会做，但是我们没法去教机器，我们不知道怎么描述的时候，这个机器就不灵了，而且教出来的徒弟永远是比人弱的，这是不够的地方。甚至我们在做一些学习系统，我们也要尝试告诉机器怎么去描绘一个实物，比如说做人脸模型，王小川长成这样，大家都认识，但是要描述出来，比如说脸很圆，这个事情也比较不靠谱。因此我们发现我们没法告诉机器。

有了深度学习的方法以后我们确实解决了一个问题，就是只告诉机器答案，我们给他的数据越原始越好，这件事情会使得程序员、工程师更容易应对专业的问题。因为它可以减少自己的专业背景，不用讲说我要去懂人，或者我要像医生一样懂得这个片子怎么看，他是拿数据训练的。所以在这样一个深度学习或者是人工智能发展过程中间，由于深度学习本身带来了好处，技术人员更容易进入到专业领域里面破解题目，这是技术本身。

但是对公司而言，公司的领头人一定是对行业理解比较深刻，对行业应用的时候必须很懂，这是我们讲的第二个侧面，我不用给机器方法，我给机器答案，机器自己找方法。AlphaGo代表一个趋势，我之前跟微软也在聊这方面，既不给你一个规则，也不给你一个答案，我把自己变成一个判断者，就像下围棋一样，围棋之前训练的时候，前三盘棋是把人之前的走棋方法告诉机器，机器就是跟人处于类似的状态。之后是机器人自己下，我也不知道哪个棋好不好，但是下完之后，人告诉机器这个结果是好不好的。人工智能又得到一个新的法门，答案都不需要知道，变得更加省事。

最近有一个消息应该是比较靠谱的，AlphaGo在今年内会跟柯洁打一场比赛，我跑去看了很多评论，以前是一边倒觉得人会赢，今天一边倒觉得机器会赢。在座的各位觉得柯洁会赢的有吗？还有是吧？这是缺乏判断力的表现。但是我会猜想Google会干什么新的事，不是简单地下棋。我有一个猜想，我认为这一次跟柯洁比赛的AlphaGo是没有经过那三千万盘棋学习的，因为之前是从KGS里面拿了人六段到九段的走棋，让机器在里面学习，这是跟李世石打比赛用到的。但是跟柯洁比赛我认为是新的，就是两个从来没有学习过的机器，然后告诉你赢了、你输了。把什么都不会的机器训练一个下棋的规则来，跟柯洁比。

如果是所料的这样就会非常好看，因为以前的机器是仿人的，甚至我们判断机器走棋走得好不好都是我们的经验去判断它。下棋的时候，头两局机器赢了，人输了，媒体的报道说法是中盘逆转，为什么叫中盘逆转？是因为前一半里面专家态度就是机器走得特别臭，走到一半的时候，发现机器越到中局的时候越好了。这个时候就觉得机器是翻转局面了。但是后来数据统计，包括Google自己说的，其实不是，在他们的视野里面，机器一直是领先的，只是以人的眼光觉得机器走得很差，以机器的眼光，它自己走得挺好的。所以我们对机器的理解是有限的，因此如果机器根本没跟人学过完全自己的经验，这次就会有很多新的方法出来。比如慕容复中原的武功学会，然后再去修炼，突然来一个西域的，或者没有跟中国比赛过的，没有学过围棋打法的，我们会遇到这样的一个问题。因此我内心中，是否用这个程序参加比赛是我的猜想但是Google尝试不用人训练机器，我蛮佩服的。就好像在重演一次人类的进化史。

# 从历史演变、技术发展、行业应用等角度，探索进击的人工智能

## 历史演变的六大纪元

依据 Ray Kurzweil 的观点，历史被分为六大阶段，不同阶段间的最大区别在于处理信息的方式发生了彻底的改变。

越高级的阶段，处理信息的方法就越高级，推演至下一阶段的速度也更快。

![历史演变的六大纪元](http://image.woshipm.com/wp-files/2016/11/VPZTpf3I2XvMPtAY1MbB.png)

### 第一纪元：物理与化学

一百多亿年前，致密炽热的奇点大爆炸诞生了宇宙。

其后几十万年，原子形成，产生了物理形式的信息存储和传输。

又经过几百万年，分子出现，信息可以通过化学方式进行存储和传输。

### 第二纪元：生物与 DNA

几十亿年前，出现了以碳元素为基础的有机物。

有机物的出现加速了生命的诞生，此时，信息通过 DNA 进行处理。

### 第三纪元：人脑

DNA 逐步进化，出现了更高级的信息处理工具：人脑。

人脑不仅可以完成信息的存储和传递，还可以对信息进行抽象和推理。

### 第四纪元：技术

随着时间的推移与技术的发展，人脑进化的速度比机器进化的速度慢。

机器智能迟早会替代人脑，成为信息处理的主要方式。

### 第五纪元：人类智能与人类技术的结合

人类智能与机器智能充分结合，人类的智慧、情感、记忆与意识将转化为数据，在计算机间存储和转移。

这使人类超越肉体的限制，获得永生。

### 第六纪元：宇宙觉醒

当人的存在变为一套数据，那么只要将这套数据传输给另一个星球上的驱壳，就相当于完成了星际旅行。

人类智慧将在宇宙中广泛传播，想去哪里就可以去哪里。

## 人工智能进化的三个阶段

依据历史纪元的划分，我们正处于第五纪元，并在加速向下一纪元转变。

在部分人看来，人工智能离我们的生活还很遥远。但是，2014年英国皇家学会举办的会议中，图灵测试第一次被通过了。

从某种意义上而言，这预示着人工智能时代即将来临。人工智能不断发展，当人工智能具备了推理和感知能力，取代人类的那一天就不远了。

人工智能究竟经历了怎样的发展，让其具备了取代人类的能力？要回答这个问题，需要从人工智能的前世今生说起。

### （1）人工智能的历史：提出概念

1956年，杰出的计算机科学家们在美国东部城市达特茅斯召开了会议，首次提出了“人工智能”的概念。

在这次会议中，首次决定将像人类一样思考的机器称为“人工智能”。

此后，人工智能就一直萦绕在人们的耳畔，经历了若干次的浪潮与低谷。

最先走入人们生活的人工智能技术是推理与搜索，而最早的人工智能产品便是人们熟知的搜索引擎。

凭借强大的推理和搜索能力，早期的人工智能可以轻易求解迷宫问题，疑难定理的证明，甚至人工智能还能赢得专业的国际象棋比赛。

这些人类都需要花费很长时间才能理清并解决的问题， 对于计算机来说非常容易，只需预先设置好规则和约束，计算机就能根据这些定义去破解问题。

可是当面对没有确定性规则的问题时（比如：面对多家企业的Offer，选择哪份？不小心着凉了，如何快速康复？），早期的人工智能就无能为力了。

### （2）人工智能的现况：突破瓶颈

早期的先驱者们梦想着设计出具备人类思维和人类智慧的机器，那么如何判断机器达到了与人类同样的智能呢？

其方法为“图灵测试 ”。

图灵测试的方法是，测试者和测试对象进行对话，测试对象为人和人工智能机器。如果测试者无法区分谁是机器谁是人，机器便通过了图灵测试，那么就认为机器具备了人类智能。

![图灵测试](http://image.woshipm.com/wp-files/2016/11/J61j9eplYFnbuROtYpZW.png)

如何才能让人工智能解决生活中的现实问题？例如，人工智能取代理财顾问，为我的投资理财出谋划策。人工智能代替医生，在我身体不舒服的时候，为我开出药方。

专家系统的诞生提供了解决方案，所谓专家系统就是模拟人类专家的决策过程。比如医疗诊断系统，会比专业的医生诊断的更好。

人类的决策过程不完全基于明确的逻辑规则，经验在某种程度上能够帮助人类做出决策。

人们在看病时倾向于选择专家，就是因为专家们阅历丰富，见识的病例多。在判断病情时，能够依据过往的经验，做出正确的判断。

专家系统的数据库中会装载大量的相关知识，这样就可以依据预先录入的规则，对现实问题进行处理。

![专家系统](http://image.woshipm.com/wp-files/2016/11/CCMaRTqdAryHcKWBn2Ed.png)

但是，人类的知识和规则是无法穷举的，如果都要事先描述知识，再定义规则，这无疑是十分困难的。

例如，心情不好。这类常识性问题对计算机来说难度很大。“心情”涉及到人类的身理特征和心理知识，“不好”究竟是何种程度？是痛不欲生还是突发伤感？

### （3）人工智能的未来：走向繁荣

以上提到的人工智能，均属于弱人工智能的范畴，只需给计算机提供足够多的知识，它就能完成特定的任务，甚至比人类完成地更好。

但弱人工智能仅仅实现了人类智能的一小部分，知识范畴以外的任务就无法胜任了。

随着互联网的发展，积累了海量的数据，“机器学习”登场了。从广义的角度看“学习”，其主要目的是进行区分，并对事物进行判断和识别。

机器学习最基本的做法是使用算法来解析数据，然后从中学习，接着对真实世界的事件作出判断和决策。

与传统的为解决特定任务、采用硬编码的软件程序不同，机器学习需要使用大量的数据进行训练，通过各种算法来学习如何进行正确的区分。

机器学习的算法包括决策树学习、推导逻辑规划、聚类、强化学习和贝叶斯算法等。

垃圾邮件的识别就属于机器学习（贝叶斯算法）的典型应用。首先需要搜集大量的垃圾邮件和非垃圾邮件，建立垃圾邮件库和非垃圾邮件库，然后提取其中的特征量，并对邮件进行识别和匹配。特征量的选取，在很大程度上决定了判断的准确性。

计算机视觉领域也有同样的工作，比如，要判断图像中的动物究竟是老虎，还是狮子，或是藏獒，也需要从图像中找到这些动物的特征量。

但计算机不能做出选取特征量的判断，只能依赖手工编码来完成。

随着时间的推移，深度学习的出现改变了一切。深度学习以数据为基础，由计算机自动生成特征量。

以人工神经网络为基础，从 Youtube 视频中寻找猫的图片便是深度学习的代表作。

人工神经网络的简要原理如下：

> 将一张图像拆分为图像块，输入到神经网络的第一层。经过第一层神经网络处理后，数据被传输到第二层，第二层完成处理后，再将数据传输给下一层。以此类推，直到最后一层，输出结果。

神经网络中的每一个神经元都为它的输入分配权重，权重与输出的结果直接相关。神经网络的输出是一个概率向量，80%的可能性是猫，15%的可能性是狗，5%的可能性是鱼。结果的正确与否由网络结构告知神经网络。

同时，神经网络的结果容易出错，因此它需要训练。需要海量的数据进行训练，直到输入的权重被调试的非常精确，无论在什么情况下都能给出正确的答案。

要想在 Youtube 视频中“学习”到猫的图片，先将数据输入到计算机中，在低层级神经网络中，识别出点和线。

接着在下一级网络中，识别出圆形和三角形等简单图案。

由这些简单图形的组合，便能得到特征量。大圆（脸）里面包含两个小圆（眼睛），两个小圆中间有一段曲线（鼻子）。

这样，高层级的神经网络中便出现了类似“脸”的东西，有猫脸，有狗脸，也有猴脸等等。

再往上，结合其他特征量，神经网络便能识别出猫的图片了。

之所以是深度学习，这里的“深度”就指的神经网络中众多的层。

![人工神经网络识别系统示意图](http://image.woshipm.com/wp-files/2016/11/Q1uQWBli4lDrdQyQiubg.png)

深度学习是人工智能的大脑，在某些应用领域中甚至比人类做的好，被认为是实现强人工智能的必由之路。

## 奇点来临的前奏曲

在宇宙中，黑洞中心是奇点。黑洞的体积为零，密度无穷大，以至于连光都无法逃脱黑洞引力的束缚，在黑洞中现有物理规律全部失效。

![黑洞](http://image.woshipm.com/wp-files/2016/11/vZPOhwq4nGR7LUBZ5YAh.png)

> 在数学上，函数 f(x) = 1/x 成立的前提条件是 x ≠ 0。

参考下图，从右至左，随着 x 接近于 0 ，函数值接近无穷大。

x = 0 称为此函数的奇点。

![数学奇点](http://image.woshipm.com/wp-files/2016/11/WdzBYTsOH9OlqFSaNKFg.png)

在人工智能中，所谓奇点，指的是人工智能可以自动地制造出超越自身能力的新人工智能的那个时点。

一台计算机能够设计出比自身更优秀的计算机，一个程序能够产生比本身更强大的程序，一段算法可以进化出更先进的算法。

广义而言，奇点意味着人工智能全面超越人类的时刻。

自计算机诞生之日起，就保持指数增长，摩尔定律中提到的18个月的周期，正在缩短。而人类智慧进化较慢，几万年来也未必增加两倍。

![当人工智能超越人类智慧](http://image.woshipm.com/wp-files/2016/11/VQpPDhOyDhd8Hd4Ev9pE.png)

不如自己的东西，生产复制地再多，也无法超越自己的能力。但如果能够制造出超越自己的东西，哪怕每次只超出了一点点，经过多次进化迭代后，人工智能就能制造出比自身更聪明的东西。经过无限次循环，人工智能便能超越人类智能了。

举例：0.9 比 1 只少 0.1，1000 次方后的结果约等于 0 ，而增加一点点， 1.1 的1000次方就是非常大的数字了。

![数字的迭代](http://image.woshipm.com/wp-files/2016/11/NmPBClGLDQHQzaGLdpRT.png)

你可能会困惑：人类发明的人工智能最终能够超越人类的智慧吗？试着思考下面的问题：汽车是人类制造的，其速度超越了人类双脚的速度。飞机也是人类发明的，将没有翅膀的人类送上了天空。所以，人工智能超越人类智慧是有可能的。

所有的技术，包括人工智能在内，本质上都来自于自然。

技术早于人类出现。鸟类会采集树枝构筑鸟巢，猩猩会使用石头砸开坚硬的果实，蚂蚁会有组织有分工地搭建庞大的巢穴。

科技的进化与自然的进化相似，奇点来临的那一天，科技体会进化为独立的生命物种。

也许最终的结局如《奇点临近》中所描述的那样，人类作为数据存储于计算机中，与人工智能共生。

### **参考文献：**

1. 《奇点临近：当计算智能超越人类》，Ray Kurzweil
2. 《人类简史：从动物到上帝》，尤瓦尔 · 赫拉利
3. 《人工智能狂潮：机器人会超越人类吗？》，松尾丰
4. 《智能爆炸：开启智人新时代》，王汉华，刘兴亮，张小平
5. 《人工智能时代 : 人机共生下财富、工作与思维的大未来》，Jerry Kaplan
6. 《智能时代 : 大数据与智能革命重新定义未来》，吴军
7. 《技术元素》，凯文 ·  凯利
8. 《科技想要什么》，凯文 ·  凯利


# CMU机器学习系负责人Manuela Veloso：人工智能与人类的未来是共生自主

在 2021 年之前，我们日常所用的软件将会具有很大程度上的智能和能力，并将会在越来越多的任务中取代人类。难道我们就要就此落后了吗？

尽管有一些人预测会出现大规模的失业和人类与人工智能之间的全面战争，但其他人并不认为未来有那么糟糕。卡内基梅隆大学机器学习系负责人 Manuela Veloso 教授设想了一个人类与人工智能密不可分的未来，它们将同心协力持续不断地交换信息和目标，她将其称之为「==共生自主（symbiotic autonomy）==」。在 Veloso 眼中的未来里，我们将难以将人类代理和自动化助理区分开——但不管是人还是软件，如果没有彼此，就不会有很大的用处。

Veloso 已经在 CMU 的校园里面测试这个想法了。他们打造了可移动的、赛格威一样的机器人 cobot。它们可以自动将客人从一栋建筑护送到另一栋建筑，而且当它们短缺时它们会请求人类的帮助。这是一种新的思考人工智能的方式，并且可能会在未来五年里带来深远的影响。

日前，The Verge 在匹兹堡对 Veloso 进行了一次专访，谈论了**机器人**、**编程自发性（programming spontaneity）**和**人工智能给人类带来的挑战**。下面是采访内容：

#### 问：自动化是过去五年里的一个大趋势。我们也看到有更多的智能被构建到了我们已经在使用的工具中，比如手机和计算机。你对未来五年的发展怎么看？

**答：**在未来，我相信**会出现人类与人工智能系统的共存，并有希望会造福于人类**。这些人工智能系统将涉及到处理数字世界的软件系统，也将涉及到在物理空间中移动的系统，比如无人机、机器人和自动汽车，另外还会有处理物理空间的系统，比如物联网。

你也将在物理世界中有更多的智能系统——不只是你的手机和电脑，而是我们周围的各种物理存在，它们能处理和感知这个物理世界，并帮助我们进行涉及到大量物理世界的特征的决策。随着时间的推移，我们还将看到这些人工智能系统还将会对更广泛的社会问题产生影响：比如**管理大城市的交通**、做出关于**气候的复杂预测**、**在人类进行重大决策时提供支持**。

#### 问：目前，我们可以看到有一些系统并不好。当一个算法或机器人进行一项决策时，我们并不总是知道它们为什么要这样决策，这让它们难以得到我们的信任。技术可以如何解决这个问题？

**答**：我正在研究的一件事是让这些机器能够解释它们自己——对它们做出的决定负责和透明。我们做的很多研究是让人类或用户询问该系统。当我的 Cobot 到我的办公室稍微迟到时，我可以说：「你为什么迟到了？」或「你选择了哪条路？」

所以我们正在研究这些人工智能系统**在学习和提升时解释自己的能力**，以便提供不同详细程度的解释。我们想通过与这些机器人交互从而让人类能够更加信任这些机器人。你就可以问：「你为什么要那样说？」或「你为什么推荐这个？」

提供那样的解释占到了我现在的研究的很大一部分，而且我相信能做到这一点的机器人能够为我们提供对于这些人工智能系统的更好的理解和信任。最终，通过这些交互，**人类也将能够纠正这些人工智能系统**。所以我们也在做尝试整合这些纠正的研究，让这些系统能够从指令中进行学习。我相信这会是我们与人工智能系统共存中的很大一部分。

#### 问：你认为为什么这些系统现在会提升这么快呢？在过去 50 年的人工智能研究中，你觉得是什么在拖我们的后腿？

**答**：你必须理解，对于一个人工智能系统而言，要知道什么是手机、什么是杯子、一个人是否健康，它就需要知识（knowledge）。早期的人工智能研究实际上是**获取知识**。我们不得不求助于人类。要人类将信息收集起来并人工录入到计算机中。

神奇的是，在过去几年来，这些信息越来越数字化。看起来这个世界通过互联网显现了出来。所以现在人工智能就是关于**可用的数据，以及处理这些数据和理解它的能力**，我们仍然在寻找最好的做这些人物的方法。另一方面，我们很乐观，因为我们知道数据已经有了。

现在的问题变成了，==我们如何从数据中学习？你怎么使用它？你怎么表征它？你怎么将这些碎片结合到一起？==那就是你用深度学习和深度强化学习做自动翻译的系统和能玩足够的机器人的方式。所有这些系统之所以成为可能，是因为我们可以远远更加高效地处理所有这些数据。我们不再必须执行**收集知识和表征知识**这些大步骤了。就是这些。

#### 问：过去五年最大的发展之一是类似 Siri 和 Alexa 的个人助理，它们都是由机器学习驱动的。我想知道你怎么看待这些系统在过去五年内的变化？

**答：**你知道，我是 Alexa 的大粉丝。我家里就有一个，大部分时间我与 Alexa 所谈论东西变得越来越广泛。在一开始的时候就是「天气怎样？」现在我会问「我的日历上有什么安排？」Alexa 在学习，我也在学习 Alexa 能做什么。它到底能够随时间变得多好，这会是很让我惊喜的。

我告诉你一件有趣的事：当我离开家的时候，我告诉 Alexa：「Alexa, stop.」我想停止它正在播放的音乐，因为我要离开了。但如果我告诉 Alexa：「Alexa, I'm leaving」，它就无法理解「I'm leaving」意味着它应该停止了。我必须明确说出「stop」才行。所以我设想个人助理会越来越能明白这样的指令：「Alexa，当我离开时，意味着你应该停止播放音乐。」这样的指令应该被提到研究日程上。

#### 问：你认为我们会达到这样的程度吗：我们可以问个人助理「我车子里的检查引擎指示灯亮了，我可以开这辆车吗？」或「谷歌，我刚拿到了一份工作邀约，我应该接受吗？」？

**答：**我认为这是可能的。这种类型的问题是**决策问题（decision-making questions）**——假设你必须选择某个健康保险计划，但你被这些选择搞糊涂了。你可能会在你要睡觉的时候告诉 Alexa：「Alexa，你看看所有这些健康保险计划，还有那些我能够购买的汽车，或者我的孩子可以去哪些学校读书。」然后它就可以在晚上帮你编译一份报告出来。

大量的相关信息都是可以通过网络获取的。你可找到那些学校的所有特征，其他人对这些学校的评价。你能找到关于这些学校的博客和其它的选择。你可以有一个能收集这些学校的所有特征的人工智能系统——它们距离多远、得到了哪些评价……你可以进入一个关于你想从教育中得到什么的主页，而人工智能系统可以将这些信息聚集到一起。它们可以查看这些特征，它们可以从过去的经验中学习，它们可以处理所有的信息，根据你的指导和问题发送所有可用的消息，以一种你能更容易消化的方式呈现这些信息。因为网络上的这些信息非常繁杂，你根本不可能实时处理掉所有这些信息。

最后，你可能也会想有一个能告诉你它这样建议的原因的助理。你可能会问：「为什么你说我应该买这辆车？我真的不喜欢那个品牌。」我认为这是非常重要的一步，让人工智能在决策中支持人类，尝试结合和学习所有的信息，并且整合你可能给出的反馈。

#### 问：除了个人决策之外，这些系统还能做什么？

**答**：你可以想象这同样系统的一个版本可以用于科研论文。目前已经有很多的科研论文发表了，而且现在它们都在网上。你可以想象有一个人工智能系统能帮助研究者消化所有这些信息并找到他们感兴趣的东西。

这个人工智能系统将仍然是网络上的信息的一个产物。很多人正在研究信息——文本信息、图片信息、流图表、表格——尝试理解网络上有什么并最终推理对这些信息的需求。比如，机器学习里有一个叫做「主动学习（active learning）」的领域，其中我们推理出其中一些过程的图像不够，而因此你可能会想要增加更多的图像。

我设想会有能够识别缺少什么的人工智能系统，从而能够将网络上的信息点连接起来，并在有需要时请求更多的数据。你可以想象它可以问研究者：「如果你告诉我更多有关这些细胞与这种化学品的交互方式，我就能有一个更好的关于当前情况的模型。」

#### 问：你的共生自主思想的一部分已经体现到了 Cobot 中，对吗？这些机器人目前被放养在 CMU 的校园里，通过一套深度相机、WiFi 和 LIDAR 装置在计算机科学大楼里面导航。它们没有机器臂，所以对于很多简单的导航任务它们也会有麻烦，但你让它们很擅长寻求帮助。

**答：**是的，当我们意识到这些自动机器人也有限制时，我们也很吃惊。它们没法必须打开世界上所有的门，它们也不能理解世界上每一种口语。也许它们会随时间变得越来越好，但同样地，我相信人类也有限制——我说话有口音，我的网球打得没有其他人那么好——所以这些机器人也会有局限性。

我们很清楚这些机器人，这些人工智能系统最重要的一个特征就是**识别它们不知道什么、不能做什么和不能理解什么，然后才向人类求救。你能按下电梯按钮吗？打开一扇门？或拿些东西放在我的篮子里，这就是我们所称呼的共生自主（symbiotic autonomy）**。机器人能够对那些它不能做的、不知道的或不理解的问题自主地向人类寻求帮助。这是一种新的思路，我们将有一些围绕在我们周围并将寻求我们帮助作为它们部分任务的人工智能系统。

当这种系统实现规模化时，共生自主会以更复杂的方式发生。系统已经能用无线交流了，它在云端交流数据，或获得远程团队的协助。你可以认为人工智能系统能和其它所有事物永远成为一个共生系统，比如网络上的信息、其它人工智能系统和旁边的人类或远处的人类。它成为一个独立运行的人工智能系统也是完全没有问题的，但是一个人工智能系统要意识到什么时候它不知道、什么时候它需要信息、什么时候该用一些概率来思考问题都是不确定的。它不能预先解决所有问题，但它能依赖于周围其他的帮助来解决，这也就是我所设想的。

#### 问：你怎样看待共生关系改变下已有的人工智能系统？

**答：**所以让我们返回去设想向人工智能求教怎样决策上哪所学校或投哪种健康保险。我猜想这些人工智能系统将在某种情况下需要一些人类没有提供的信息。**人工智能系统也将意识到如果它们知道那些额外的特征，这将会帮助我们更好地决策**。

真正有趣的是**什么时候人工智能系统能自己认识到它们缺失了些什么信息。它们意识到是否能有更多的信息，是否能做一些明确的行为**，例如它们是否能够预订那家网上订不到房间的旅馆、是否能给你订一个离开会地更近一些的旅店。我真的认为这种能力是很重要的，因为我不打算知道需要做某些决策的所有信息。

现在我们用的 Uber、谷歌地图或 Waze 通常对路线的的规划已经是做得很不错了，然而 Waze 会反过来问你「你现在饿了吗？我能给你一条最短路径吗？你喜欢走这条岔路看看更美的景色吗？」**。如果智能助手知道我十分喜欢兰花、十分喜欢某种艺术那有怎么样？我只要稍稍地偏离路径，我就能看到更好的博物馆。它在路线规划中并不知道这些，如果知道这些，那么它一定会规划一条通过博物馆的路**。

#### 问：许多现在的人工智能系统专门从事某一具体的任务，如对象识别或路径优化，但是这就导致了十分孤立的专家系统。我很好奇为什么你想的是带领我们返回一种软件中更为泛化的智能。

**答**：通用人工智能问题是极端困难的，我也确信深度学习就是其要求的技术基础，深度强化学习也会为通用人工智能加把料。我们也在做许多这种理解迁移学习概念的研究。我们是怎样有这些算法的——是因为它们能够从事特别的任务，但同样还能学习更多其它东西吗？我们并没有真正理解人工智能，我们还不知道做很多的事情。按照算法与技术、泛化的方法和提供解释的方法来看，我们的人工智能还真正处于婴儿期，关于很多这些事情我们还束手无策。

我真的认为通用人工智能有一天能从聚合人工智能专家系统中诞生出来，就像 Minsky 描述的那样合并他们就成为了一种**心智社会（Society of Mind）**。你也可以用一些特殊目的的算法来解决特别复杂的问题，就像 Simon 和 Allen Newell 在人工智能刚开始研究时预测的那样。

所以通用人工智能是极其困难的，但因为现在这么多的数据它又是极其令人兴奋的。现在有很多人在使用电子设备并产生数据，而且越来越多的人在使用计算机、手机、Alexa 和 Uber，所有这些都给我们在研究通用人工智能铺平了道路。我们仍然还有很多研究要做，仍然不知道通用人工智能系统确切的样子，但是我们在一条正确的道路上。

#### 问：你曾经担心过这种不确定性吗？有一些担忧是当人工智能超越人类的智能，那么人类也将会灭亡。

**答：**我完全是一个乐观主义者，我认为我们所做的自主系统研究（包括自动驾驶汽车和自主机器人）都是要求对人类负责的。在某种意义上，这是和技术毫无关系的。技术会发展，但它是由我们由人类发明的。它不是从外星人那来的，而是我们自己的研究。==它是人类智能构思的技术，它取决于人类思维也充分地利用人类思维才产生==。

我很相信这将发生，之所以我很乐观是因为我看到人类已经意识到了他们需要很小心地研究这些技术，同样我也意识到了。但是最好还是投资于教育。把机器人扔在一边，它会持续变得更好，但是聚焦于教育，人们知道其他人、关照其他人、关心社会的进步、地球自然的发展和科学的进步。解决所有这些问题、治疗癌症、终结贫穷等。很多和人类相关的事都能使用这种我们正在发展的技术去解决。

在某种程度上，**人工智能的人文主义将最终能将我们凝聚到一起**，所以我是很乐观的。

# 机器智能时代将改变谁的价值？

## 就经济学而言，技术会导致某项输入成本下降，从而给相关输入造成影响。

> 编者按：技术总是不断演进，但是有一些基本规律仍然有效。利用这些基本规律对未来发展做出正确解读，无论是对个人的职业发展还是企业战略规划，或者投资趋势判断来说都至关重要。比方说，最近对机器智能的炒作非常厉害，但这个东西会对哪些事情产生有利影响，对哪些事情产生不利影响呢？加拿大多伦多大学罗特曼管理学院的三位教授用一个简单经济学原理进行了分析。

1995年被认为是“新经济”的开始。数字通信即将颠覆市场改变一切。但是经济学家总体而言对此炒作并不买账。这不是说我们没有意识到改变的发生，而是我们同时还意识到，旧的经济视角对于审视所发生的变化仍然有用。“新经济”的经济学可以从较高的层面加以描述：数字技术可导致搜索和沟通成本的下降，从而导致更多的搜索和更多的沟通，以及伴随搜索和沟通而来的更多活动。基本上是这么个情况。

今天，我们看到在机器智能方面也出现了类似的炒作。但再次地，作为经济学家，我们认为一些简单规则仍然有效。技术革命往往会导致一些重要活动变得廉价，比如通信成本或者信息查找。==机器智能基本上属于预测技术，所以经济转变将围绕着预测成本的下降而进行==。

机器智能的第一效应将会是降低依赖于预测的商品和服务的成本。这很重要，因为预测是包括交通、农业、医疗保健、能源制造以及零售等大量活动的输入。

一旦任何输入的成本出现大幅下挫，就会产生其他两方面非常确定的经济意义。首先，我们将开始利用预测来执行此前无法做到的任务。其次，作为预测补充的其他东西的价值将开始提升。

## 大量任务将被重新框定为预测问题

随着机器智能降低了预测成本，我们将开始利用它来作为此前从未做过的事情的输入。以半导体作为历史事例，这个技术进步领域导致了另一个输入——也就是算术成本的大幅下挫。有了半导体，我们计算的成本变得非常低廉，所以对于那些把算术作为关键输入的活动，比如数据分析和会计等也变得廉价了许多。然而，我们还开始利用新的廉价计算去解决此前未能解决的算术问题。摄影就是一个例子。我们从以胶片、化学为基础的解决方案（胶卷相机）转向了以数字化和算术为基础的解决方案（数码相机）。廉价计算的其他新应用还包括通信、音乐以及药物发现等。

机器智能和预测的情况也一样。随着预测成本下降，除了历史上面向预测的那些活动，比如**存货管理和需求预测会变得更廉价**以外，我们还会**利用预测来处理其他过去不以预测作为输入的问题**。

比如说导航。直到最近，自动驾驶仍受限于在仓库工厂等高度受控的环境下进行，得由程序员来预测车辆可能遭遇的场景范围，然后相应运用判断型的决策算法（比如说如果有东西接近车辆的话要慢下来）。把无人车放到城市道路去是无法想象的，因为在这样一个不受控的环境下可能的场景数量需要对接近无穷的判断语句进行编程。

的确是不可想象，直到最近情况还是这样。不过一旦预测变得廉价，**创新者就把驾驶重新框定为预测问题**。他们不再用判断语句来进行编程，而是让AI去预测：“==人类司机会怎么做？==”他们给汽车配备了各种传感器——比如摄像头、雷达、激光雷达等——然后收集了好几百万公里的人类驾驶数据。通过把车外配备的传感器的输入性环境数据与车内人类司机做出的驾驶决定（转弯、刹车、加速）关联起来，AI就可以**学习人类司机是如何对每一秒中有关环境的输入数据做出响应的**。此前自动驾驶问题并未被视为是预测性问题，但现在==预测已经成为无人车解决方案的重要组成部分==。

## 判断将变得更有价值

当基础输入成本直线下降时，这往往会影响到其他输入的价值。对于该输入的互补品来说价值会提高，而它的替代品价值则会降低。以拍摄为例，随着计算成本的下挫，与数码相机相关的软硬件组件价值会提高，因为需求增加了——我们需要更多的相机。这些组件是计算的互补品，是要跟计算一起使用的。相反，胶卷相关的化学品价值就要降低——因为我们的需求变少了。

所有的人类活动都可以描述为5个高级组成部分：数据、预测、判断、行动以及结果。比方说，因为疼痛去看医生会导致：

1. 拍X光，验血，监视（**数据**） 
2. 问题诊断，比如“如果我们进行A治疗的话，则预测会有X结果，但如果按照B来治疗的话，则结果预测为Y”（**预测**）
3. 权衡选项：“考虑到你的年龄，生活方式以及家庭情况，我认为你可能最好采取A疗法；让我们一起来讨论一下你对风险和副作用的感觉”（**判断**）
4. 按照A方案进行治疗（**行动**）
5. 完全康复，副作用最小（**结果**）。

随着机器智能的改进，人类预测技能的价值将会下降，因为**机器预测可提供比人类预测更廉价且更好的替代**，就算机器在计算方面所做的事情一样。但是，这并不会像很多专家所认为那样，给人类工作带来灭顶之灾。因为==人类判断技能的价值将会提高==。用经济学的语言来说，判断是对预测的补充，因此当预测的成本下挫时，对判断的需求就会提升。我们将需要更多的人类判断。

比如说，当预测很廉价时，就可以更频繁更便利的进行诊断，因此我们就会在早期阶段检测出更多的症状。这意味着在医疗方面要做出更多的决策，后者又意味着对伦理、精神支持等方面会有更大的需求，而这些东西都是由人来提供的。**判断与预测之间的界线没有那么明显**——一些判断任务甚至也可以被框定为一系列的预测。尽管如此，总体而言，预测相关的人类技能价值将会下降，而判断相关技能的价值将会看涨。

把机器智能崛起解读为预测成本的下降，并不能解答每一个与技术发展有关的具体问题。但这仍然有两方面的关键意义：

1. 预测作为一项输入其角色将扩展到更多的商品和服务上
2. 其他输入的价值会发生变化，这主要取决于那些输入对预测的替代性和互补性程度。这些改变正在来临。而经理们需要投资到判断相关能力的速度和程度将取决于这些变化到来又多快。

# 中科院发布寒武纪深度神经网络处理器是什么？

第三届世界互联网大会于2016年11月16日在浙江乌镇召开，并举办了领先科技成果发布会。其中中国最引人注目的就是中国科学院计算技术研究所发布了寒武纪深度神经网络处理器，听起来很高大上，那么到底这颗深度神经网络处理有什么过人之处？人工神经网络就是一种模仿生物神经网络结构特点的计算机算法，最基本的特征就是模仿大脑神经元之间传递模式，并对输入的信息进行快速处理。

而每一个神经元都自己独特的激励函数，用于处理计算来自其他相领的神经元加权输入值，并且用加权值神经元之间的信息传递强度来定义。人工神经网络算法最大不同是可以不断自我学习，通过大量样本数据进行训练调整传递加权值，改善自身拓扑结构，使得算法更加高效，广泛适用于人工智能领域，目前像是谷歌的Alpha Go、百度的语音识别和自动驾驶、阿里巴巴仿真机器人都是大量使用到人工神经网络算法。

如果用人话对人工神经网络进行概括性描述就是：非线性、并行计算、自适应、可学习、要大量训练。

但是如果采用通用型处理器进行深度神经网络计算就显得效率低下，中科院计算技术研究所的陈天石就举出一个例子，**谷歌与斯坦福大学合作，利用16000个处理器核构建了一个10亿神经突出的深度神经网络，耗时多日才完成猫脸识别**。

目前通用型处理器都是基于冯诺依曼结构，其存储和运算处理是分离的，**需要大量读写运行操作的深度神经网络，不可避免受到了传输数据带宽的制约，效率低下**。

另外随着科学技术发展，通用型处理器已经不能满足各式各样需求，走上了专用细分的道理，GPU负责图形处理，DSP负责信号处理，而神经网络处理器就负责各式各样的智能识别任务。
因此中国科学院计算技术研究所和寒武纪公司提出采用专门的硬件神经元，设计高速连接的专门的存储结构，采用适用于神经网络算法的专用指令集。开发了寒武纪系列神经网络处理器：**单核神经网络处理器结构的DianNao，超大规模神经网络的多核处理器结构的DaDianNao，面向多种机器学习算法的PuDianNao**。

最新推出的寒武纪-1A（Cambricon-1A）商用智能处理器，**集成到终端SoC芯片，每秒可处理160亿个虚拟神经元，每秒峰值运算能力达2万亿虚拟突触，性能比通用处理器高两个数量级，功耗降低了一个数量级**。

而最新开发的神经网络处理器指令集DianNaoYu则是参照RISC（精简指令集）设计思想，所有指令长度都是64bit，有效简化指令译码器的负担，减少功耗以及芯片面积。一条指令既可以完成一组神经元处理，优化了计算数据在芯片上的传输，模拟实验表明，**采用DianNaoYu指令集的深度神经网络处理器相对X86指令集处理器有两个数量级的性能提升**。

人工智能作为互联网下一个风口，寒武纪-1A处理器应该说很好适应了这样的场景需求，可以做到基于神经网络算法的语音识别、机器视觉、自然语言理解、视频图像搜索等等现今难以完美实现的需求，更有可能走入寻常百姓家的数码产品、电器、嵌入式终端上。

# 首枚光子神经形态芯片问世 运算速度快3个数量级

据《麻省理工技术评论》杂志网站近日报道，美国普林斯顿大学的科研团队日前研制出全球首枚光子神经形态芯片，并证明其能以超快速度计算。该芯片有望开启一个全新的光子计算产业。普林斯顿大学亚力山大·泰特团队的新成果是**利用光子解决了神经网络电路速度受限这一难题**。神经网络电路已在计算领域掀起风暴。科学家希望制造出更强大的神经网络电路，其关键在于==制造出能像神经元那样工作的电路，或称神经形态芯片==，但此类电路的主要问题是要提高速度。光子计算是计算科学领域的“明日之星”。

与电子相比，光子拥有更多带宽，能快速处理更多数据。但光子数据处理系统制造成本较高，因此一直未被广泛采用。

团队研制出的光子神经网络的核心是一种光学设备——其中的**每个节点拥有神经元一样的响应特征**。这些节点采用微型圆形波导的形式，被蚀刻进一个光可在其中循环的硅基座内。当光被输入，接着会调节在阈值处工作的激光器的输出，在此区域中，入射光的微小变化都会对该激光的输出产生巨大影响。

该光学设备的原理在于：**系统中的每个节点都使用一定波长的光，这一技术被称为波分复用**。来自各个节点的光会被送入该激光器，而且激光输出会被反馈回节点，**创造出一个拥有非线性特征的反馈电路**。关于这种非线性能模拟神经行为的程度，研究表明其输出在数学上等效于一种被称为“==连续时间递归神经网络(CTRNN)==”的设备，这说明CTRNN的编程工具可以应用于更大的硅光子神经网络。

泰特团队用一个拥有49个节点的硅光子神经网络来模拟某种微分方程的数学问题，并将其与普通的中央处理单元进行比较。结果表明，在此项任务中，光子神经网络的速度提升了3个数量级。

研究人员表示，这将开启一个全新的光子计算产业。泰特说：“==硅光子神经网络可能会成为更庞大的、可扩展信息处理的硅光子系统家族的‘排头兵’==”。

# 大自然是理解人工智能的最佳指南

我们可以将机器学习算法的不断进化看作类似生物学和工程学的交织发展。

> 编者按：纵观历史发展，技术学者也经常窥自然而研其道。对于AI来说，自然进化为我们提供了研究机器以及准备其未来发展的可借鉴框架。本文作者David Cheng是DCM Ventures的高级投资经理。

在现存的有机体中，进化是依靠基因不断变异，代际传承的结果。物竞天择，适者生存而不适者消亡。高度适应性是好事，但如果没有及时进化出腮，洪水一来，全军覆没。

而另一方面，工程是一种精心规划的过程，每一步扎实可靠以达到预期目标。随着人工智能的出现，我们可以将机器学习算法的不断进化看作类似生物学和工程学的交织发展。

为了更好理解这种对比（**自然进化与机器进化**）， 我们可以将机器学习中必需的数据集合看作「**自然环境**」，把训练步骤看作「**自然选择**」。训练过程可以是监督学习或无监督学习，强化学习，聚类算法、决策树或是不同的深度学习方法。

与自然进化高度相似的地方在于，==生物体赖以生存的环境相同，但以各自的方式解决了相同的问题，殊途同归==。鲨鱼和海豚最后会以相似生存机制存活，尽管它们有着完全不同的起源。同理，在机器学习中，经常用于图像分割的K均值聚类算法，实际上是获取了未分类的输入数据（通常为图像），然后输出高相似度的聚类，反复迭代直到得到预期的聚类群组（在K均值算法中，当迭代聚类中心不再发生改变，即群组相似度已达最高）。如果你将相同的数据给了十个人，让他们使用不同算法解决相同问题，他们很可能会采取不同手段但得到相同结果。大自然和机器解决问题的方法，在某种程度上，高度相似。

![大自然是理解人工智能的最佳指南](https://pic.36krcnd.com/avatar/201611/22030751/8bc113skbjt8yt7y.jpeg!1200)

对企业而言，这些为什么至关重要？

随着机器学习技术进入商业领域应用，企业面临着研究策略以安全并高效地实施这项技术的挑战。

- 纵观历史发展，技术学者也经常**窥自然而研其道**。以下是商业可以借鉴进化来理解人工智能潜在发展的几种方式:
- 趋异进化：大自然中，趋异进化指的是多种生物有共同演化起源，但是演化过程中不断分化，最终导致构造和功能不同。在人工智能中，乍看之下非常相似的问题，但即使在相关性极高的数据集中，用同源的几种算法很难得到相同结果。例如，即便使用ImageNet进行目标识别效果不错，并不意味着在视频识别和面部识别时依然奏效。
- 趋同进化：指的是自然界中两种不同演化起源的生物体，却有着相同的构造和功能。而人工智能中，留心观察就能发现，看似在处理不同类型数据集，本质上都在解决同样的问题。Google借助用户搜索数据优化了搜索引擎中的拼写检查。Google通过使用搜索关键词数据优化了检索的拼写检查。他们会时刻跟踪用户在查什么，当他们注意到数百万其他人拼写方式不同，就会建议你做出同样的拼写，贴心之举。
- 共同进化：在自然界中，可以看到捕食者和被捕食者、宿主和寄生者，互相影响，共同演化的现象。如果两个AI系统共同发展，有趣的事情可能会发生。网络安全公司正在研究机器学习解决方案，不断训练他们的系统去检测新的网络威胁。

眼下有大把的AI团队帮助人们提高工作效率，但这些应用还处于起步阶段，离人们的预期，还需要一次质变。或许最好的办法就是将AI放到我们已经能理解的语境中——进化。

这对AI来说再好不过了，自然进化为我们提供了研究机器以及准备其未来发展的可借鉴框架。同时，AI团队的领导者应该认真考虑AI发展战略，投资必要的人才和基础设施非常重要，以将他们的数据转变为变革性的解决方案。

# AI 的未来

我最近一直在想 AI 的本质到底是什么？后来我突然想到，既然 AI 的意思是人工智能，那么 AI 的极限就相当于是人。

也就是说，讨论 AI 的本质，直接拿人脑来类比就好了。那么人脑对于世界的作用我暂且分为三种：识别、判断、行动。

- **识别**，是人脑处理信息的第一步，比如我走在路上看到对面迎面走来一个生物，大脑首先会判断出来这是一个人。而这第一步也是现在大多 AI 公司在做的事情，也就是**图像识别、语音识别**等等。
- **判断**，是基于认识而产生的，根据迎面走来的那个人的穿着和表情等，大脑可以判断出这个人是否带有敌意。这就要比简单地识别更进一步。
- **行动**，是根据识别和判断而产生的结果。我识别出一个人走来，判断出敌意，那么大脑最终指挥产生我的行动：跑。

所以 AI 对我来说，就是这三个过程量的改进和组合。

如果说**人类的行为大都是基于经验**，那么 ==AI 的行为就是基于数据==。一个人的经验有可能不全、不准确、或受到各种外部条件影响，而数据是可以克服这些问题的。

所以 **AI 最终能够作用于任何存在大量数据、并且可以被训练总结成“经验”的领域**。那么越能够被量化、越年老越吃香的行业，越容易被 AI 取代。而且，数据本身也是存在规模效应或类网络效应的，所以未来在某个垂直领域内，成功公司的集中度也会很高。

此外，很多人也都提到过 AI 的场景问题。AI 的好处是它是一个新的维度，也就是说任何行业和公司都可以 AI+，但是 AI 的问题是==他的维度是一种对既有场景和模式的升级而不是革命==，所以要找一个适合 AI 创业公司的新场景就极难。

比如我们可以说携程通过 AI 能让人们更好地买到低价票，百度通过 AI 能让人们更好地找到所需信息，但很难说 AI 本身有太多 2C 的场景（至少目前看来 AI 个人助手还是一个非刚需的伪命题，而且技术的演进也远没到真的出现智能助手的时候）。

所以 AI 将更多是一个 2B 的场景，是通过技术帮助现有公司做的更好的一个事情。那么随之而来的第一个问题就是：

2B 场景下，已经有互联网巨头占领的领域，是否还有创业者的机会？互联网巨头自身的技术和人员储备会不如创业团队吗？（而且拥有大量数据的大公司本身就有更大的优势。）我觉得这个问题要打一个非常大的问号。

那么对于创业者来说，也许去为一些小市场或小公司加上 AI 更有机会？但紧随其后的第二个问题是，互联网巨头会不会开放自己的 AI 能力？根据最新的报道，Google 和 Amazon 都开始在自己的云服务之上增加机器学习能力的服务，本身公有云的布局和客户构成就是能够和 AI 最好地进行协同的，我相信这是大公司必然会走的一步。

所以基于以上分析，我觉得在 AI 领域未来会有三个结果：

1. 互联网巨头都会重拳布局，并且会开放自己的接口。AI 市场很大部分会像云市场一样，是被几家巨头瓜分的。
2. 当下的很多创业公司会被大公司收购，而且很多时候是**偏向人才和技术收购**。
3. 一些垂直领域的 2B 的 AI 创业公司才有机会，而且是越传统的领域越有机会，比如**教育、医疗、金融、政府机构**等。那么除了技术以外，这些创业公司对行业的理解和 BD 能力也是同等重要。


# 谷歌新目标——让计算机实现自我编程，自主机器时代不再遥远

开源代码这么多，把历史上的代码学习一下，很多编程场景可以自动化

多人对AI的想象都停留在应用层，而忽视了技术层AI也将产生颠覆——==让机器自己编程==。谷歌大脑、DeepMind、Facebook甚至Viv 都在这一方向上努力，发表了一系列研究论文。Venture Beat 作者 Lucas Carlson认为，机器自我编程其实离我们并不遥远，将很快实现。一旦机器做到这一步，在软件发挥重大作用的所有领域，将会经历一场颠覆性的变革。

想象AI 的未来是很有趣的：家庭服务机器人、亚马逊的智能家庭中枢（Echo）等设备将走进每家每户，还有无人机快递和更加精准的医学诊断。这些吸人眼球的消费应用充斥着公众的想象，以至于大家都忽视了AI对另一个领域的颠覆——软件本身的发展。

想象一下，**如果计算机自己能理解自己，它们可以做些什么**？用不了多久，计算机就能做到这件事。并且，我不是在描述遥远的未来，我说的是触手可及的现在，使用时下现有的技术就能达到。

迄今为止，机器学习的专家倾向于聚焦那些为特定任务开发的AI 应用，比如人脸识别、自动驾驶、语音识别甚至是搜索。但是，如果这些类似的算法能够在不需要人为帮助、解释或者干预的情况下，理解它们自身的代码结构呢？正如他们理解人类的语言和图像一样。

==如果代码开始对自己进行分析、自我修正并提升，且速度比人为的更快，那么技术的突破可能会来得更快==。由此带来的可能性是无止境的：医学的进步、更加自然的机器人、更智能的手机、更少bug的软件，更少的银行欺诈等等。

**人工智能具有解决软件开发中的一个古老问题的潜力**。代码编写或操纵其他代码的能力的概念已经存在了很长时间，一般称为元编程（它实际上起源于20世纪50年代末的Lisp）。它解决的难题，目前都还在人们的想象之中。

但是，现在人工智能让改变发生了。

使用人工智能，计算机能够理解一个软件开发项目从无到有的发展历史过程中的所有代码，并立即改进或者删除单独一行代码中的bug，不管是用什么编程语言。即便是一个缺乏经验的或者中等水平的程序员都能讲清楚让计算机自我编程的原理。由此，一个癌症项目的研究可能几天或者几个月就能完成，而不需要花费好几年的时间，这将带来显著的进步。

今天，这项最终将会带来颠覆性改变的技术尚处在萌芽时期，但是，它已经开始生长。比如，谷歌的TensorFlow机器学习软件，让每位程序员都能将神经网络直接融入到所开发的APP中，让APP拥有识别图片中的人和物体的能力。要把这些想法变成现实，你将不再需要一个博士学位。让业余人士也可以修正程序，这可能会成为AI发展历史上最大的突破。

## 谷歌的目标：大部分代码都不需要人为编写

国外著名科技记者 Steven Levy 今年 6 月在他刊于 BackChannel 的文章《谷歌如何将自己重塑为一家“AI 为先”的公司》（How Google Is Remaking Itself As A "Machine Learning First" Company）中提到，谷歌大脑负责人 Jeff Dean 表示，随着他和团队对机器学习了解得更多，他们利用机器学习的方法也更加大胆。“以前，我们可能在系统的几个子组件中使用机器学习，”Jeff Dean 说：“现在我们实际上使用机器学习来替换整套系统，而不是试图为每个部分制作一个更好的机器学习模型。”Levy 在文中写道，如果现在让 Jeff Dean 改写谷歌的基础设施，大部分代码都不会由人编码，而将由机器学习自动生成。

![](https://pic.36krcnd.com/201611/28074659/s1mg3k06vc78sjkr!1200)

> 谷歌的代码bug预测系统，使用一个得分算法，随着commits变得越来越旧，它们的价值越来越小。

认为计算机自我编程离我们还很远？如果我告诉你，一些大公司，比如谷歌，已经开始在内部的项目管理系统中尝试使用这一概念，你可能会觉得震惊。但是，**谷歌确实已经开发了一个 bug 预测程序**，==使用机器学习和统计分析，来判断某一行代码是否存在瑕疵==。谷歌工程师、W3C的联合主席 Ilya Grigorik 也开发了一个开源版本的 bug 预测工具，目前已被下载 2万次。



开源地址：[https://github.com/igrigorik/bugspots](https://github.com/igrigorik/bugspots)

另一个例子来自Siri 的继承者——Viv。Wired 最近的一篇报道中写道，Viv 不仅使用一系列的自然语言处理来实现语言识别， 还**基于英语词汇建立了复杂的自适应性计算机程序**。==代码自己写代码（Code writing code）==。由于被写入的代码是经过Viv的开发人员自己训练和专门化的，所以这里的“写代码”并不是我们通常所说的写代码的能力，但这确实是一个大的进步。

在这个方向上，另一个大的进步来自非专业领域。Emil Schutte 曾有过一句非常具有挑衅性的言论：厌倦了写代码？我也是！让Stack Overflow来做这件事吧。他分享了一个例子来证明这一概念，从Stack Overflow 的大型编程数据库中提取完整的工作代码，来提供完整的功能代码块，但是，这样得到的模块还是基于已经写好的代码。

## DeepMind 的尝试

实际上更早之前，DeepMind 团队开发了一个“**神经编程解释器**”（NPI），能自己学习并且编辑简单的程序，排序的泛化能力也比序列到序列的 LSTM 更高。描述这项研究的论文《神经程序解释器》（Neural Programmer-Interpreters），被评选为 ICLR16 最佳论文。

==NPI 是一种递归性的合成神经网络，能学习对程序进行表征和执行==。NPI 的核心模块是一个基于 LSTM 的序列模型，这个模型的输入包括一个可学习的程序嵌入、由调用程序传递的程序参数和对环境的特征表征。这个核心模块的输出包括，一个能指示接下来将调用哪个程序的键、一个经典算法程序的参数，以及一个能指示该程序是否该停止的标记。除了递归性内核外，NPI 构架还包括一个内嵌的可学习程序的键值内存。这种程序-内存的结构对于程序的持续学习和重用是极其重要的。![](https://pic.36krcnd.com/201611/28074700/4dfq8mywx5kdnh33!1200)

> NPI 与 序列到序列 LSTM 对不同长度的序列进行排序的准确率对比，最长序列含有20个数组。

NPI 有三个拥有学习能力的部件：一是**任务未知的递归内核**，二是**持续键值程序内存**，三是**基于特定领域的编码器**，这个编码器能在多个感知上有差异的环境中让单一的 NPI 提供截然不同的功能。通过合成低层程序表达高层程序，NPI 减少了样本复杂性，同时比序列到序列的 LSTM 更容易泛化。通过在既有程序的基础上进行建构，程序内存能高效学习额外的任务。NPI 也可以利用环境缓存计算的中间结果，从而减轻递归隐藏单元的长期存储负担。

不过，当时 DeepMind 团队并未使用无监督学习的方法的训练 NPI，其模型也只能学习合成若干种简单的程序，包括加法、排序和对 3D 模型进行正则化转换。不过，单一 NPI 能学会执行这些程序以及所有 21 个关联子程序。

## 田渊栋对计算机自我编程的研究综述

Facebook 人工智能实验室研究员田渊栋在他提交 ICLR17 的文章中，就有一篇研究了这方面的问题。

![](https://pic.36krcnd.com/201611/28074700/ctcl0j47wgl6ndr6!1200)

论文摘要：**构建能够通过自动推断（infer），将一组输入映射到输出的计算机程序仍是一个开放且极具挑战性的问题**。由于在可能的程序上存储着巨大的搜索空间，并且需要处理高阶逻辑（如 for循环或递归），所以程序进行归纳（induction）任务是很困难的。在本文中，我们使用 Hierarchical Generative Convolutional Neural Networks（HGCNN），自动根据输入/输出对生成程序。HGCNN 以层次式预测候选代码串，由此可以使用标准的搜索技术来构造程序。应当注意，该模型仅使用随机生成的程序进行训练，因此可被视为一种无监督学习的方法。我们证明，文中所提出的方法可以生成程序，从简单的 Swap 到更复杂的循环和分支（比如找到一串数组中的最大值）。我们还展示了使用该方法，在实现诸如 Bubble Sort 等嵌套循环程序时取得的不错结果。将 LSTM 等作为比较的基础，新方法的预测精度有了显著的提高。

田渊栋在《**深度学习没有解决的理论问题**》里表示，这篇论文将算法的输入输出的结果抽取特征后，送入卷积神经网络文献中，再层次式地生成图像的经典框架，生成一张二维图，每一行就是一行代码，或者更确切地说，是代码的概率分布。有了好的分布，就可以帮助启发式搜索找到正确的程序。而神经网络的训练数据，则由大量的随机代码、随机输入及随机代码执行后得到的输出来提供——基本不需要人工干预，算是一种非监督的办法。

同时，田渊栋还在后面补充：“等到今年的 ICLR 的文章一公布，随便翻一翻就找到了七篇计算机自动生成（或者自动优化）代码的文章。打开一看，引论里全在描述同样的动机。”

那这个动机就是什么？

“==让计算机自己写代码==”。

## 一旦机器可以理解自己，一场颠覆性变革将会发生

随着越来越多的这类技术变得成熟，机器将会在各种各样的任务上超越人类。那么，机器为什么不能理解自己呢？我想这只是时间的问题。并且，一旦机器做到这一步，你会发现，在软件发挥重大作用的所有领域，将会经历一场颠覆性的变革。

人工智能的核心挑战之一便是教会机器学习新的程序、从既有程序中快速地编写新程序，并自动在一定条件下执行这些程序以解决广泛种类的任务。在各种人工智能问题中，程序以不同的面貌出现，包括**运动行为、图像转换、强化学习策略、经典算法和符号关系**等等。

现在，机器已经能够自动执行越来越多的程序，而且现在开源代码这么多，如果把历史上的代码都学习一下，很多编程场景应该是可以自动化的，至少可以大大减少人工。人类程序员尤其是初级程序员的工作被取代的可能性，也越来越大。

# 凯文·凯利最新演讲：预言未来的12个趋势

**未来，人工智能的时代即将来临，这个趋势也可以说是认知的趋势**。这个词听起来很炫，但实际上的意思就是==我们应该如何变得更聪明==。外界对人工智能可能有一些固有的思维，认为它们会变得和人类一样聪明。

![](http://www.alibuybuy.com/wp-content/uploads/2016/04/91be5a216a20fbaa8e62d64b0e793f06.jpg)

> 凯文·凯利（KK）《连线》(Wired)杂志创始主编，对互联网的发展有着独到的预见性，其二十年撰写的《失控》至今依然十分畅销。2016年4月1日，在深圳湾新传媒发起，联合益田集团·玫瑰府邸主办，由南极圈&创业邦联合承办的第二届深圳论坛·聆听大师之“洞见由「必然」的未来”活动上，凯叔预言了未来的十二个趋势，而商机就在里面。

我所看到的十二个趋势，其实并不是什么新鲜的想法，因为过去20年中，这些都正在悄然发生，只是未来这些趋势将会更加明显，更加剧烈。这十二个趋势在未来将会渗透到我们的文化以及商业的各个方面中。如果要发现新的商机，就必须要关注这十二个趋势。

所有的产业都在向分散式结构靠拢，如Uber。

## 第一个趋势：形成／成为（Becoming）

大家可能会关注苹果、百度、腾讯这些大公司，但我今天关心的并不是这些一个个具体的大公司，而是一个大的潮流和趋势。

为什么我不关心具体的大公司，而关心趋势？

比如40年前，我们并不知道电脑将会发生翻天覆地的变化，价格会变得越来越便宜。如果有这样的一种意识，你就会创造出很多新的产品，这就是为什么我不关心具体的大公司，而要考虑宏观的发展趋势。

世界正在发生着翻天覆地的变化，==未来是未知的==，也就是没有所谓的专家，我们都不知道未来会发生什么。正是在变动和未知的情况下，现场的每一个人都有可能变成专家，并做出一些变革和创新。

**从层级化结构到网络化结构，这是一个变化趋势**。正因为网络的存在，我们在沟通方面创造了更多的可能。这个结构非常有效，执行会非常迅捷。在交流的时代，最有效的结构就是一个网络化结构。从三、四十年前发展至今，网络沟通的前进并没有结束，我们会继续发展下去，并创造更多的机遇，这种分散型的网络结构会刺激出更多的想象。那么我们如何做事情呢？可以通过这种分散式的结构实现创新，这将是一个长期的趋势。

在未来十到二十年，这将改变公司的角色，如果公司还保留之前的层级结构，就无法适应时代的要求，不能在市场中存活。新的企业文化会给公司企业带来影响，也会产生新的空间。公司可能感觉没有以前那么安全，没有以前那么确定，所有的事情都变得可以被质疑。

如果你想要快速实现一些事情，可以通过网络的手段实现。**集中式的结构是一个层级结构**，**分散式的结构是一个开放性结构**，这就是网络式结构的活力所在，大家可以在里面自由地创造。

在分散式的网络结构中，我们已经做了很多的事情，但仍有很长的路要走。未来会有更多新的事物，比如政府职能在分散式结构中会有所变，教育如何通过分散式结构推动自身发展等等。==变成分散式的网络结构是一个长期的趋势==。Ebay使用的是分散式结构，Uber也是如此。众筹也是一种分散式结构，你可以通过众筹来得到资金，会有不同的客户来支持你的创业。

你在使用谷歌的时候，通过搜索得到答案。另一方面，每当你输入一个查询词，点击一个搜索引擎生成的链接或是在网上创建一个链接，实际上是在训练谷歌的人工智能，你在给这个公司增加价值。谷歌每天处理亿次查询，就是在一遍又一遍地训练深度学习型人工智能。所有的产业都在向分散式结构靠拢，未来这个趋势会持续发展。

## 第二个趋势：认知（COGNITIVE）

未来，**人工智能的时代即将来临，这个趋势也可以说是认知的趋势**。这个词听起来很炫，但实际上的意思就是我们应该如何变得更聪明。外界对人工智能可能有一些固有的思维，认为它们会变得和人类一样聪明。

我的想法是：==它们不是和人类一样的智能，但它们能够帮助人类==。

像是iPhone里面的Siri，就是人工智能的一种。在安卓、微软，我们也有类似的系统，你提问它，就能得到答案。现在医院每天都使用人工智能，医院拍片使用的也是人工智能，它们不会累，能一直工作，并能准确的诊断疾病。

在法律方面，人工智能实际上可以整合各方面的信息，然后制作一份份文件，专业性不输于律师；在飞行过程中，人类通过人工智能进行飞机的操作，飞行员只需驾驶飞机七到八分钟，剩下的操作都交给人工智能；现在购买新车，车里面会安装个芯片帮助你刹车，它的刹车技术比任何人类都要强；未来人工智能甚至可以帮助人类诊断疾病，它的医学诊断技术和人类医生一样强。

### 三种关键的技术元素

现在所发生的科技变化，能帮助人工智能更快速的学习进步。在这当中，三种技术元素的发展加快了人工智能数量和质量的提升。

- 第一，**神经元网络**（通过模拟大脑神经元网络处理、记忆信息的方式，完成人脑那样的信息处理功能）。这是在20世纪50年代被发明出来，过去我们可能只是在几千个神经元当中实验，并不能得到理想的效果，但当我们把它扩大到几百万，甚至数亿量级的神经元时，就会有更大量的数据、更深层次的算法、更好的效果。
- 第二，**GPU芯片**（图形处理器芯片）。GPU芯片通常是游戏芯片，也可以用在AI（人工智能）领域，它有很大的价值。因为你可以通过这样一个小小的芯片，让人工智同时处理很多事情，而且这些芯片现在变得越来越便宜。过去，它的发展可能很慢，但随着科学不断进步，它的发展速度越来越快，蕴含巨大的商业价值。
- 第三，**大量的数据**。每种智能都需要训练，有大量数据才能进行预测或者是进行处理，大规模数据可以帮助人工智能变得更聪明。

### 未来人工智能可以做成服务进行售卖；

为什谷歌的AlphaGo能打败围棋世界冠军，这是我们之前没有想到的。这个芯片不仅能让我们玩游戏，还能让我们实现很多人工智能的效应，做一些我们做不到或者不愿意做的事情。谷歌现在训练人工智能，并不只是训练人工智能玩游戏，而是教它怎么玩游戏，教它如何自己玩游戏，培养它能够像人类一样玩好游戏。

生活中已经有很多东西比我们更机智了。比如说计算机、手机导航系统。像谷歌、[百度](http://newseed.pedaily.cn/company/20886)这样的搜索引擎，它们甚至猜测你想要问什么问题，即使你还没输入完你的问题，你只要问它两个字母，它就可以猜出你的问题是什么，它是可以预测和参与到你的体验当中的。这就是AI（人工智能），它的作用非常大，这些都是在后台运作的事情，对你来说是无形的。

**今天我们看到很多事物电力化了**，==而未来我们会把许多事物都智能化==。

未来十到二十年，我们所创造的人工智能将与人类不同。所谓的人工智能是像谷歌自动驾驶汽车，用AI（人工智能）来驾驶汽车。这种驾驶与人类完全不同，它们不会像人类一样会分心，它们在开车时专心驾驶，它并不会想到金融相关的问题，这也是我们要求它们做的事。

人工智能可以有很多种工作形式，我们可以和人工智能合作，或是创造出各种不同的思维形式。以前我们只有一种思维方式，那就是人类的思维方式，但我们现在想要它们和人类有完全不同的思维形式，这也是AI（人工智能）之所以能够帮我们的方式。不是说它们比我们更强大，而是**它们和我们的思维角度完全不一样**。

未来人工智能可以做成服务进行售卖，它可以通过电线把智慧传到你家里，像一个商品一样。150年前的美国，许多人通过把原有的事物电力化，创造了财富。比如，水泵加上电力服务，把它变成了一个电子水泵或者是电动的水泵，或者把洗衣桶变成了自动洗衣桶、电动洗衣桶，那就是洗衣机。**他们把原有的产品加上电力，创造了电力化这项服务**。

未来，人工智能可以作为一个商品来售卖，就像过去的电力一样传输，我觉得将会有数以万计的创业公司从事**把人工智能运用在某一个领域的工作**。接下来可能会有上万家企业都是用这种方式创业，这里有很大的潜力，你可以把某些东西加上人工智能，把零售业加上人工智能等等。

比如：照相机，我们把它人工智能化，间接的就好像有很多人在照相机里面为你工作一样，好像每天24小时都有数百个大脑在跟你一起工作。我认为这有非常巨大的潜力，并不意味着你一定要自己创造AI，而是你可以像购买电力一样购买智能系统，这与大家以往所想的不一样，AI会成为一种商品，大家都可以购买它。但我们得在这个基础上做一些改变，需要创造新的功能，比如在生态系统上，用不同的方式来使用这个商品，这也可以带来更多的创造性。

==对人工智能来说，使用的人越多，它就越聪明==。随着它越来越聪明，使用它的人就会越来越多，这是一个循环。

一家公司进入这个良性循环后，规模会变得越来越大，未来人工智能领域将出现两到三家巨型的寡头公司，大家都能从那儿得到服务。当然，我们会有很多类型的人工智能，我们也可以==用人工智能帮助人类创造更好的人工智能==，那么人工智能范畴就可以发展得越来越快。

### 人工智能将给人类创造新的工作机会。

我们之前对于机器人的设想是它看起来像人类，但这一点比较难实现。现在我们所看到的机器人手臂，虽然不像人类，但能够帮助我们装东西，这就很有用。我们把人工智能加入到这样的机器手里面，它会找出问题，然后解决它。它们**可以进行试错练习，它犯错误之后会记住，下次不会再犯**。

另外一种机器人，它有一个眼睛可以观察，你给它示范是怎么做的，**通过观察你的做法和过程，它就能进行模仿**。它有一个眼睛可以看，可以观察。这种机器人是有特殊程序的，它可以和人类一起工作，不会伤害人类，不像汽车工厂见到的机器人，它们装置汽车，身边不可以有人类，因为会伤害到人类。新的机器人，人类是可以跟它们一起工作的，未来我们将会和人工智能一起工作。旧的工作会遭到更新换代，但机器人也会给人类创造新的工作。

两百年前，70%的美国劳动力以农场为主，后来自动化实现后，机器代替农民，被替代的农民转向其它工作。那么农民去哪里找新的工作？他们可以成为健身房的教练，也可以做设计师，他们主要是用机械化来代替他们进行工作，他们可以从事别的行业。==人工智能取代了我们的工作，但也可以为我们创造新的工作机会==。对于任何需要生产力的工作，都会进行人工智能化。人工智能发挥作用非常大，因为机器人的工作效率非常高，它们被设计来就是做高效率的工作。

**对效率要求并不太高，需要有经验，需要创造力的工作适合人类做**。比如科学家做实验，这并不是效率要求特别高的工作，因为你的成果并不是特别多。艺术方面的工作也并不是效率要求特别高的，大家不是特别在乎你画这幅画花了多少时间，这些都和效率都无关，但效率要求高的工作就适合机器人来做。

我们去到现场听演出，好的演出价格越来越高，越来越有价值，这和效率无关。对效率要求不高的工作，我们会花费越来越多的钱，比如保姆工作，带小孩的工作，这些都需要经验，这是非常适合人类的。==未来，你的工资高低将取决于你能否和机器人默契配合==。配合得越好，你的工资就会越高。

总而言之，人工智能可以购买，可以使用，可以做任何事情，可以让我们有不同的想法。

## 第三个趋势：互动（INTERACTING）

我们创造的物质将会和我们进行互动，这就是第三个趋势。

### VR技术（虚拟现实）

以虚拟现实为例子(Virtual Reality，简称VR，**是利用电脑模拟产生一个三维空间的虚拟世界，提供使用者关于视觉、听觉、触觉等感官的模拟，让使用者如同身临其境一般，可以及时、没有限制地观察三度空间内的事物**)。过去的五个月，我试用了很多虚拟现实方面的设备，它在硅谷发展非常快，IBM也投入了做虚拟现实的产品，一些西装或者是手套，都可以和虚拟现实相关联。你可以虚拟现实里面观看，和周边的朋友交流，不管你在哪里，VR都能帮你实现这个需求。

### AR技术（增强现实）

通过AR技术（Augmented Reality，简称AR，**通过电脑技术，将虚拟的信息应用到真实世界，真实的环境和虚拟的物体实时地叠加到了同一个画面或空间同时存在**）。你能在一个空间里面见到虚拟的物品，甚至能见到一个虚拟的人，这些东西都能在你眼前切切实实见到。

**这是一种是进入式的体验，你感受到那些东西在你身边是确确实实发生的**，可能只是一个卡通，或者是一个虚造的东西，你感觉自己切切实实地处在另外一个环境。比如说你在看米奇老鼠这个电影，它丢了一个球，你可以看到那个球好像是从屏幕那边滚过来的，但实际上这并没有发生，你的大脑来拟造了球滚过来的现实。对于电影来说，它只是一帧一帧的画面，但你的大脑把它虚拟成了现实，==整个身体透过大脑有了身临其境的感觉==。

再比方说我站在台上，我身边并没有什么悬崖但透过虚拟技术，可以让你的大脑感受到这有一个悬崖存在，以为有很多人掉下去了，这种真实感是推动我们研究虚拟现实产品的动力。

1989年，我当时试用一个刚出来的虚拟现实产品，戴着手套，感受真的太真实了。我当时认为这肯定会改变世界的，但这个产品当时是要花100万美元购买的，还没有人负担得起。但现在这个虚拟产品得以实行，因为智能手机的出现，我们有了很多可以承载虚拟现实的设备，而且我们现在有很多屏幕的产品，你把它放在眼前就能感受到虚拟现实。手机里面的定位系统，过去也非常昂贵的，现在只需要几美元就能购买到了，手机价格也在下降。

我们现在已经能在手机上看电影了，这也是过去没办法实现的一个服务。虚拟现实，以前是需要几百万美元购买，现在则不需要了。智能手机之后，下一个平台是什么？那就是VR，就是虚拟现实，虚拟现实的各个类型。

你可能会看到有一帮人，他们一起用虚拟现实的产品。当你把眼罩戴上，你就身临其境，处在完全不同的地方，这是你在现实中完全不可能处于的环境，你可能觉得害怕或是兴奋，我试过很多不同的虚拟现实产品。

### MR技术（混合现实）

所谓的混合现实（Mix reality，简称MR，**既包括增强现实和增强虚拟，指的是合并现实和虚拟世界而产生的新的可视化环境。在新的可视化环境里物理和数字对象共存，并实时互动**），你戴上眼罩之后，你看看身边的环境，好像出现了新的虚拟物品或是人物，你感觉它真实存在那里一样，但其实只是虚拟现实，这个技术发展得非常非常快，它会像智能手机一样迅速发展，得到普及。这就意味着在未来，在家里你可能根本不需要有任何屏幕，你只要戴上一个眼罩，就有一个虚拟屏幕供你使用。

比如说，你可以在床上看电影，但可能并没有屏幕的存在。你在家可以办公，不管想要多少屏幕来工作或者生活，这都不成问题，因为虚拟现实都可以为你缔造。

你可以通过虚拟现实产品进行互动，进行娱乐。你戴的这个眼罩在未来会有很大的改进，它可能会变得更轻，更方便。**未来，你可以戴着眼罩可能在周围360度都能看到不同的东西**。未来，你可能会在整个房间都装上探测器，这个房间不用放置太多的家具，你可以在里面漫游，看到想看到的东西，玩想玩的游戏。同时，可以使用一些小技巧，让这个房间看起来更大。在房间里都装探测器，目前还没有办法方便地实现。

现在我们拥有一个大的互联网，里面非常多的信息，你们需要任何信息，都可以从互联网中得到。你可以在里面进行信息的互动，可以发信息给朋友。通过虚拟现实，我们将改造这个互联网。那些戴上虚拟现实产品的朋友们，他们不只是看到了这个体验，还能感受到体验，这就是这个服务真正的强大之处。在虚拟现实的游戏中，你会有你的视角，你就觉得你就是你在游戏里扮演的那个人。在微软，他们做过一个实验，让你感受你不是在操控一个人，你就是那个人。当这些游戏变成了你的视角，从而变得更加刺激。==从看见你自己在玩游戏，到你真正的以第一视角在玩游戏==。

我想跟你们分享一个例子，虚拟现实有多强大？你可以怎么用它？通过虚拟现实，我把我的身体转向90度，我体会到我其实是在走直线的，但实际上我可能只是在这个房间里面转来转去。通过虚拟现实产品，可以欺骗我的大脑，让我觉得一直走直线的。这意味着通过虚拟产品，可以模拟在爬山，或者说在户外做运动，但你实际可能只是在房间里原地走路。虽然你只是在房间里，但通过戴上虚拟产品的装备，你就可以体会到在大自然里面探索。

你还可以通过虚拟产品创造一个虚拟的人，你可以听到他们的声音，跟他们交流，你能真切地感受他们就在那里。他们可以跟你对视，跟你有视线交流，让你觉得他们是真实存在。几个月前，微软创造了一个虚拟的人，就是一个在月球上行走的宇航员，你戴上虚拟产品之后，你就觉得他们是真实存在的。

在几年前，虚拟现实还不能作为商业使用，但现在可以。你可以让机器人进到你不能进的地方，戴上虚拟产品，你可以确切感受到你是存在于那个环境里的。比如说你想体会在无人机里面的感觉，你肯定不能在那里，但你可以通过虚拟产品来达到这个效果。

苹果公司最近买了一个产品，它可以模仿你的表情创造一个假人来跟你交流。我觉得**虚拟现实最重要的是它可以成为社交媒体的一个载体**。当有其他人使用虚拟现实的时候，越来越多的人使用，将会把这个服务打造得更加完美，我们可以和其他人一起分享服务。不只是使用虚拟产品进入虚拟景观，我们还可以使用虚拟产品来分享物品。

## 第四个趋势：使用（ACCESSING）

“使用”这个趋势过去就已经存在了，但未来会变得越来越重要。拥有物品的性质将转变为：你不是拥有，而是使用这个物品。比如Uber优步，让你觉得不用车也可以使用车的服务，Facebook脸书网站也没有实体，阿里巴巴也没有实体，没有库存。这些公司自己售卖产品，它们并不拥有自己售卖的产品。产品从客户来，消费者扮演生产者，这造成一个结果就是：==使用权比所有权更加重要==。比如我可以从亚马逊买Kindle无限量礼包，随时可以下载我想要读的书。

==我们根据需求来创造经济，这就是未来的趋势==。我们可以通过互联网来实现，像优步这样的服务会渗透到各行各业。试想一下，一个行业原本是需要拥有它，才能享受它，变成现在不需要拥有，就可以享受了，你可以通过取得服务的这种方式来取代拥有这个实物的事情。

除了优步之外，你可以用App租一辆车，通过输入一个密码，就把车开走。你可以在上网说：我愿意花12美元去城市另外一头，谁愿意搭我，有人就会接单，可以通过不同的新方式满足你交通上的需求；在医疗方面的服务，你不用去买设备，不用去医院检查，可以租用这些设备，达成检查的需求。当然我们在这个领域当中还处于最开始的状态，未来还是有很多新的东西，新的类型会冒出来。

## 第五个趋势：分享（SHARING）

分享在过去20年已经有所发展了，但我仍然认为在这个领域，我们还有很大的进步空间。**分享的趋势是硬件软件化**。通过人工智能的加入，它可以与你交流，知道你的日程表，知道你什么时候会到家，然后它会提前开启空调。当你到家的时候，气温就非常适宜。在做不同事情的时候，它也能帮我们做预测，进而给我们提供帮助。

==人工智能不是实物，它是通过软件来帮助我们的==。

最开始，是从一个非常个性化的“我”，变成了“我们”，“我们”开始分享，从“我想要什么”到“我们想要什么”。

任何可以被分享的东西一定会被分享。你试想一下，有什么东西是还没有被分享的？**你可以通过分享让它变得更有价值**。

我们有很多东西暂时可能不会分享，但以后我们可能会分享它们。

未来在金融领域，如何进行分享？在中国，我们有很多平台，你可以分享融资，可以让你的顾客帮你，为你下一个产品融资（**产品众筹**）。你不用去银行，只要去这些平台就可以了，如果顾客对于你将要制造的东西非常感兴趣的，他们会对你进行投资。分享经济将会不断地产生新的东西来分享。

现在全球众筹市场的交易资金达到180亿美元。在众筹领域，还有**股权众筹**，通过股权众筹来给你整个公司融资，美国现在就有这样的股权众筹例子。现在你要进行公众的众筹，可能要走很多程序，但是只要使用这种服务，不管是多大的公司，你都可以得到资助。

谈到比特币（比特币是一种P2P形式的数字货币）。人们对此有很多不同的评论，这个和区块链技术是相关的。你是在分享结算的过程中，它不由任何一个人所拥有的，你可以把它打造成一个由人工智能来参与的事情，你可以把它放在平台上让大家一起来做这个事。

在房地产方面，你可以使用这样的方法。如果大家都同意这种分散式的做法，那么你就可以得到更快速、更方便的服务，这也是分享趋势发展的方向。==所谓的分享是任务的分享==，我们之前没办法完成的事情，现在通过分享来做成。

## 第六个趋势：屏读（Screening）

过去的屏幕朝着更加流动的形势变化，未来会有一种更加权威和开放的介质出现。

第六个趋势是屏读，即不用再看屏幕。在过去，我们通常通过屏幕来读取信息。但屏幕的问题在于，它们是一个固化的、精确的形式，不会变化。从过去固化、精确、权威的屏幕，朝着一种更加流动的形势变化。屏幕总是在不断地变动，看起来有点杂乱，你可以看到它的各种不同的角度，比如它的背面、侧面等。

另一个变化是，会有一种更加权威和开放的介质出现。当然，在这样的情况下，会有各种信息充斥进来，因此，==我们更需要信息的筛选能力==。我们可以看到，不管是在车上、房子的表面，很多地方都会有屏幕。将来我们会有一个无屏显示的技术。

现在我们有电子书，在未来电子书可能每一页都有它自己的屏幕显示。当你打开书，就像你打开原始的书籍一样，但是它每一页都会有不同的特征。

==未来屏幕和我们之间的互动是强有力的趋势==。

我们可能同时会操作很多不同的屏幕，比如手机、iPad、电视等等。当我们跟电脑相交流的时候，我们使用整个身体进行交流，我们可以通过身体去控制这个数据，电影《钢铁侠》就是这么做的，我跟这个电影合作过，也帮助了他们。

**用身体与AI（人工智能）交流是一个趋势**。比如你做个手势，就可以和手表进行交流，如果我要做一个关于未来的电影， 要怎么样使用电脑呢？我们不会使用屏幕来使用电脑了，而是用整个身体（如语言、手势）来使用电脑，未来将会如此，屏幕将会与我们互动。它会看我们的眼睛是往哪边动的，观测我们的情绪与注意力。

有一个网站，就应用了大家使用自己的眼睛看屏幕的过程，以后我们会使用技术来更加适应大家看屏幕的习惯，这就是技术。**用软件来跟踪人的情绪，看你是迷惑、兴奋、愤怒、还是沮丧，你的情绪都能被软件检测到**。屏幕会观察你，也会适应你，它会根据你的情绪做出相对应的改变。比如说我们俩对话时，我会根据你的情绪和反应改变，未来屏幕将会让我们之间有这样的互动。这是一个非常强有力的趋势，对我们来说会越来越重要。

## 第七个趋势：流动（Flowing）

第七个趋势就是流动，它概括了以上所有的趋势。物体会从本身固有的状态变成流动的状态，甚至变成流动的数据。不管你处于什么行业，都和数据相关。客户的信息是非常宝贵的，现在的商业就是要通过数据分析，让商业做得更好。

数据需要关联起来，需要流动起来，否则它就是无效的。数据需要实时不停地与其它数据进行关联与分析。我们所说的并不仅仅是一个固态的数据，而是怎么样把数据关联起来。第一层数据是固化的，比如文件、目录、桌面等；第二层则有了界面，经过连接，上传到网络；我们即将进化到第三层，在未来将会有各种数据流、不同的标签、云端和云数据等。

==未来的数据是流动的==，比如微信数据流、脸书数据流、电影数据流、音乐数据流等。从界面到数据流，从台式机到数据云，从我到我们，从实物到数据的过程，我们关注的并不仅仅是实物个体，而且更关注数据，这是我们谈到的第七个趋势流动。

## 第八个趋势：重混（Remixing）

第八个趋势是重混：我们把这些东西重新解开，再混合起来。我们可以看到，在过去创造的大部分财富，有一部分得益于将有价值的东西重组，把不同的新想法混合重组起来。

现在我们要做的是拆解，并且重组。**重组就是将不同价值的东西进行拆解，重新组合，成为新的有价值的组合**。我们读到的新闻、报纸媒介，就可能将这些信息拆分，然后进行新的重组，获取我们所需要的更加有价值的信息组合。比如这个网页，我们可以将它拆分后重组，产生新的东西，这就是我们现在所谈的重组信息的创新理念。

再比如拆解银行，银行提供不同的服务，你可以贷款、存钱。银行也可以进行拆解，并与其它有价值的东西组合起来，成为一个新兴的个体。车能够给我们提供一些功能和服务，比如将车的一些部件拆出来，和其它东西组合，产生新的产品。任何的事物都可以被拆解，然后进行重组，我们可以尽情地发挥我们的创造力，来思考如何拆解创造新的产品。它们可以是体育队、餐厅，或者其它，在重组的过程中，我们要看到最核心的部分，然后重组产生新的价值。

## 第九个趋势：跟踪（Tracking）

第九个趋势是跟踪：==跟踪一个关键要素形成的数据==。跟踪我们自己的各种行为，记录每天的事情和思想，这些技术变得越来越便宜。现在有更多的科学天才，他们想要创造这样的技术，做出这样的跟踪功能，有很多量化的设备可以实现这个功能。

市面上有记录血压和睡眠的产品，它可以记录我们的脑电波和血压等。在这个量化的过程中我们发现，任何可以被测量的事物都可以被测量，而且（这样的）服务价格越来越被大众接受。我们能够轻而易举的拿到这些量化的设备，来记录我们所需要的一些数据。

在这个图上，显示的是我们生活中所遇到的一系列数据流，如果我们从出生开始到老都可以记录的话，我们就能得到一个很大的数据库。从宏观来看，可能每个人的数据都是很平常的，但是对于个人来说，这个数据却很重要，它记录我们与别人的不同。

我们的心跳和睡眠规律，都是独一无二的，我们能通过这些设备实时地监控数据。我们可以从谷歌上面下载各种数据，现在也可以从量化设备上来下载自己身体各方面的数据。就医学角度而言，如果我们能追踪到一系列身体数据，我们能够得到更好的医疗建议，就能得到量身定制的医疗建议或医药处方，每天的身体变化情况也能监控。到了新的一天，就能得到一个新的反馈。

另外一个理念就是：==任何可以被跟踪的事物都一定会被跟踪==，“双向监督”会优化“跟踪”这项科技。

我们发现，被跟踪的事物是有价值的。通过手机来跟踪朋友，通过脸书来识别世界上任何一个人。实际上我们正在用各种设备跟踪别人。

我们可以用手机来定位对方在哪里，当一个名人进入大厅时，我们就能发现他，这也是跟踪的一种体现。当然，这个实时跟踪的数据确实挺可怕的。所以我的建议是，如果我们不能停止这个科技的发展，那么我们应该思考：如何更好地发展这项科技呢？答案是：**双向监督**。当你的公司在跟踪我，我也在跟踪你，如果信息不对，可以及时更正。

在一个小城镇，邻居知道你什么时候睡觉，什么时候去杂货店，他知道你各方面的信息，你可能很不舒服，当然你也知道他所做的一切，你知道他的生活是什么样的。如果某些人说了一些他不对的事情的时候，你就能知道他说的事情是不对的，这也是跟踪的一个好处。如果某天他碰到了一个陌生人，你也可以及时叫警察。所以在这个层面上说，相互监督是有好处的。但是当我们发生信息不对称的时候，比如他知道我的信息，我却并不知道他的信息时，我们就会觉得很不舒服。

从相互监督来说，我们要延伸到另外一个点：**我们所面临的“透明和个性化”跟“私有和通用”是相关联的**。我希望被认为是独一无二的，不只是大数据中的一个。我希望我的家人和朋友都待我很好，我希望我的朋友家人，甚至到警察，都认为我是一个独特的个体，我希望他们能看到我，这是透明化的一端。

同时我也希望大家看不到我，我有我自己的私人空间，我希望我们是有选择权的。当给他机会选择的时候，通常大多数人选择的是分享这一端，他们会上各种社交网络，希望大家都知道他的信息，这是人的天性。另一方面他希望大家了解他所做的，希望大家待他如一个特别的个体。如果他从这个社交网络上获得了一些好处，满足了心理需求，他就会开心，但是同时他又不希望在这个社交上面失去他自己的隐私，那么其实他们是隐私让位于炫耀的。

## 第十个趋势：过滤（Filtering）

第十个趋势是过滤，这可能有点抽象。它的意思是说，我们生活在历史上最好的时代：不管是对于看电影、读书、成为顾客等等不同场景与角色当中，这都是最好的时代。我们有很多的选择，有很多非常有趣、非常棒的事情可以去尝试。现在有很多好的电影正在制作当中，好的书正在写的过程当中，这个速率是前所未有的快。因为大家有很好的资源，很好的工具，帮助我们有很多不一样的选择，我们可以从中选择我们喜欢和好的。这会影响到我们经济运行的方式，因为拥有丰富资源的世界，会极大地影响经济领域。

==金钱与人的注意力相伴相随==。

在这个时候，当我们拥有很多资源的时候，什么比较罕见的呢？那就是人，人是一个稀缺资源，人只有24个小时，同时我们的注意力是有限的，我们要怎么分配我们的注意力呢？当我看到新的经济诞生、新的零售业正在发展的时候，我发现不管注意力如何改变，金钱都会相伴跟随。当商务经济开始发展的时候，人们可能会说这个网络商务能赚多少钱呢，赚不到钱的。那时候大家对网络经济的注意力其实不是很多。当时我关注到了这个领域，做了一些相应的调查。注意力可能对于一个新领域需要四五年来养成，但一旦注意力放在了这个领域，金钱就会相伴跟随。

拿小孩举例，小孩们所注意的地方，可能在未来会成为一个热点领域。他们喜欢电脑游戏，那么在未来电脑游戏就会成为热点区域，会商品化。人们花很多时间看视频而非读书，那就意味着做视频会比书方面要赚更多钱。这不管是对于网络世界，还是现实世界来说都是这样。在最开始，可能烹饪这些技能都是不怎么赚钱的，如果人们的注意力是放在这块，那它就能形成一个领域，金钱就会相伴而来。如果你计算一下，人们的注意力有多少是放在电视上的，那么电视能赚多少钱，是可以从广告的投入程度来决定的。在美国，人们看电视每小时是20美分，这是个很便宜的价格。我们就通过注意力，来让广告商赚钱。

**为关注而付费，这是一个新的趋势**。

想象一下，在读邮件的过程中，你实际上是在为关注而付费的。这就是一个新的趋势，你需要付费让别人来关注你新的App，向看广告的人付费，这也是一个新的方式。那些拥有更多粉丝的人，他们要关注一个软件，别人为他付费会付得更多。在KLOUT这个网站上（备注：KLOUT是一家衡量用户在Twitter、Facebook、Google+、LinkedIn、Foursquare、Wikipedia等社交网络上影响力指数的创业公司。来源：百度百科），每个人有不同的粉丝数量，通过他们拥有的粉丝数就可以分析出影响力有多大。可能对于一些年轻的高中女孩，她们有非常大的网络社交影响力，你要取得这些女孩的注意力就要付更多的钱。

零售商和公司，它们会去计算这个顾客在一生当中可能为他们的产品花多少钱。一个人会产生波纹式的影响力，他可能会影响别人。这样的影响可能会带来更多的收益。要得到他们的关注力，也是要付费的。

可能通过这种分散性的方式，做市场的人可以直接付费给那些名人，让他们产生影响。那些广告商就会受到影响。你可以创造一个系统，在网络上的一个共享式的系统，你可以付费让大众来创作广告。把这个软件建立在顾客基础上的，如果大家去点击这个顾客所制作的东西时，那么他就能获得收入。而那些忠实的顾客，某公司忠实的顾客，他们就会去做这样的事情。他们也会有所收获，大家去点击他们所制作的视频或者其它产品，他们也能通过这个来赚钱。

==在过滤的过程中，我们需要管理好自己的注意力==。

## 第十一个趋势：提问（Questioning）

==在未来，“答案”是免费的，而“问题”更有价值==。

第十一个趋势是提问。我们现在的世界使“回答”变成一种商品，像谷歌每天给出10亿条回答，但是未来会发生很大的变化。比方说现在有两个公司，其中一个公司在中国，它用人工智能等技术，能够给到我们非常准确的回答。在这种情况下，答案其实是会变成免费的，而有价值的是我们的提问。

==机器人会给我们答案，但是它却不会提问==，**通常一个好的问题，会抛砖引玉出更多有价值的问题**。我们并不仅仅是局限于提问，而是要对我们所面临的事情，提出更加有价值的问题。

像英国人讨厌美国人的一点是，他们总是喜欢抄袭，而不去创造。当然在中国也有这个现象，虽然这个文化有待于改进。**我们现在需要做的是更多地提出问题、去创新**。在未来，答案是免费的，而问题是更有价值的。

有趣的是，当你提出一个问题的时候，你得到一个答案，这是科学。在科学当中你有一个问题，但是从这个问题，我们又会引发出很多新的问题。随着未知领域的扩张，我们会发现，我们会面临越来越多的问题。

好的问题不仅带来一个答案，还会引出更多有价值的问题。**这些问题和答案之间的差距，就是我们的未知领域**。

随着科学的发展，我们发现我们有更多的未知，因为当我们有一些答案的时候，我们会发现更多新的问题，那么这些问题和答案之间的差距，就是我们的未知领域。我们会发现，这个未知领域的扩张，比我们所知道的知识的扩张速度更加快。而要提出好的问题是很困难的，像爱因斯坦最著名的一个提问：如果我坐在像光速一样的机器里，我看到的是什么呢？这样一个简单的问题，是他所有伟大发明的一个基础。

所以一个好的问题，不仅能带来一个答案，更加有价值的是，它能引发出更多更好的问题。这就是我们想要创新的时候所需要营造的文化。

## 第十二个趋势：开始（Beginning）

接下来一个趋势就是”开始”，它是一个过程。我们现在所创造新的东西，实质上只是处于开始的阶段。

20世纪70年代的人们难以想象电脑可以变得如此之小。

对于现在我们在讨论新技术，就像在以前大家甚至很难以相信，电脑是会变得更小的。在20世纪70年代，电脑之大可能塞满整个房间，那时候我们说有一天可能我们电脑会非常小，你会把它们放在一个很小的地方，那么大家就会觉得你可能疯掉了。一个电脑，有一个门这么小的电脑，对于当时来说是一个很奢侈的想法。现在大家住在酒店房间的时候用房卡进门，这实际上也是一个和电脑有关的操作，我们可以把它放在走廊里、放在椅子里，这对当时来说是难以想象的。

**很多在过去看来不可能发生的事情，在未来或许可行**。我们需要去相信那些不可能的事情。

维基百科这个事情在它创始之前，也是被大家认为是不可能的事，在维基百科里面你可以购买新的资讯。而现在，我们确实拥有百科这样的东西。所以它虽然在理论上不可行，但是在实践上是可行的。在很多网上的事情，我们之前也认为不可能，你可以通过手机知道世界上任何一个地方的天气情况，在20年前，得知这样的信息是非常昂贵的。

而现在你可以得到这些信息的速度之快之方便之免费，都是前所未有的。我们在这个清单上还可以发现很多东西，都是我们以前无法相信的。如果在两千年我跟你说，我们在2006年会生活在一个什么样的世界里，那么你肯定会觉得不可能。所以我们更需要去相信那些不可能的事情。

==人工智能会激发创造更多不可能的事情==。未来20年最伟大的产品还未问世。

人工智能变得越来越聪明，我们通过这个会得到激发创造更多不可能的事。谁能想象呢？一个公司可以有几十亿的客户，而且他们得到这些服务很开心。你可能无法理解，但是这就是可能性，**我们要打开我们的眼界**。

在未来的20年，我们现在所拥有的事情规模可能会变得更加大，发展得更加快，可能有更多人的参与。而我们现在只处在最开始的开始，我们在第一天，也就是说我们已经发生的事情，其实并不算什么，我们所创造的平台以后将会见证更多、更加有趣的事情。

**在2036年，我们可以做什么样的预测呢**？那时候虚拟现实和人工智能可能变得不重要了。未来20年最伟大的产品现在还没有，我们大家都还没有见过它，它可能在未来20年才会得到创造，它可能是一个现在仍然从未存在过的东西。

在1991年，也在讨论未来的时候，可能不会把互联网算进去，而现在我们会创造一个比互联网更加厉害的东西。可能我们会在这上面分享经验，然后也会囊入人工智能的部分，追踪所有我们可以追踪的东西，屏读我们所有能屏读的东西。也就是说未来20年最大的产品还没有问世，你可能会成为其中的一员，就是创造这个产品的一员。

**我们现在还处在最开端，大家没有来晚**，我希望你们可以接受这个挑战，塑造未来20年的未来。就算你刚才听了我所有内容，但是我们最好的事情还没有发生。

# [人工智能的真正风险](http://www.solidot.org/story?sid=50550)

 过去几年，霍金（Stephen Hawking）、马斯克（Elon Musk）、比尔·盖茨等一些名人警告我们应加强关注超级AI可能带来的危险后果。而且他们还把钱用在这方面：包括马斯克在内的几位亿万富翁为OpenAI提供支持，该组织致力于开发惠及人类的人工智能。但是对很多人来说，这不过是杞人忧天。吴恩达称担心杀人机器人的出现就好像担心火星上人口过剩一样。与其担心人类被人工智能统治，不如思考因为我们过分相信我们制造的智能系统而可能带来的真正风险。**机器学习的工作模式是训练已有数据寻找规律**。当机器作出回答时，**我们通常无法知道它的解答过程**。这就存在明显的问题。==机器的准确性取决于它学习时所使用的数据的准确性==。由于我们提供给人工智能的很多数据都是不完美的，我们也不应期待人工智能一直能提供完美的答案。**我们需要加强审视基于人工智能的决策过程**。由于我们按照自己的样子制造出人工智能，它就很可能兼具人类的优点和缺点。

# 机器人可以通过照片指认罪犯？这个“谬论”最近被中国研究员给证实了

技术与道德局限仍然是跨不过的一道坎儿。

如果你看过《Lie to me》这部美剧，就不会对“**透过辨别微表情指认犯罪者**”这个设定感到新奇。

事实上，自从人类发明摄影术以后，学术界与人工智能界就正式开启了关于“如何通过面部识别技术来确认罪犯”的脑洞：

摄影时代的到来曾让一部分19世纪科学家坚信，机器绝对有能力通过识别人的面部特征来准确找到罪犯。虽然他们这种假设最终被打上了“不可信”与“荒谬”的标签，但200年以后，这一曾经的“谬论”却可能为他们挽回声誉：

**新一代人工智能技术或许可以证明他们的言论是有据可查的。**

## **上海交大：神经网络识别犯人的精准度高达89.5%**

在中国，来自上海交通大学的研究员吴小林与张希让这个极具争议的传统型议题——“通过面部识别确认罪犯”再次回归大众视野：

**他们建立了一个据说只需通过验证面部特征就可找出犯人的神经网络。**

在他们的论文中，为了证明这个理论的可行性，研究员们将大量嫌疑犯与未犯罪者照片混放在一起，继而利用大量机器视觉算法来测试这些人的面部表情，目标就是发掘出一套能够可靠分辨出犯人的神经网络系统。

在这个过程中，科学家需要将1856张无面部毛发（包括眉毛、嘴毛以及胡须等等）、年龄在18~56岁之间的中国人照片灌输给神经网络。这些照片中的一半人（约有730张已被确认为犯罪者）具有犯罪前科。

值得注意的是，研究员只用其中的90%来训练人工智能以识别犯人与普通人之间的差异，其余10%用来检测这套系统的目标达成度。

**而成果的确令人印象深刻。根据研究人员提供的数据，这套神经网络区分犯人与普通人的精准度高达89.5%。**因此，吴小林与张希也认为：

> “即便‘通过面部表情推测罪犯’是一个历史争论，但这些与事实高度匹配的结果的确是一个很好的证据。”

![机器人可以通过照片指认罪犯？这个“谬论”最近被中国研究员给证实了](https://pic.36krcnd.com/avatar/201611/28105935/ijnj2gou1vxdtath.png!1200)

被神经网络解析的图片

研究结果与MIT科技评论此前给出的解释非常类似，神经网络识别面部特征的要素可以被划分为三个类别：

- 犯人上唇的弯曲度会比普通人平均高出23%；
- 犯人双眼内眼角之间的距离比普通人窄6%；
- 犯人的鼻尖与嘴角之间形成的角度比普通人小20%。

不过上海交大的研究员们还得出了一个更有意思的结论：与普通人相比，犯罪者之间的面部表情往往呈现出更大的差异。

> “换句话说，比起罪犯们的脸，普通大众的脸有更高的相似度；而犯人之间的面容比普通人有更大的差异度。”

实际上，上海交大的研究结果很难引起人工智能界的惊讶：这个准确率极高的结果根本不值得大惊小怪。

此前学术界就指出，如果“**犯罪心理学家**”的存在是对“**人类有能力分辨出犯人与普通人**”的最好证明，那么机器也应该有能力这么做——毕竟神经网络系统就是对人类大脑的最好模仿。

![机器人可以通过照片指认罪犯？这个“谬论”最近被中国研究员给证实了](https://pic.36krcnd.com/avatar/201611/28110808/j6qbe927gt5q52q3.png!1200)

## 人工智能在面部识别应用领域的技术与道德局限：

然而，这项特殊研究的主要方法还不能获得足够信任，原因就在于研究所选取的各项参数还存在诸多问题。

譬如用于训练神经网络的照片样本是严重受限的（只有1000多份）。或者至少可以这么说，研究结果在很大程度上取决于照片的质量与数量。

因此，这个研究成果一公布，就毫不意外地引起网友的担忧与谴责：

照这么说，人们无意中翘起的嘴角，嘴巴的大小与形状，拍摄照片的角度都会让一个人变得“贼眉鼠眼”。因此，研究结果所谓的科学依据与可靠性仅仅是人工智能技术的“一厢情愿”。

而MIT科技评论也认为，这项人工智能技术引起的最大担忧其实在于，**计算机很可能在人类法庭上根据一个人的面相，带有偏见来指证一个无辜的人**。与此同时，一个看起来很无辜的犯人也有可能被机器证明“无罪”而逍遥法外。

**实际上，就像文章开头所说的，对此类研究的大肆谴责一直延续了几十年甚至上百年。**

譬如今年9月，在一项名为Beauty.AI的选美大赛上，由 6 名 AI 机器人担任评委。这些机器人利用 5 种算法对来自全球年龄在18-69岁的自拍照片进行了评判。

但选美结果却遭到了很大的非议——因为机器人根本“不喜欢”皮肤黑的人，几乎所有黑皮肤的照片都被机器筛掉了。

所以说，这种带有“种族歧视”的结果再一次让基于人工智能的面部识别技术陷入尴尬的境地。

因此，就像Beauty.AI选美大赛首席技术官Alex Zhavoronkov给出的解释一样，==对神经网络进行充足的训练是将人工智能推入应用层的前提==：

> “如果在你采集的数据库中没有足够多不同肤色的照片可以参考，那么人工智能机器人注定会产生有偏见的结果。”

或许我们不能质疑，未来某一天，除了完美打破各项成功纪录，人工智能技术将有足够能力执行各种基于面部识别的任务。

但是，我们却不能排除另一个潜在的安全威胁：**那些被机器打上“无害”标签的普通人真的不会给我们带来威胁吗**？在这项技术足够成熟后，**如何鉴别那些能够进行完美“反侦查”的“伪装者”**？

或许这些理由就是我们不能对人工智能识别技术掉以轻心的根本原因。

# 研究人员试图教机器人如何“做梦”

人类的夜间睡眠（甚至白天小睡）都能帮助巩固记忆，并==将短期记忆转入长期记忆==。**通过稳定、增强和整合这三个不同的过程来促进记忆的形成，并将记忆变成更有组织性的文件系统**。首先，稳定过程能在6毫秒内将一段记忆编码。接下来大脑能在数分钟、数小时或是一整天内增强记忆，将其巩固为长期记忆。 最终将出现整合过程，在这个过程中大脑会将全新的记忆碎片加入到已有记忆中——就像整理一个档案系统。

现在研究人员希望机器人也能“完成”同样的事情。 谷歌的DeepMind此前已在经典视频游戏中取得成功。谷歌在《Breakout》和《Asteroids》等游戏中教会人工智能（AI）并非为击败游戏而简单排序，而且为今天的监督学习技术奠定了基础。尽管DeepMind已经很先进，但其仍然无法在《星际争霸》或《Labyrinth》等更复杂的游戏中击败人类。 当我们梦到尴尬的情况或威胁的问题时， AI的“梦中”却包含了如何对这些游戏的所有章节进行重新排列，它们还会不断重复这个过程。

现在研究人员的目标是能够让AI通过实验向人类一样学习。**从监督学习——AI分析数据并寻找模式——向非监督学习转变**，包括教机器人通过实验来分析不同的行为过程对结果的影响。研究人员表示， 到目前为止，AI的监督学习速度已经增长了10倍。

# 麻省理工学院的深度学习软件能生成未来的视频

LeCun曾在演讲中提到，**2016年深度学习领域最让他兴奋的技术莫过于对抗学习，而无监督学习一直都是人工智能研究者孜孜追求的“终极目标”之一**。MIT 计算机科学和人工智能实验室的研究员们在本年度的NIPS上提交了结合对抗学习和无监督学习两种方法的研究——让计算机在观看了200万条视频后自动“创作”视频内容，结果非常逼真。研究所开发的深度学习神经网络也可以直接用到现有的图片和视频中，把静态图片变成动态视频，并且对人类的动作具有一定的判断和预测能力。

MIT 计算机科学和人工智能实验室（CSAIL) 的研究员开发了一个深度学习算法，能够自动生成视频，并预测出接下来的视频内容。

研究成果论文将在下周在巴塞罗那举行的 NIPS ( Conference on Neural Information Processing Systems )上发表。CSAIL 的研究团队让该算法观看了200万条视频，这些视频加起来如果要回放的话，需要2年的时间才能播完。

视频包含了日常生活的常见场景，以让机器更好地适应正常的人类交流行为。更重要的是，这些视频是“野生”的，也就是说，它们都是非标签的。简单地说，就是研究员不会给算法提供理解视频内容的任何线索。

在这一视频数据集的基础上，算法将基于200万条视频中获得的观察，尝试从零开始生成视频，这和人类创作视频的步骤是一样的 。随后，生成的视频会被填入另一个深度学习算法中，新的算法负责判断哪些视频是机器生成的，哪些是“真实”的。这种训练机器的方法叫对抗式学习（adversarial learning）。

## 研究使用的神经网络工作原理

计算机视觉研究领域中，许多研究者都在攻克类似的问题，其中就包括MIT的教授 Bill Freeman，他在”视觉动态“（visual dynamics）领域的工作也能提前创造出视频中下一帧。但是，他的模型聚焦于推断性的视频，Torralba 的视频能够生成全新的视频，这些视频内容此前是从未讲过的。  

*![当机器学会创作视频，预测人类行为](https://pic.36krcnd.com/201611/29072529/c36cmftvbh8jc1og!1200)*

*图来自 : Carl Vondrick, MIT CSAIL*

此前的系统都是一帧一帧地创建场景，这会带来巨大的失误概率，这项研究聚焦于一次处理整个场景，算法每秒生成32帧图像。”一帧一帧地创建场景，意味着信息是被分成很多块的“，Vondrick 说，”我们采用同时预测所有帧的方法。“

当然，一次生成所有的帧也有缺点：在变得更精确的同时，长视频中的计算机模型会变得更加复杂。

为了创建出多帧的效果，研究者教会模型在不受背景的影响下生成前景，然后，把对象放到场景中，让模型学习哪一个物体是移动的，哪一个不动。团队使用了”对抗学习“的方法，在多次尝试后，生成器学会如何”欺骗“区分器（discriminator）。

## “双流架构”，生成视频更逼真

”在这一模型的早期原型中，我们的发现是，生成器（也就是神经网络）会改变背景或者在背景中加入异常的动态图片，来尝试欺骗其他的网络“，CSAIL 博士候选人、论文第一作者Carl Vondrick说，”我们需要告诉模型一个概念，那就是现实世界在大多数情况下都是静态的。“

为了改正这一问题，Vondrick 和他的同事创造了一个“双流架构”（two-stream architecture），这一架构会强迫生成的网络在前景中的对象移动时，对静态的背景进行渲染。

这种”双流架构“模型生成许多更加逼真的视频。算法生成的视频是64X64分辨率的，包含了32帧（标准的电影是每秒24帧，这意味着算法生成的视频有1秒~1.5秒），视频描绘的内容包括沙滩、火车站以及新生儿的脸（下图，这相当吓人）。

![当机器学会创作视频，预测人类行为](https://pic.36krcnd.com/201611/29072529/rmf0ry6hgj3dxcck!1200)

虽然听起来从零开始生成几秒的视频并没有多了不起，但是这比起此前的研究已经有了显著的进步，此前使用深度学习框架，只能生成一个视频中的几帧，并且在内容上，也会受到更为严格的参数限制。

让机器生成视频遇到的一个主要难点在于，视频中的物体是动态的，特别是人物，常常被渲染成模糊的一团，虽然研究者都在坚持：”我们的模型有潜力生成非常好的动态场景“。

确实，这种场景是非常值得赞叹的。研究者向亚马逊的 Mechanical Turk 的工作人员展示了一段由机器生成的视频和原来”真“的视频，向他们求证哪一段视频更为真实，结果，有20%的人选择了机器生成的视频。

*![当机器学会创作视频，预测人类行为](https://pic.36krcnd.com/201611/29072529/vsvy54dd02s3cspc!1200)*

*团队采用了两个神经网络，互相对抗，其中一个尝试欺骗另一个，让它认为自己生成的视频是”真“的。图：MIT CSAIL*

除了生成原始视频，这一研究另一个亮眼的成果是能在已有的视频和照片上进行应用。当研究者把深度学习算法应用到一个静态的帧中，算法就能够识别出照片中的物体，把它们制作成32帧的动图，生成”非常合乎常理“的动作。Vondrick说，根据自己的了解，这是首次实现让机器从静态图片中生成多帧的视频。

这种预测对象或人的运动的能力对于未来机器融入现实世界是至关重要的，因为这将允许机器不采取可能伤害人的动作，或者帮助人们不伤害自己。根据Vondrick的说法，这一研究成果对无人监督的机器学习也有促进作用，因为这种类型的机器视觉算法接收的是来自未标记视频的所有输入数据。

如果机器真的想要善于识别和分类对象，它们将需要能够在没有标签数据的情况下这样做。

但是对于Vondrick来说，他的研究中最令人兴奋的可能性之一却跟科学或现实世界没什么关系。他纯粹是想让机器创作一段视频。

”从某种程度上来说，我对让机器自己创作一段视频或者电视节目非常痴迷“，Vondrick 说，“我们只生成了一秒钟的视频，但随着我们的进步，也许可以生成几分钟的视频，讲一个连贯的故事。我们现在还做不到，但我认为我们迈出了第一步。

[*原文地址1*](http://motherboard.vice.com/read/researchers-taught-a-machine-how-to-generate-the-next-frames-in-a-video)*，*[*原文地址2*](http://robohub.org/generating-predictive-videos-using-deep-learning/)*，*[*论文地址*](http://web.mit.edu/vondrick/tinyvideo/paper.pdf)

## MIT研发神经网络训练新方法，可以给出决策背后的原因

AI 一直被人诟病为是黑盒子，原因就在于不能给出决策背后的原因。近期，在由计算机语言学协会（the Association for Computational Linguistics）举办的会议中， MIT 计算机科学及人工智能实验室( CSAIL )的研究人员展示了一种新的神经网络训练方法，不仅能做预测和分类，还可以给出决策背后的原因。



---

# 这个简单算法也许可以让人工智能真正像人一样思考

**连通性理论认为，再复杂的思想也不过是神经元的排列组合**。

![这个简单算法也许可以让人工智能真正像人一样思考](https://pic.36krcnd.com/avatar/201611/29135943/kqb0glxo2izk9kzu.jpg!heading)

不得不说，虽然人工智能这词里面既有人工又有智能，但是它跟人体最复杂的器官——人脑差得还有点远。但是根据最近发表在《Frontiers in Systems Neuroscience》的一篇[论文](http://journal.frontiersin.org/article/10.3389/fnsys.2016.00095/full)，如果其发现属实的话，人类似乎离开发出类似人脑思维的AI不远了。这篇论文的题目叫做“**脑计算是通过2的幂次方排列逻辑组织的（Brain Computation Is Organized via Power-of-Two-Based Permutation Logic）**”，论文作者认为这个基础算法就是人类智能的引擎。值得注意的是，论文作者多为华人，其中就包括著名的生物学家与神经学家钱卓。

钱卓是是国际著名的神经生物学与分子生物学家，其创造基因工程小鼠进行学习记忆研究的“聪明鼠”项目曾经在学术界引起轰动。据钱卓介绍，该算法可见于[连通性理论](http://www.augusta.edu/colleges/medicine/discovery/bbdi/tsien/documents/theoryofconnectivity.pdf)（钱卓是去年提出这一解释大脑运作机制理论的），属于相当简单的数理逻辑，它构成了我们负责的脑计算的基础。简单来说，这个理论解释了**我们是如何获取知识，以及如何概括知识并从中得出结论的，这个过程相当于数十亿神经元的排列与组合**。论文提供的证据表明，人类的大脑也许就是按照一个出奇简单的数理逻辑运作的。

连通性理论描述了类似神经元组是如何形成复杂度团（群组数量）来处理信息的基本思想的。这些神经元祖会集群为功能连通图（FCM），后者则用来处理每一个可能的想法组合。想法越复杂，牵涉到的团就越多。

当然，这只是理论猜想。为了对这一理论进行测试，钱卓的团队监控记录了算法在7个不同的大脑区域是如何运作的，这些区域每一个都涉及到老鼠和仓鼠对食物、恐惧等的原始反应。算法表示的是一个功能连通图所需的团数N，研究表明N=2的i次方-1。

![这个简单算法也许可以让人工智能真正像人一样思考](https://pic.36krcnd.com/avatar/201611/29140029/v9rzkw71usqakl99.jpg!1200)

> 细胞群的归纳与计算逻辑。公式定义的是细胞结群的大小，即该细胞集群内部的神经团数量。

研究人员通过提供饼干、小球、牛奶、大米等4种不同的食物组合来监听受试老鼠的大脑反应，最后他们得出了15种独特反应的组合（N=2的i次方-1，i表示输入，这里就是食物，N就是神经团数量），正好符合了连通性理论的预测。而且这些反应似乎都是大脑预先编排好的——在提供食物给老鼠后，这些反应就会自然出现，而一旦刺激物没有之后又会消失。

当然，这个发现的潜在意义更主要是指AI上面。想想看，**如果人脑智能无论复杂度如何都能用这个简单算法表示的话，一旦运用到人工智能的神经网络上，AI是不是就可以模仿人的思维了呢**？细思极恐啊。

# 傅盛：深度学习是一种新的思维方式

落后最怕的是思维方式的落后。

首先我们必须认识到——**人工智能一定不是简单的一个神经网络**，也不是用一个新的函数替代一个旧的函数。==人工智能是对整个产业的重构，是对我们整个思维方法的重新塑造==。

**它将现实所有物理事件产生的东西归结于一个点——数据**。然后，**再把这个数据，用神经网络的方式去认知和理解，达到过去所有算法无法企及的高度**。

而深度学习，无疑成为当今人工智能大爆炸的核心驱动。它不只是一种算法的升级，而是一种全新的思维模式。

今天，==我们完全可以利用深度学习，利用海量数据的快速运算，消除信息的不确定性，帮助我们认知世界==。

这种认知的可能性，最广为人知的就是AlphaGo打败李世石。我说过，**现象即规律**。这个现象给我最大的启示就是——把过去围棋的定式算法问题，转换成了黑白点的数据问题。它利用神经网络超大规模的数据处理能力，去理解人类记录过的围棋数据，以及自己左右互搏产生的海量数据，在人类也不明白的情况下，一举碾压了人族。

**它带来的颠覆性在于：==将人类过去痴迷的算法问题，变成了数据和计算问题==。**

我认为，**这是重构技术模式，产品形态，用户理解的新方式**。深度学习的突飞猛进，也将使得猎豹这样的工具厂商，有机会与社交产品站在同一维度同台竞争。

**唯一需要思考的是：==如何让用户成为一种生产力==？**

比如，你觉得特斯拉是汽车生产商吗？如果你重新换个角度，会发现特斯拉本质是一个数据采集器。它利用汽车载体实现了对人类驾驶行为的触达。

我最新买的特斯拉P90D，已经可以自主学习变道。它会多次来回试探，学习你开车的动作。你每一次开车，都是在给它贡献数据。它跟谷歌的无人驾驶有很大不同。

他们走了完全不一样的路线，思维角度也不一样。

谷歌是传统的软件工程思维。用高精尖地图，把一段路的地图精确到厘米级，以便车子开的过程中就知道路况，通过激光来避开路面障碍。但问题在于，这套方案，只有知道地图和路况不发生改变时才能运行。

但特斯拉用的是NVIDIA+Mobileye的方案，跟人开车的状态一样。它认为，**辅助驾驶到了一定程度就是实现无人驾驶**。只要收集大量的驾驶数据做处理。不用管地图，用产品就能实现数据收集。实际上，就是**把所有路况信息和人的操作动作数据化**。

**我认为，未来的公司本质都是数据公司。市场的竞争，一定会从技术竞争演变成数据竞争。**

各公司的商业策略和产品策略，都会围绕着获取数据开展。后进的公司要想不坐以待毙，唯一的办法就是快速获得数据。

==深度学习绝不只是一场技术革命，或一种算法的改良。本质上，它是一种全新的理解用户和商业模式的思维方式==。

# 李开复：人工智能的黄金时代

大家听到人工智能这个词大概是在今年年初，AlphaGO 战胜李世石的时候。当时在讨论人工智能是在模仿人脑，超越人脑，奇点是否来临？我们是否会被机器统治？

实际上这些都是很玄很远而且也不太靠谱的说法。所以我建议大家也不要再看任何讨论刚才几个问题的文章了。其实，人工智能跟人脑的关系也不大，也没有什么超越人脑的可能。人工智能全部都是我们完全控制的奴隶，我们让他们做什么，就做什么。有没有一天它们会比我们聪明，告诉我们做什么，这个我不知道。

但是对于我们来说，至少还有20年，**这20年我们应该专注怎么用好人工智能**，给人类创造价值，帮我们赚钱。还有就是怎么去投资人工智能，以及担心人工智能会取代哪些工作。至于其他的问题就不用考虑了。

人工智能这个事情，其实绝对不仅仅是取代人脑，它会比人脑厉害很多。但是这不是说它是在所有领域，它一定是在几个前提条件下，而且一定是在某一个狭窄的领域。

![](https://pic.36krcnd.com/201611/30013046/yv3l3rolkdj6pwjj!1200)

比如说围棋，比如说传一篇文章，比如说量化交易，这些领域里面，它可以非常的厉害。因为它用巨大的数据，来做一些分类，**预测或者对未来的推测**。比如说，演示文稿上的这10个工作， 10年以后90%干这些行业的人就都失业了。当然，剩下来的则是顶尖的，对于记者他可以写很深度的文章，而顶尖的翻译他可以为元首做实时的翻译，或者是翻译诗词、诗歌。

这些人工智能做不到，但是普通的翻译、记者、助理等等都不需要。普通的保安也不需要了。有没有一个作为人的保安可以记住20万犯罪者的照片，不可能的，但是机器可以。所以在这些领域里面，人根本没有任何的机会，这不是说什么机器会不会比人能干，在这些领域里面，确实，人就是没有希望。

比如说司机，无人驾驶10年左右就会来临。无人驾驶来的时候，世界上做司机工作的9%的人类他们都要换工作，所以在这个领域，就是如此被巨大的颠覆了。

![](https://pic.36krcnd.com/201611/30013046/uhopf2j6xk2kry5j!1200)

人工智能也就是这样几个事情，感知、决策、反馈。

![](https://pic.36krcnd.com/201611/30013046/rd1e4vdr0xmlfulr!1200)

前两件已经做的很好了，后一件还需要时间。我们在这几个领域可以看到，过去二三十年有很多重要的里程碑，尤其是在最近的5年，我们发现人工智能能用了。

![](https://pic.36krcnd.com/201611/30013046/khzrb4l9azdu0e3s!1200)

当然如果你像我这么不幸在30年前就做人工智能，我们就没有生逢其时，也没有找到这个风口。我们就只能写写论文，然后再换份工作。但是30年之后，我们非常清晰的看到这个领域成熟了。

为什么说这五年成熟了呢？30年前做的太早呢，为什么三十年前成为先烈，现在成了伟大的创业者呢？

==就是因为一个特别重要的技术，叫做深度学习==。

![](https://pic.36krcnd.com/201611/30013046/zqovinvpavadpmyr!1200)

**深度学习是什么**？你丢一大堆数据给它，然后问它，我应该买什么股票？这个人的保险该付多少钱？这个想贷款的该不该贷？这个信用卡的交易是否有欺诈的嫌疑？你还可以问他，这么多的男人你应该找哪一个为对象？你也可以问他，今天晚上这么多好吃的，我应该吃哪些？它都会告诉你一个答案。

但是非常重要的是**它来做这么个决策只会在一个狭窄的领域，而不是任何的领域**。

![](https://pic.36krcnd.com/201611/30013046/2xvzd74t07jg2jfy!1200)

==深度学习其实只是一个技术==，以后还有很多其他的技术，这里就不说了，但是绝对不是人工智能就能取代人脑。**人脑的情感、自我认知是机器完全没有的**，还有**我们人可以跨领域思考**，比如说我现在跳出来说我中午不要吃汉堡，你们每个人都可以懂，但是机器不能懂，机器一次只能懂某一个领域。

![](https://pic.36krcnd.com/201611/30013046/5qbi8jenuhnj297l!1200)

所以说人工智能的五个条件很简单。**海量的数据，清晰领域界限，顶尖的AI科学家，还有自动标注数据，以及超大的计算量**。原来所说的，7年前听到我所说的移动互联网的时代来到了，任何三个小朋友都可以创业。

在人工智能的时代，这个完全被颠覆了。三个小朋友你不要想创业了，因为你没有巨大的机器，没有顶尖的科学家，你也没有特别大的计算量。所以这个是==科学家的创业时代来临了==，而不是三个小朋友的创业时代。

![](https://pic.36krcnd.com/201611/30013046/leu4uyzj24m6yjd7!1200)

## 深度学习到底有多了不起？

大家看左边这张图，你可以看到在5年之内，左上角代表的是在图像识别领域机器超越人类，左下角是语音识别领域机器的错误率低于人类。一个往上，一个往下，都是代表超越人类的表现。

**当人脸识别超越了人类**，我们还需要保安吗？**当语音识别超越了人类**，我们还需要客服吗？还需要打电话推销吗？**当自动驾驶超越人类**，我们还需要司机吗？**当传内容，写新闻，金融稿件的能力超越了人类**，我们还需要金融界记者吗？这些都不需要。

90%的金融领域的报道都是传出来的，这些报道以后绝对不是人写的，人写是会犯错的，机器不会犯错，只有深度的报道才需要人写。所以，这就是超越人类的一些领域。

那到底哪些领域可以做人工智能，可以挣钱呢？实在太多了，我在这里随便列了三十多个领域，在任何一个领域就是一个商业计划书，如果你能找到一个该领域的超级的商业专家，销售专家，再搭配一个人工智能的科学家，那就是一个黄金创业团队。这些细节这里就不多讲了。

简单来说，谁能做人工智能的创业，第一种，谁手中拥有互联网数据的这个是最了不起的，也就是BAT、滴滴、美图等等，他们手中有数据，而且已经标注，只要有科学家就可以产生价值。

第二种是传统企业，比如说股票的数据，比如说保险业、银行业，各种金融的。我觉得数据非常的丰富，而且是非常的狭窄领域，不用跨领域的理解，而且可以快速产生商业价值。再往下医学，如何看片子，看MRI，看CT，看各种人的健康记录一定是超过医生的，现在至少有3种重要的病症人工智能已经超越了医生的平均水平，而且你像这个是要花多少临床的时间，现在三种可能再过5年就是300种，再过10年可能就是3000种。

然后90%的医生就都不需要了，至少被机器取代。那这些医生就要做更高等的工作，更深入的工作，去发掘新的医药的工作，或者是做更心理医疗的工作。面对病人，机器还是冷冰冰的，可能还需要一个人脸对着病人，但是90%的医生，在10年以后应该都打不过我们机器的诊断能力了。这对人类是有很大意义的，教育的数据也是很多的，就不多细讲。

最右边是无人驾驶。这是我们特别看好的领域，它是最大颠覆量的，以后都不需要人开车了。再加上电动车和共享经济，以后我们出门的时候，一辆坐一人的车就会出现在我们面前，它带我们去要去的地方，节能低碳，减少雾霾，而且这还会影响整个经济。如果大家谁有投资停车场的，十年以后就没有停车场了。所以，这些都有巨大的颠覆性。

如果你们觉得听起来像是天方夜谭，像是科幻小说，那么你们也可以想一想，2009年当我告诉所有人移动互联网时代来临的时候，大部分人也是这样想的。甚至当时的BAT听了移动互联网的预测之后，他们总是认为没有PC大，没有PC赚钱，成长的会很慢。但现在你看他们一个个也都追上来了。所以人工智能是一个特别巨大的领域和机会。

## 那么我们到底该和谁学人工智能呢？

![](https://pic.36krcnd.com/201611/30013046/bbzvjnx4ynp1bjrb!1200)

世界上最懂人工智能的绝对是谷歌这个公司了。在一年前他就宣布了要做Alphabet这个母公司。

什么是Alphabet呢？其实它就是把谷歌里面做搜索提炼出来的人工智能做成谷歌大脑，然后把它用到各种领域。用在围棋就成了AlphaGo，我们已经看到它的威力有多大了，用在汽车就是Google car，用在健康就是Google house用在基因检测就是Google genetics，所以在Alphabet上面，谷歌的野心就是要把一个谷歌的成功变成26个，这是一个特别有野心的人工智能的公司。

![](https://pic.36krcnd.com/201611/30013046/fhrj337v4odq88t4!1200)

而这个公司内部也是在用刚才所说的深度学习。这个图是来自谷歌的一个科学家，他对外演讲用的我们可以看到也是在这4年，他们才领悟了人工智能的价值和谷歌大脑的价值，收购了Deep Mind这样的公司。所以很明确的就是，谷歌的Alphabet这样的一个动作，绝对是它看到了机器学习可以进入各种领域的机会，这也是它所进行的一个很有野心的探索。

## 到底人工智能如何克服挑战产生竞争壁垒呢？

![](https://pic.36krcnd.com/201611/30013047/jsixymujm7nq4psb!1200)

简单的来说。

- 第一，就是要寻找行业里面有特别大的大数据，然后是垄断性和闭环的。

- 第二，是买很多机器，尤其是CPU＋GPU。

- 第三，是有很厉害的深度学习的科学家。左边两个，谷歌基本是为了买这两个人，花出1亿到4亿美金，右边的是我们投资的Face++公司聘了的，刚才看到的2015年超越人脸识别，超越世界图像识别人类能力的那位科学家孙剑，他是我们Face++挖过来的，这边就不放金钱了。

  因为我们投的公司不好意思去说我们花了多少钱雇了这样一个人，但是至少可以说明一点的是，这样的大脑是有特别巨大的价值的。

- 第四，虽然这些顶尖科学家很有价值，同样的小朋友也有价值。不过小朋友还不能创业，需要培训。只要我们找到前10名的高校毕业的顶尖毕业生，这些毕业生必须是学下面几个领域，计算机、统计、数学、应用数学，电子系，还有自动化系。在这6个科系里面的顶尖学生，前10学校的前10到50名的学生我们全部招进创新工场我们来培训他，成为人工智能科学家。

只要给我们6个月的时间，然后有左边的这些高手来带他们一下。人工智能很大的一个特色是速成，他不像是你去找一个化学科学家，或者说生物科技或者甚至是计算机领域的这个Networking 、Database之类的，非常难学。人工智能不一样，它很好学，==前提是你一定要是一个数学天才==。所以我们就设立这样一个计划，这是人工智能很大的一个特点，是可以速成快速创造价值的。

这个可能主要是对产品的探讨，这里就不多说了。

## 接下来说下怎么样让人工智能快速商业化，虽然它的技术还不够好。

![](https://pic.36krcnd.com/201611/30013047/w13cviu9t53j0hv9!1200)

有四个理由：

- 第一是做助手，而非取代人；
- 第二是界面要用好，给很多结果，而不只是一个结果；
- 第三草船借箭，要用户提供数据，如果你的数据不够；
- 第四局限你的领域，不要做一个特别伟大的超级的技术。

**下面我要讲的是中国的一些特别的机会。**

![](https://pic.36krcnd.com/201611/30013047/es43aglzqotypma3!1200)

中国在人工智能领域比移动互联网领域还适合创造世界顶尖的公司。

- 第一个理由就是，**中国人很适合做人工智能**。我们知道美国的很多中学的学生，加减乘除都做不好，我们中国虽然教育有很多的挑战和问题，但是理工科的学生平均水平特别强，人数又特别多，所以==今天在世界上做人工智能的科学家有43%是中国人==，所以我们可以知道，当然很多是在海外读书，现在要把他们拉回来，所以这是一个特别大的机会。
- 第二，**训练小朋友非常快速**，这刚才已经讲过了。
- 第三，**传统企业的人工智能技术非常的弱**。就是他们现在的这个产品，是没有用人工智能，相对来说是很弱。

> 比如说我们现在做一个Credit Card Fraud Protection。就是去识别信用卡被盗卡的这样一个现象，比如说我突然在这个阿布达比刷了2万块钱银行就会警觉了，实际上很多偷信用卡的人，比这个聪明，他不会去刷2万块钱，他会刷100块，200块，他还会到各种城市去刷，也许就是请朋友吃顿饭之类的。我最近的信用卡就是这样被盗的。
>
> 这个如何抓呢，美国的银行做信用卡已经做了40年，他们靠非人工智能的技术，就是一条一条的规则写进去，然后把用户做各种的规则，比如这个人收入是怎么样的。然后如果他突然飞到几千里之外，用的金额是什么，如果有三次什么之类的。这样一大套，如果是这个就怎么样，如果不是这个就怎么样，套这个来做这个信用卡的盗卡的识别。那这些银行没有人工智能，但是这些技术在美国做的很好。
>
> 所以要在美国做人工智能的公司，去卖这样一个Credit Card Fraud Protection技术给银行是不靠谱的也是不可能的。除非你是有拿了大数据来做，不过那得有多难。
>
> 但是在中国几个小朋友随便写一个简单的机器学习算法，深度学习都不用，拿到中国的任何银行马上就能产生价值。所以呢，过去这些银在国内不太开放，技术也比较落后，不太愿意别的技术进来，还是要感谢AlphaGo 自从它打败围棋世界冠军以后，中国的银行开始相对开放了。我们投的一些公司，比如说第四范式就已经进入了十五家银行，产生了特别大的价值。
>
> 银行曾经不是经常打电话给我们说，要不要买什么产品，过去它的这个转化率非常低，但是经过我们人工智能一条就增加了65%。所以以后银行打的垃圾电话，经过创新工场投资的这个第四范式，精准度会比较高。过去1000个电话买1个，现在接600个电话就会买一个。
>
> 这个对于你来说，都是让人烦扰的电话，但是对银行来说，产生了多大的价值，它如果一年靠这个电话卖20亿的产品，现在就卖33亿了，因为有了之前说的那65%的成长。所以这一类的人工智能在国内因为它的算法竞争对手太弱，在银行保险、券商等等的机会特别大。
>
> 在座可能有些看过量化交易的，但是你们看的量化交易都是没有智能的，都是拼速度的。但是加上智能就不得了。我读博士的时候就是做人工智能，我的一个同学跟我学一样语音识别，但是他比我聪明，我毕业之后去苹果了，他去了文艺复兴科技公司（Renaissance Technologies）。它是美国做量化交易第一的公司，他在那边做了30年，然后我们在Wikipedia可以看到他的这个身价大概是我的几十倍。
>
> 当然我说的不是这个，更重要的是说他把机器算法很早就做到了二级股票市场交易中去了。他们内部基金每一年的年化收益，20年，71.8%。这就是人工智能的力量。当然这个基金做不大，一做大这个收益就会下来，但是至少也还是几十亿的规模。所以你可以看到，这些机会，是非常非常的大。
>
> 当然30年前美国的股票交易也很落后，量化一进去，就把大家都击溃了。他今年是Renaissance的CEO，你可以看到在这种算法里，科学家的力量是多大。整个Renaissance的公司至少在创立的时候，都是不懂股票的，一大堆算法进来，交易大师就打不过他们了。
>
> 那么在中国，这个景象正在发生。我们看到的人工智能的项目里，三个就有一个是做股票交易的。在过去两年里面，我除了个人买了一支股票之外，其他的钱都是交给这些小朋友打理，他们在国际国内港股A股的这些市场，加上做这些AI的对冲，每一天大部分交易就是T或者T＋1，然后就结算，基本没有什么风险，收益率也没有一个月是负的，每一年的回报虽然不到71.8%，但是也是很高的。
>
> 所以这是一个特别大的机会，在国内量化AI的环境还不成熟的时候，如何找到这些机会，可能获得的是比VC的基金或者PE的基金回报都还要高。

- 第四个理由，因为**中国市场大，互联网公司多，很多非AI的公司到了一定的规模，就开始需要AI**。比如我们投资的美图，知乎，VIP KID。我们也恭喜美图准备在香港上市，我们是美图最早的投资人，也非常看好，我们会继续的持有，非常看好他。

> 美图的这个公司呢，你可能觉得就是帮助女孩子变漂亮一点，但是变漂亮的过程中你要知道大家都喜欢哪样的漂亮，得到用户回馈，加入AI算法这个是非常重要的。从这里我们可以学到，中国的女孩子喜欢非常的白，但是印度的女孩子白一点就好，非洲的女孩子也希望白一点。
>
> 中国的女孩子希望眼睛越大越大，但是美国的稍微加一点点眼影就可以了。修改以后就看用户是否喜欢不喜欢，**这个可以做人工智能的回馈**，甚至人工智能还可以生成，可以帮助来推测，你会喜欢什么样的照片，或者甚至把你变成卡通画，或者是一张很美的像画出来的画一样。这是第四点。

- 第五点，**美国人工智能现在是绝对领先中国的，但是他们进不了中国，中国上面有各种理由**。因为美国公司进不来，给我们3年时间就不输于美国公司了。人工智能的这个技术都是美国和加拿大做出来的，他们是非常乐于公开的，每次写完了就放到网上，放到网上大家就学去了，中国和美国的公司一起学，所以这也没有太大的门槛。中国的公司只要给我们3年的时间，给我们更多的机会，我们一定会产生和美国一样的价值。


- 最后一点是**中国对人工智能各方面的约束较少**。比如说Trump上台以后，假如我们两年以后发现Uber的Otto，这个Otto它是取代卡车司机的，假如它做的非常好，两年以后会取代这个人类的话，会不为有这个卡车的工会冒出来一起抗议。

> 美国有150万的卡车司机，他们也是投了Trump票的，我们也很清楚低收入的美国中年男人尤其是白人投了这个票，这些人要是抗议，会不会有可能通过一个法律使得卡车无人驾驶先暂缓推出，或者先要证明自己不伤人之类的。就这样，很简单的一个规矩就把这个技术给放缓了。所以我觉得中国在这方面就会有更大的机会。
>
> 还有无**人驾驶最大的敌人是什么**？第一是法律，第二是人。我们人是最差劲的司机了，容易犯困，要睡觉，还喝酒，然后犯错，而且不可预测等等。机器则是非常冷静的，但是它面对这些不冷静的人也会很头疼。如果某一天这个城市里都是无人驾驶的车，不允许人开车了，这一天就是技术飞腾的时候了。那么哪个国家会有可能做这样一个小城市？肯定不是美国，但有可能是中国。你可以想象，如果路上都没有人了，车子也都安全了。
>
> 比如说一辆车可以告诉后面的车，我爆胎了，你小心一点。甚至你可以想象这样的一个环境，车子会说我的主人急着上班，请你让我一下，我给你2毛钱，这些情况都可以发生，前提是人要被赶出去，所以我非常急迫希望人类不要开车。

创新工场对人工智能有一个很完整的投资蓝图，在这里我想就不适合讲太多的细节了。

![](https://pic.36krcnd.com/201611/30013047/7oxip9kjhwvjr02w!1200)

**讲几个重点。**

- 第一个重点是**大数据的机会**，这是现在面临的，也是即将到来的一个巨大的机会。
- 第二个是**语言方面**，听到的语言不代表听懂的语言，所以人类的语言，对自然语言的理解还是一个很大的问题，所以要推到接近10年以后。
- 第三，是**传感器的降价非常的重要**。现在它太贵了，但是我们非常有信心在无人驾驶和机器人的推广下，量产它就会降价，所以这可能需要3年的时间。机器人，我们都认为，家庭机器人基本不靠谱。因为我们科幻片看太多了，尤其是机器人有眼睛、耳朵、手脚，所以把我们的期望值就变得太高了。

我们更看好的是家里的家电，比如说Amazon Echo，是个音响，但是它也慢慢的变聪明了，放的是周杰伦它能知道，放的是古典音乐它也都知道，过几天你说，家里没有牙膏了，它还能马上跳出来说京东立刻帮你寄到家里。这些功能在美国已经实现了，京东当然也做了类似的这样的技术，这些我觉得还是比较靠谱的。还有我们投资的小鱼在家，这些产生陪伴这类功能的是可以的，但是前提是家庭机器人一定不可以有眼睛、耳朵、手和脚，听到这样的项目你赶快跑。

最后是自动驾驶，它需要时间，就像刚才所说的。

## 那么创新工场在人工智能领域在做什么呢？

![](https://pic.36krcnd.com/201611/30013047/jkfggiv6xd34ulkl!1200)

右边我们在做VC，我们投了很多国内的公司，包括刚才讲的美图、Face++，第四范式、地平线机器人等等公司，也投了一批美国的公司。还有驭势科技，是国内领先的无人驾驶公司。当然这是VC的投资，如果说有好的创业者拿了项目来，我们可以像其他的VC一样可以投资他。

左边做的是一个人工智能的孵化，我们做了一个工程院，在直接的招顶尖的人工智能专家，还有一批刚毕业的学生，我们会出主意给他，买数据给他，拿机器给他，让他在这些方面，能够快速的探索，创造价值，然后出来创业，创业的时候我们的基金也可以投他。这个布局很像我们在移动互联网时代的布局。当我们有一些这个领域的优势的时候，我们认为这个是一个可行的方法。

![](https://pic.36krcnd.com/201611/30013047/wgrrpkw7qt0200sj!1200)

VC投资就不多说了，我们一共管理大概12亿美金的基金，这是我们些投资的公司，这里刚才讲的差不多了。

![](https://pic.36krcnd.com/201611/30013047/gyq13a5mx4yqsmwg!1200)

再提一个美国的项目，中间下面是Wonder Workshop，它是一个人工智能的玩具。它可以跟着小朋友，就像现在的这个大疆新的机型，可以让它跟着你一样。甚至两个机器可以在一块玩等等，很有趣的。它是一个没有眼睛、耳朵、手与脚只是几个小轮子做的这样的一个机器人，我们认为这个领域也像Echo音响一样是有机会的。

![](https://pic.36krcnd.com/201611/30013047/4iz3o7rlv1cb6w8q!1200)

那么讲到创新工场人工智能工程院，刚才我们也说过了，我们会找一批专家带一批学生，买大量的数据，数据也包括了金融交易的数据。其实现在美国有很有意思的公司，我觉得国内也有一些类似的公司，就是把这个量化交易做成一种竞赛，把这些数据全部弄好了，然后这些小朋友上去比算法，然后Backtesting，看看过去3年，5年，10年可以赚多少钱.谁做的更好，我们基金就跟他分红，当然，这里说的不是我们创新工场的基金，它指的是一个特殊的量化基金，这是一种比赛。

然后还有无人驾驶和一些识别之类的也是一些领域。我们认为在AI科学家，AI时代的创业呢，都是科学家。科学家呢，不知道怎么买数据，没有钱买机器，不懂商业，我们可以在这些方面补足，所以这是一个很特殊的新的做法。

![](https://pic.36krcnd.com/201611/30013047/0dz9l83zrqrzaoyi!1200)

那我们在这方面的布局也得到不少国内外的认可，在纽约时报、华尔街日报、Forbes等也都有报道我们的投资和我们投资的一些公司。

## 最后我答应告诉大家三个秘密，如何去做早期公司的投资。

第一个怎么投资公司。刚才我已经说过了，要衡量它有没有大数据，然后有没有独特的大数据，不是买来的大数据，有没有科学家，有没有闭环，有没有很多机器。然后他做的这个领域，是不是可以产生商业价值的领域，还是一批科学家在瞎搞。这是第一个。看这些项目要小心，还有看机器人的项目，有眼睛耳朵手与脚的就千万不要再听了，虽然听起来很酷。无人驾驶可以去想想怎么去参与。

这是投公司的，投基金呢？投创新工场和真格基金就可以了。

至于买股票呢？我是美图的董事，可能下面不适合说，但是你应该知道我要说什么，我们看好美图，认可美图。

刚才也分享了，量化AI在国内的投资应该机会特别大，这不是一个人工智能投资，这是一个真的二级市场的投资，当然要避免一些法律所不允许的事情，但是机会还是很多。那么我们现在也在专门看这个量化AI投资，对于这些呢，如果有兴趣的我们也可以一起以后在别的机会一起探索。

我也给大家说了，过去两年，我所有的资产基本都是在创新工场里，除了一栋房子，创新工场，我所有的资产基本上都是交给机器人管理，都是用AI量化来管理。这个也就是告诉你我对这个领域是多么看好和认可。

当然三年后这个领域可能就是红海了，只是说现在的机会是非常好的。

当然我还有一支股票是例外的，是我孩子决定要投资的。就像如果说在移动互联网时代，二级市场最好的投资标的是ARM，人工智能的时代是什么？大家确实可以看一看NVIDIA。

关于作者：

> 李博士曾以最高荣誉毕业于哥伦比亚大学，并于1988年获卡内基梅隆大学计算机学博士学位。曾就职于Google，微软，苹果等世界顶尖科技公司，并分别担任全球副总裁职务。2013年还被入选为《时代周刊》全球最有影响力100人榜单。2009年9月李博士在中国北京创立创新工场，帮助中国青年成功创业，创新工场立足互联网、移动互联网和云计算等领域，培育了一大批创新人才和众多新一代高科技企业。



# 百度人工智能云平台——“天智”

在2016百度云智峰会上，百度正式对外发布了自己基于云的人工智能应用平台——天智。这个平台由三个部分组成，分别是感知平台、机器学习平台与深度学习平台。

![](https://pic.36krcnd.com/avatar/201611/30063743/uoemuwk3jyicrjob.png!1200)

> 对于用户来说，三个平台的应用方式并不相同

其中，感知平台已经在今年9月百度世界大会上被详细介绍过，这个平台主要输出是图像技术、语音技术、自然语言处理的技术。

![](https://pic.36krcnd.com/avatar/201611/30064013/rfb5vcj971rolv0p.png!1200)

> 感知平台

其中，图像技术的话包括了文字识别、人脸识别等等，而语音技术包括了语音的识别和语音的合成，声纹的识别等等，而自然语言处理则包括了百度的NLP Cloud的能力。

百度云事业部总经理刘炀在解释这个平台的作用时，提示我们需要记住一个字——聪明的“聪”。他表示，**“聪”是由耳目口心组成的**，而“耳目口”的功能都是百度感知平台能做到的——**语音识别、图象识别以及对自然语言合成**。

因此，在他看来，与其他两个平台相比，百度感知平台有一个特点：由于这个平台都是基于百度自己搜集的大量人机交互数据来学习并生产模型，所以其API能够由外部直接进行调用。因此，用户其实不需要我们弄懂其中的技术细节就能使用。 

换句话说，感知平台可以触及的用户群体在三个平台中也是最大的。

**第二个是机器学习平台，与感知平台不同，机器学习平台实际上是百度提供的托管服务。**

![](https://pic.36krcnd.com/avatar/201611/30064133/7d74vm3xe8n97nfi.png!1200)

> 机器学习平台

在这个机器学习平台上，百度将数据训练的流程打通，与天算平台（智能大数据平台）进行了深度集成。

此外，这个平台内置了二十多种常用的机器学习算法，支持业界标准Spark MLlib，同时也对应了百度内部的海量数据和常用模板。

但使用这个平台需要用户提供自己的数据。刘炀解释，如果是一秒钟就要解决的事情，用户可以通过感知平台来解决。但如果需要基于大量重复发生的数据进行预测，百度的机器学习平台则非常适合这样的场景。

刘炀举了一个例子，如果你在物流领域掌握大量数据，就可以预测下一次从A地到B地哪一条路最短最方便，这是适合机器学习平台去解决的问题。

**所以，可以使用机器学习平台的用户必须本身就掌握了大量行业数据。**

**第三个平台是深度学习平台。百度在今年9月已经对深度学习框架进行开源。而今天，作为百度内部大量数据系统组成的深度学习平台，PaddlePaddle在今天也正式对全球开发者进行开放。**

![](https://pic.36krcnd.com/avatar/201611/30064216/ebff4356i6vhtoot.png!1200)

> 深度学习平台

据刘炀介绍，这平台拥有大量神经网络算法，运行十分高效灵活。如果用户对小规模数据进行研究，可以单机进行；但如果数据量达到一定规模，基于一个分布式系统就可以运行并建立模型；如果数据量非常庞大，则需要有CPU的集群来进行学习。

那么深度学习平台适合于什么样的用户？其目标用户群体肯定比感知平台及机器学习平台的用户群要窄，它更适合于数据科学家以及专业级别非常高的工程师，因为用户必须对数据模型运作有深刻的理解才能使用这个数据学习平台。

但当前的“天智”仅仅初级1.0版本，也就是说，百度的人工智能云平台未来还有很长的路要走。

目前，百度在机器学习领域的发展其实还处于“感知”阶段，对于“认知”等需要靠深度学习才能解决的问题，百度的水平其实还没有达到一定的高度。

---

# 人工智能那些事儿：深度学习VS机器学习VS模式识别

我们来关注下三个非常相关的概念（深度学习、机器学习和模式识别），以及他们与2015年最热门的科技主题（机器人和人工智能）的联系。

**![1472087265-4344-eaPgx850MbqaEe5Ag4LInUrAphIg](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290598702407.jpg)**

图1：人工智能并非将人放入一台计算机中（图片来源于WorkFusion的博客）

环绕四周，你会发现不缺乏一些初创的高科技公司招聘机器学习专家的岗位。而其中只有一小部分需要深度学习专家。我敢打赌，大多数初创公司都可以从最基本的数据分析中获益。那如何才能发现未来的数据科学家？你需要学习他们的思考方式。

**三个与“学习”高度相关的流行词汇：**

模式识别（Pattern recognition）、机器学习（machine learning）和深度学习（deep learning）代表三种不同的思想流派。模式识别是最古老的（作为一个术语而言，可以说是很过时的）。机器学习是最基础的（当下初创公司和研究实验室的热点领域之一）。而深度学习是非常崭新和有影响力的前沿领域，我们甚至不会去思考后深度学习时代。我们可以看下图所示的谷歌趋势图。

可以看到：

> *1）机器学习就像是一个真正的冠军一样持续昂首而上；2）模式识别一开始主要是作为机器学习的代名词；3）模式识别正在慢慢没落和消亡；4）深度学习是个崭新的和快速攀升的领域。*

![1472087265-7794-58yY7lzKvjuuoEUfRkTFgvT95wrg](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290598571763.png)

2004年至今三个概念的谷歌搜索指数（图来源于谷歌趋势）

**一、模式识别：智能程序的诞生**

模式识别是70年代和80年代非常流行的一个术语。它强调的是如何让一个计算机程序去做一些看起来很“智能”的事情，例如识别“3”这个数字。而且在融入了很多的智慧和直觉后，人们也的确构建了这样的一个程序。例如，区分“3”和“B”或者“3”和“8”。早在以前，大家也不会去关心你是怎么实现的，只要这个机器不是由人躲在盒子里面伪装的就好（图2）。不过，如果你的算法对图像应用了一些像滤波器、边缘检测和形态学处理等等高大上的技术后，模式识别社区肯定就会对它感兴趣。光学字符识别就是从这个社区诞生的。因此，把模式识别称为70年代，80年代和90年代初的“智能”信号处理是合适的。决策树、启发式和二次判别分析等全部诞生于这个时代。而且，在这个时代，模式识别也成为了计算机科学领域的小伙伴搞的东西，而不是电子工程。从这个时代诞生的模式识别领域最著名的书之一是由Duda&Hart执笔的“模式识别（Pattern Classification）”。对基础的研究者来说，仍然是一本不错的入门教材。不过对于里面的一些词汇就不要太纠结了，因为这本书已经有一定的年代了，词汇会有点过时。

![1472087265-2466-NgSHNMnYwfN6ic63xvCiaqtaqDfQ](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290598126186.jpg)

图2：一个字符“3”的图像被划分为16个子块。

自定义规则、自定义决策，以及自定义“智能”程序在这个任务上，曾经都风靡一时。（更多信息，可以查看这个OCR网页）

**小测试****：**计算机视觉领域最著名的会议叫CVPR，这个PR就是模式识别。你能猜出第一届CVPR会议是哪年召开的吗？

**二、机器学习：从样本中学习的智能程序**

在90年代初，人们开始意识到一种可以更有效地构建模式识别算法的方法，那就是用数据（可以通过廉价劳动力采集获得）去替换专家（具有很多图像方面知识的人）。因此，我们搜集大量的人脸和非人脸图像，再选择一个算法，然后冲着咖啡、晒着太阳，等着计算机完成对这些图像的学习。这就是机器学习的思想。“机器学习”强调的是，在给计算机程序（或者机器）输入一些数据后，它必须做一些事情，那就是学习这些数据，而这个学习的步骤是明确的。相信我，就算计算机完成学习要耗上一天的时间，也会比你邀请你的研究伙伴来到你家然后专门手工得为这个任务设计一些分类规则要好。

![1472087265-1405-bibeBlXOt9NxhKd63ciaOOFImYwQ](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290599543104.jpg)

图3：典型的机器学习流程（图来源于Natalia Konstantinova博士的博客）。

在21世纪中期，机器学习成为了计算机科学领域一个重要的研究课题，计算机科学家们开始将这些想法应用到更大范围的问题上，不再限于识别字符、识别猫和狗或者识别图像中的某个目标等等这些问题。研究人员开始将机器学习应用到机器人（强化学习，操控，行动规划，抓取）、基因数据的分析和金融市场的预测中。另外，机器学习与图论的联姻也成就了一个新的课题—图模型。每一个机器人专家都“无奈地”成为了机器学习专家，同时，机器学习也迅速成为了众人渴望的必备技能之一。然而，“机器学习”这个概念对底层算法只字未提。我们已经看到凸优化、核方法、支持向量机和Boosting算法等都有各自辉煌的时期。再加上一些人工设计的特征，那在机器学习领域，我们就有了很多的方法，很多不同的思想流派，然而，对于一个新人来说，对特征和算法的选择依然一头雾水，没有清晰的指导原则。但，值得庆幸的是，这一切即将改变……

**三、深度学习：一统江湖的架构**

快进到今天，我们看到的是一个夺人眼球的技术—深度学习。而在深度学习的模型中，受宠爱最多的就是被用在大规模图像识别任务中的卷积神经网络（Convolutional Neural Nets，CNN），简称ConvNets。

![1472087265-3034-PvwQplt30kqaG0elvnP5UicuAanQ](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290599210210.png)

图4：ConvNet框架（图来源于Torch的教程）

深度学习强调的是你使用的模型（例如深度卷积多层神经网络），模型中的参数通过从数据中学习获得。然而，深度学习也带来了一些其他需要考虑的问题。因为你面对的是一个高维的模型（即庞大的网络），所以你需要大量的数据（大数据）和强大的运算能力（图形处理器，GPU）才能优化这个模型。卷积被广泛用于深度学习（尤其是计算机视觉应用中），而且它的架构往往都是非浅层的。

如果你要学习Deep Learning，那就得先复习下一些线性代数的基本知识，当然了，也得有编程基础。我强烈推荐Andrej Karpathy的博文：“神经网络的黑客指南”。另外，作为学习的开端，可以选择一个不用卷积操作的应用问题，然后自己实现基于CPU的反向传播算法。

对于深度学习，还存在很多没有解决的问题。既没有完整的关于深度学习有效性的理论，也没有任何一本能超越机器学习实战经验的指南或者书。另外，深度学习不是万能的，它有足够的理由能日益流行，但始终无法接管整个世界。不过，只要你不断增加你的机器学习技能，你的饭碗无忧。但也不要对深度框架过于崇拜，不要害怕对这些框架进行裁剪和调整，以得到和你的学习算法能协同工作的软件框架。未来的Linux内核也许会在Caffe（一个非常流行的深度学习框架）上运行，然而，伟大的产品总是需要伟大的愿景、领域的专业知识、市场的开发，和最重要的：人类的创造力。

**其他相关术语：**

1）大数据（Big-data）：大数据是个丰富的概念，例如包含大量数据的存储，数据中隐含信息的挖掘等。对企业经营来说，大数据往往可以给出一些决策的建议。对机器学习算法而言，它与大数据的结合在早几年已经出现。研究人员甚至任何一个日常开发人员都可以接触到云计算、GPU、DevOps和PaaS等等这些服务。

2）人工智能（Artificial Intelligence）：人工智能应该是一个最老的术语了，同时也是最含糊的。它在过去50年里经历了几度兴衰。当你遇到一个说自己是做人工智能的人，你可以有两种选择：要么摆个嘲笑的表情，要么抽出一张纸，记录下他所说的一切。

**结论：**

关于机器学习的讨论在此停留（不要单纯的认为它是深度学习、机器学习或者模式识别中的一个，这三者只是强调的东西有所不同），然而，研究会继续，探索会继续。我们会继续构建更智能的软件，我们的算法也将继续学习，但我们只会开始探索那些能真正一统江湖的框架。

---

# Pedro Domingos深度解析机器学习五大流派中主算法精髓

*本文联合编译：Blake 高斐*

![1472129861-5819-57bd8010454cd](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290653604725.jpg)

*Pedro Domingos是华盛顿大学计算机科学与工程学教授，也是国际机器学习协会的联合创始人之一。他 曾在IST Lisbon获得电子工程和计算科学的硕士学位，在加州大学Irvine分校获得信息与计算科学博士学位。而后在IST作为助理教授工作了两年，于 1999年加入华盛顿大学。他还是SIGKDD创新奖获得者（数据科学领域中最高奖项），也是AAAI Fellow之一。雷锋网(搜索“雷锋网”公众号关注)注：本文是Pedro Domingos在Google所作的机器学习演讲内容整理。*

![1472129848-8120-57bd808e3361f](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290654102906.jpg)

让我们首先从一个简单的问题开始，知识到底是从哪里来的？以前已知的三个来源有：

> 1.  **进化**——来自于你的DNA
> 2.  **经验**——来自于你的神经
> 3.  **文化**——这些知识来自于与他人交流，读书学习等

我们日常生活中几乎每件事都是来自于这三个方面的知识，最近出现了第四个来源，那就是计算机。现在有越来越多的知识是来自于计算机（这些知识也是被计算机发现的）。![1472129848-4519-57bd80a38c693](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290654110940.jpg)

计算机来源的出现对于前三个来说是非常大的改变，**进化天然就存在于地球上**。**经验是将我们与动物以及虫类分类开的原因**，**文化则是使得我们之所以为人的根本**。

这四种中每一种与前者的差别都是数量级的差异，后者也能发现更多的知识。计算机比之前三种要快几个数量级，且能与其他几种实现共存。

![1472129851-4432-57bd80a6f328d](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290655202163.jpg)

Yann Lecun——Facebook AI研究组主任

> 未来世界上大多数知识都将被机器提取，且将留存在机器中。

所以，机器学习不但对于计算机科学家来说是一个大的改变，对于普通人来说也是他们需要理解的一件事。

![1472129849-8902-57bd80a8e7a32](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290655437288.jpg)

## 那么计算机到底是如何发现新的知识的呢？

1.  **填补现有知识的空白**

   和科学家工作的方式很像，观察——做出假设——通过理论来进行解释——成功（或失败，尝试新的）等

2.  **大脑仿真**

   世界上最伟大的学习机器就是人的大脑，因此让我们对它进行逆向工程。

3.  **模拟进化过程**

   进化过程，从某种角度来说甚至比人类的大脑更伟大（因为它造就了你的大脑，你的躯体，还有其他地球上的一切生命），所以来说这个过程值得好好弄清楚并且使用计算机来进行运算。

4.  **系统地减少不确定性**

   你学到的知识不一定正确，当从数据中获得什么东西时，你对它却不能完全确定。所以使用概率来量化这个不确定性，当你看到更多的证据时，不同的假设的概率能够进一步完善。还可以使用贝叶斯理论来进行这个工作。

5.  **注意新旧知识之间的相似性**

   通过类比来进行推理，在心理学上有证据说人类经常这样做。==当你面临一个情境时，你在以往的经验中寻找相似的情境，然后将这两者连接起来==。

![1472129849-1394-57bd817cb5ca7](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290656981813.jpg)

## 机器学习五大流派（主要算法）

- 符号主义——逻辑学、哲学——逆向演绎

> 相信填补现有知识的空白的

- 联结主义——神经科学——反向传播

> 希望从大脑运行方式得到启发

- 进化主义——进化生物学——遗传编码

> 遗传算法

- 贝叶斯派——统计学——概率推理
- 行为类推主义——心理学——机器内核（支持向量机）

### 符号主义

![1472129848-4892-57bd817f339f3](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290656798841.jpg)

> 符号主义代表人物：Tom Mitchell、Steve Muggleton、Ross Quinlan 

![1472129851-4811-57bd81823ea13](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290657110449.jpg)

> 逆向演绎

Tom Mitchell、Steve Muggleton、Ross Quinlan等认为学习是一个逆向演绎的过程，推理是从通用规则推导至特定事实，归纳刚好相反，从特定事实总结出通用准则。我们可以由减法和加法的相反关系来推倒出推理的原理。

![1472129853-1552-57bd82d5e3637](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290657964342.jpg)

> 逆向演理示例：

苏格拉底是人类+人类是凡人= 苏格拉底是凡人

（但是计算机现在还不能理解自然语言）

![1472129859-8533-57bd831dcb17d](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290658103250.jpg)

> 找出图中的生物学家

其实是那台机器，图中的机器是一名完整的、自动的生物学家，它也是从分子生物学中的DNA、蛋白质、RNA开始学习的。使用逆向演绎来进行假设，设计实验来测试这些假设是否成立（在没有人类的帮助下）。然后它给出结果，提炼假设（或者提出新的假设）。

### 联结主义

![1472129853-6532-57bd82db0ee03](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290658287710.jpg)

> 联结主义代表人物有：Geoff Hinton、Yann Lecun、Yoshua Bengio

![1472129853-8673-57bd82ddad728](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290659103913.jpg)

> 单一神经元

神 经元是一种非常有趣的细胞，看起来像树一样。神经元是具有长突触（轴突）的细胞，它由细胞体和细胞突起构成。在长的轴突上套有一层鞘，组成神经纤维，它的 末端的细小分支叫做神经末梢。细胞突起是由细胞体延伸出来的细长部分，又可分为树突和轴突。每个神经元可以有一或多个树突，可以接受刺激并将兴奋传入细胞体。每个神经元只有一个轴突，可以把兴奋从胞体传送到另一个神经元或其他组织，如肌肉或腺体。神经元之间是互相连接的，这样形成了一个大的神经网络。人类所学会的知识几乎都存在神经元之间的突触中，整个学习过程基本上是出现在一个神经元帮助另一个神经元发射信号的过程。

![1472129856-2503-57bd833e2a564](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290659102561.jpg)

> 人工神经元模型

人工神经元的工作过程：将输入加权组合，

例如：每个输入都是像素，每个都进行加权组合，当其超过阈值时会得到输出为1的结果，否则得到的就是0的结果。

再如输入是猫，当所有的加权组合起来超过了阈值，神经元就能识别出来：这是只猫。

![1472129859-9529-57bd83404608e](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290660128161.jpg)

> 反向传播

- 问题一：你如何训练这些神经元的网络？

  神经网络拥有一大堆神经元，需要通过一层一层计算才能得到输出。

- 问题二：如果运算中出现错误了怎么办？如何在整个大型、紊乱的神经网络中进行调整，来得出正确的答案？

  当出现错误，神经元本应该发射信号时，实际上却不会。出现问题的神经元可能是整个网络中的任一一个，但是想要找出它来却十分困难。这就是反向传播能解决的问题，当人们在20世纪60年代设想出神经网络时，他们并没有想到这个反向传播的方法，它最终是在19世纪80年代由David Rumelhart等人提出的。

  反向传播的基本理念是十分直观的，举例来说，理想输出应该是1，但是实际输出确是0.2，需要将其增大。

- 问题三：怎样调整权重才能让其增大？

  通过后续的神经元向前序神经元进行反馈，一层一层向后直到得到的值接近真实值，这就是反向传播算法（也是深度学习的核心所在）。


![1472129855-4920-57bd8342d4e28](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290661887917.jpg)

近期以来深度学习被用于各种领域中，证券市场预测、搜索、广告、视频识别、语义识别等。不过对于大众来说，最有名的应该是Google推出的能识别猫的神经网络——在当时，它是有史以来最大型的神经网络（可能超过10亿参数）。

### 进化主义

![1472129856-9831-57bd8345bcf87](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290661138144.jpg)

> 进化主义代表人物：John Holland、John Koza、Hop Lipson

进化理论认为反向传播只是在模型中调整权重而已，而没有整个弄明白大脑的真正来源是什么。所以要搞清楚整个进化过程是如何进行的，然后在计算机上模拟同样的过程。

![1472129867-2531-57bd83495f11d](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290662892479.jpg)

> 遗传算法是如何工作的？

遗传算法（Genetic Algorithm）是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，是一种通过模拟自然进化过程搜索最优解的方法。遗传算法是 从代表问题可能潜在的解集的一个种群（population）开始的，而一个种群则由经过基因（gene）编码的一定数目的个体(individual) 组成。每个个体实际上是染色体(chromosome)带有特征的实体。染色体作为遗传物质的主要载体，即多个基因的集合，其内部表现（即基因型）是某种 基因组合，它决定了个体的形状的外部表现，如黑头发的特征是由染色体中控制这一特征的某种基因组合决定的。因此，在一开始需要实现从表现型到基因型的映射即编码工作。不同的人是通过他们的基因进行区分的，但是与人类不同，计算机的构成单元只是比特符（0和1）。遗传算法（Genetic Algorithm）是一类借鉴生物界的进化规律（适者生存，优胜劣汰遗传机制）演化而来的随机化搜索方法。它是由美国的J.Holland教授1975 年首先提出，其主要特点是直接对结构对象进行操作，不存在求导和函数连续性的限定；具有内在的隐并行性和更好的全局寻优能力；采用概率化的寻优方法，能自动获取和指导优化的搜索空间，自适应地调整搜索方向，不需要确定的规则。遗传算法的这些性质，已被人们广泛地应用于组合优化、机器学习、信号处理、自适应 控制和人工生命等领域。它是现代有关智能计算中的关键技术。

遗传操作是模拟生物基因遗传的做法。在遗传算法中，通过编码组成初始群体后，遗传操作的任务就是对群体的个体按照它们对环境适应度(适应度评估)施加一定的操作，从而实现优胜劣汰的进化过程。

![1472129859-9621-57bd83aa0ba3d](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290662965719.jpg)

> 遗传编码

由于仿照基因编码的工作很复杂，我们往往进行简化，如二进制编码，初代种群产生之后，按照适者生存和优胜劣汰的原理，逐代（generation）演化产生 出越来越好的近似解，在每一代，根据问题域中个体的适应度（fitness）大小选择（selection）个体，并借助于自然遗传学的遗传算子（genetic operators）进行组合交叉（crossover）和变异（mutation），产生出代表新的解集的种群。这个过程将导致种群像自然进化一样的后 生代种群比前代更加适应于环境，末代种群中的最优个体经过解码（decoding），可以作为问题近似最优解。

![1472129859-2702-57bd83ac5d430](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290663719061.jpg)

当 下，遗传算法专家已经不满足于在电脑上进行模拟了，他们将自己的技术也带到了真实世界中——机器人技术。他们最开始用的是普通的机器人模式，当他们训练到足够好时，通过3D打印技术将整个机器人打印出来，打印出来的机器人真的能够进行爬行走动等动作。（hod lipson实验室）虽然这些机器人现在还不够好，但是相比它们刚起步的时候，已经发展的相当迅速了。

### 贝叶斯派

![1472129861-4804-57bd83af703a5](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290664508549.jpg)

> 贝叶斯派代表人物：David Heckerman Judea pearl Micheal Jordan

贝叶斯一直以来都是小众领域，其中Judea pearl是图灵奖获得者。

![1472129867-8231-57bd83b2cf6b4](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290664995540.jpg)

![1472129864-1294-57bd83b5f3666](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290665110690.jpg)

> 贝叶斯理论

贝叶斯定理是概率论中的一个定理，它跟随机变量的条件概率以及边缘概率分布有关。在有些关于概率的解说中，贝叶斯定理能够告知我们如何利用新证据修改已有的看法。

其中P(A|B)是在B发生的情况下A发生的可能性。

在贝叶斯定理中，每个名词都有约定俗成的名称：

- P(A|B)是已知B发生后A的条件概率，也由于得自B的取值而被称作A的后验概率。

- P(B|A)是已知A发生后B的条件概率，也由于得自A的取值而被称作B的后验概率。

- P(A)是A的先验概率或（或边缘概率）。之所以称为”先验”是因为它不考虑任何B方面的因素。

- P(B)是B的先验概率或边缘概率。

- 后验概率 = (相似度*先验概率)/标准化常量


也就是说，**后验概率与先验概率和相似度的乘积成正比**。

另外，比例P(B|A)/P(B)也有时被称作标准相似度（standardised likelihood），贝叶斯定理可表述为：

==后验概率 = 标准相似度*先验概率==

贝叶斯学习机制已经被应用于许多领域。例如，自动驾驶车辆的“大脑”中就配有贝叶斯学习机制。因而，在某种程度上，贝叶斯定理在帮助驾驶车辆或者帮助车辆学习如何驾驶方面起到重大作用。

![1472129867-4117-57bd6f0b6fad7](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290665221742.jpg)

> 贝叶斯学习机制应用——垃圾邮件过滤器

不过，大概人人都熟悉的一项贝叶斯学习机制应用为垃圾邮件过滤器。首个垃圾邮件过滤器是由David Heckerman及其同事共同设计的。他们仅仅运用一个非常建议的贝叶斯学习机，即初级（naive）贝叶斯分类器。下面是该分类器的工作原理：其基于的假设为——一封邮件是垃圾邮件或一封邮件不是垃圾邮件，当然这种假设是在我们检测邮件内容之前提出的。其中蕴含的先验概率为：当你判断一封邮件为垃圾邮件的先验概率为90%，99%，99.999%时，你的假设即为正确的。证明这一假设正确与否的证据在于邮件的真实内容。例如，当邮件内容含有“万艾可” 一词，这封邮件将在极大程度上被判定为垃圾邮件；当邮件内容含有大写全拼“FREE”一词，这封邮件将在极大程度上被判定为垃圾邮件；当“FREE”一词后面出现四个感叹号，这封邮件将在极大程度上被判定为垃圾邮件。当邮件署名出现你最好朋友的名字，这将降低这封邮件被判定为垃圾邮件的概率。因而，初级贝叶斯分类器就包含了这些“证据”。在一天结束时，该分类器将计算出一封邮件为垃圾邮件或非垃圾邮件的概率，基于计算得出的概率，分类器决定是否将该邮件过滤掉或将其发送给用户。垃圾邮件过滤器使我们能够有效管理自己的邮箱。

当下，各种不同的算法被应用于垃圾邮件过滤器。但是，贝叶斯学习机制是首个应用于垃圾过滤的算法，并在其他众多垃圾邮件过滤过滤器中得到应用。

### 行为类推主义

![1472129868-5293-57bd6f0f0af60](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290666111938.jpg)

> 行为类比推理法

最后，正如我提到的，行为类比主义者所持的基本观点为：我们所做的一切，所学习的一切，都是通过类比法推理得出的。所谓的类比推理法，即观察我们需要作出决定的新情景和我们已经熟悉的情景之间的相似度。早期行为类比主义的先驱之一为Peter Hart。他证实了，有些事物是与最佳临近算法相连的，这种算法是首个基于相似度的算法，稍后将对此详细讲解。Vladimir Vapnik发明了支持向量机，内核机，成为当时运用最广，最成功的基于相似度学习机。这些都是最原始的类比推理形式。人们，例如Douglas Hofstadter，也致力于研究许多复杂高端的学习机。Douglas Hofstadter不仅是著名的量化研究科学家和计算机科学家，也是“哥德尔，埃舍尔，巴赫”一书的作者。其最著名的书有500页，书中的观点是一切智能都只是类比。他强烈主张类比是主算法。

最佳邻近算法

![1472129862-9393-57bd6f1181ea0](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290667123458.jpg)

内核机

![1472129867-5054-57bd6f13d2d9f](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290667992958.jpg)

> 理解类比推理法的实例，最佳邻近算法及内核机

下面是一个用于理解这一观点的一个谜题。假设给出两个国家，由于所给出的是积极的例子和消极的例子，我赋予它们富有想象力的名字“Posistan”和 “Negaland”。在图中，我将不给出两个国家的边界线，只给出两个国家的主要城市的位置。Posistan的主要城市用加号标出，Positiveville为首都，Negaland的主要城市也用同样的方式标出。所给出的问题是：倘若我给出主要的城市，你能告诉我边界线的位置吗？当然，你并不能给出确定的答案，因为这些城市并不能决定边界线的位置。但是，这也是机器学习的问题所在。我们得学会概括。

最佳邻近算法能够为这一问题提供简单的答案。即如果地图上的一点临近某一个积极地城市或任何一个消极城市，那么我们可以假定这一个点位于Posistan。该假设将产生如下效果，即将地图划分为这个城市的邻近城市，如此一来，Posistan将成为这些积极城市邻近区域的联合国家。一个城市的邻近城市由那些离其最近的点构成。因而，便可得到一条锯齿状的边界线。尽管最佳邻近算法是如此简单，但是在学习阶段，这种算法甚至于不能起到任何作用，这一点是令人惊奇的。这个问题中所涉及的一些推理过程不是理想化的，其中之一便是，所得出得这条边界线可能不是最正确的，因为真正的边界线可能更为平滑。第二，倘若你仔细观察这幅地图，你可能舍弃一些城市，但是这一举动不会对最终结果产生太大影响。倘若舍弃这个城市，它将并入其他两个城市，最终的边界线不会发生变化。唯一需要保留的是那些界定边界线的城市，即所谓的“支持向量”，通常，这些向量存在于超空间内。因此，通常情况下，可以舍弃大量的城市，而不会对最终结果产生任何影响。 不过，在大数据集中，舍弃大量数据将对最终输出值产生影响。支持向量机，或简称为内核机，将解决这一问题。存在一种学习程序，能够舍弃对界定边界线来讲没 有必要的例子，保留必要的例子，如此一来，能够得到一条平滑的边界线。在确定边界线的过程中，支持向量机将使得边界线与其最邻近的城市之间的距离达到最 大。这边是支持向量机的工作原理。

> 推荐系统

![1472129867-7089-57bd6f162e2fa](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290668922171.jpg)

在深度学习盛行之前，支持向量机可能是应用最强健地学习算法。人们从20世纪50年代便开始运用这种基于类比的学习算法，因此这种学习算法基本上适用于地球上的一切事物。我们都体验过这种学习算法的应用实例，尽管可能没有意识到应用到了基于类比的学习算法。这便是推荐系统。例如，我想弄清楚推荐给你什么类型 的电影比较合适，当然民俗电影已经有20年的历史了，也是一种非常简单的电影形式。我将不用电影的类别进行推荐，因为人们的兴趣复杂多变，这在很大程度上 将是一个难题。我将采用一种“协同过滤”方法，即找到一些品味兴趣与你相似的五个人，这意味着你和他们一样给某部电影五个星，给另一部电影一个星。倘若他 们对一部你没有看过的电影五颗星，我便可以通过类比推理法假定，你也会喜欢那部电影，这样我便可以向你推荐这部电影。这种运用类比推理的“协同过滤”方法 取得了极好的成效。事实上，Netflix四分之三的业务得益于这种推荐系统。亚马逊也运用了这种推荐系统，这种系统为其业务的发展带来了三分之一的成 效。这些时间以来，人们运用各种学习算法来实现这一推荐系统，但是最佳邻近算法是最早应用于研究这一系统的学习算法，也是最优的算法之一。

## 机器学习五大流派，其中存在的问题及解决方案

![1472129864-2323-57bd6f5dc729f](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290668105556.jpg)

再返回来，我们之前讲到机器学习的五大流派，我们发现**每个流派都存在各自能够更好解决的一个问题**。**每一个流派都有一种特定的主算法，这种算法可以解决出现的问题**。例如，只有象征主义者能够解决的问题是**学习那些可以用不同形式组构的知识**，他们用**逆向推理**的方法学习这些知识。联结主义者**运用反向传播算法来解决信用分配问题**。进化论者**解决学习结构问题**。联结主义者**仅从一个固定的结构开始，进而调整权重值**。进化论者知道如何运用遗传程序提出一种学习结构。**贝叶斯学习机制均是研究不确定的事物**，他们知道如何就处理所有不确定的事物，他们参考大量数据便可以知道如何提高假说发生的概率。他们使用**概率推理法**，这种方法在算法上是非常有效的，能够将贝叶斯原理应用于超大的假说集中。最终，行为类比主义者**运用事物之间的相似度进行推理**。他们能够从一两个例子中概括推理。当时最好的类比算法当属核心机。但是，我想指出的是，因为每一个出现的问题都是真式且重要的，没有一种单一算法能够解决这些问题。**我们真正需要的是一种能够同时解决这五个问题的单一算法**。这样的话， 我们便需要一种==机器学习大统一理论==。事实上，我们已经朝向这个目标做出了很多努力，并取得了一定成就，但是我们仍然任重道远。

![1472129870-5428-57bd6f5fe0557](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290669143338.jpg)

![1472129871-6488-57bd6f62a95b3](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290669117958.jpg)

### 如何将五种算法化零为整

下面我将给大家呈现我们当前所处的研究状态。我们拥有五种算法或五种类型的学习方法，关键在于如何将其统一起来。看起来，这是一个难题，甚至有人声称，这是 一个难以实现的目标。这一目标之所以看似难以企及是因为这五种算法之间看起来是不同的。但是，仔细观察，这五种算法之间还是存在相通之处，它们都由三个相同成分构成，即**表征，评估，优化**。

我们将分析每一个成分具体指代什么，以实现五种算法的统一。**表征指学习者如何表示正在学习的知识，模型和编程**。学习者将用于编写算法的编程语言不是Java，或c++，或类似的任何语言，而应当是**一阶逻辑语言**。因此，我们的首要任务是统一这些表征方法。最自然的做法是运用象征主义者的表征方法，这里我们运用的是一阶逻辑的变体形式，而**贝叶斯用到的表征方法是图像模型**。这些表征方法已经得到极其普遍的运用。倘若能够将这两种表征方法相结合，我们可以用来表达任何一种事物。例如，任何一种计算机编程都可以运用一阶逻辑来表达。任何用于处理不确定事物或权衡证据的方法都可以用图像模型来表征。现在我们确实已经实现将这两种表征方法结合在一起的目标。事实上，我们已经发展形成各种形式的概率逻辑。应用最广泛的是**Markov逻辑网络**，该网络实际上是逻辑网络和Markov网络的结合体。该网络是一种非常简单的模型，由公式和一阶逻辑开始，然后赋予每一个规则于权重值。

接下来，任何一种学习算法的组成成分是评估。评估是一个分数函数，这个函数会显示一个候选模型的性能优劣。例如，该候选模型是否与数据，与我的目的一致。事 实上，**每一种学习问题在于能否找到实现评估函数值最大化的编程**。一个比较明显的候选模型是**贝叶斯使用的后验概率**。通常来讲，评估不应当成为算法的一部分， 评估结果应当由用户提供，用户来决定学习者应当优化的内容。

最后一个组成成分是优化，即**找到实现函数值最大化的模型**。因而，这里便有**遗传编程与反向传播算法的自然结合**，即去发现我们能够运用遗传编程的公式。在一阶逻辑中，每一个公式是一个树，我们可以穿越这些树，应用遗传过程来提出能够更好的公式。我拥有一个涉及到许多不同公式，事实，和不同步骤的推理链，所有的公式，事实，和不同的步骤都被赋予一定的权重值，我可以运用反向传播算法来学习这些权重。我们在这一块儿做出很多努力，但是还未成功。但是，有些人认为实现将五种算法统一为一种单一算法这一目标，仅仅是时间问题。我却不是特别乐观。 我个人认为，即使我们成功地实现这五种范式的统一，在此过程中仍会出现一些主要思想的丢失，还可能存在我们尚未拥有的想法，没有了这些想法，我们将不能拥有一种真正意义上的全面的学习机制。

## 浅论主算法的未来影响

![1472129872-2453-57bd6f68baa07](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290670981554.jpg)

我将针对主算法的未来影响稍作讨论，以此结束我们今天的演讲。在这里我提出四个术语。

- 第一个术语为**家庭机器人**。 我们都希望拥有一台家庭机器人能够为我们做饭，铺床，等等便利服务，但是，为何至今我们都没能实现这一目标？首先，要实现这一目标不能离开机器学习，现今 还没有任何一种程序能够使得机器人做任何其想要做的一切事物。其次，我们现有的学习算法还有待优化。因为家庭机器人在一天的工作任务中将会遇到所有这五种 问题，这将要求其能够解决所有的问题。因此，在主算法发展过程中，我们还需多做努力。

- 第二个术语为**网络大脑**。 每一个人， 包括谷歌在内，都试图将网络转变为一个知识库。我希望问问题并得到答案，而非查询关键字再返回到网页。但是，这便要求网络中所有的知识都要以计算机能够推理的方式表征出来，例如，一阶逻辑。另一方面，网络中到处充斥着冲突，噪音，差异，其他等等因素，因此我需要应用概率来解决这一问题。因而，需要统一这五 种学习算法，以便能够从网络中提取知识。

- 第三个术语为**癌症治疗**。 关于人体健康，治疗癌症可能是最重要的。可是，为什么我们还未找到治疗癌症的有效方法？问题在于癌症不是一种单一的疾病，每个人的癌症病症都是不同的。事实上，病人病情发展过程中，同一种癌症都会发生变异，因此，一种药物是不太可能治愈所有的癌症。癌症的一种真正治疗方法，或至少越来越多的癌症研究者认为，将依靠一种学习算法项目，这种项目能够包含病人的基因组信息，病史，肿瘤细胞的变异，以此来预测使用哪一种药物能够杀死这种肿瘤细胞，而不会对病人的正常细胞产生危害，或者使用一系列药物，或多种药物联合治疗，或者针对某一病人设计特定的药物。在某种程度上，这与向人们推荐书目或电影的推荐系统相似， 只不过，这里需要推荐一种药物。当然，这里涉及的问题比如何推荐一种药物，书目，电影更为复杂，你要理解细胞的工作原理，基因与及细胞形成的蛋白质是如何 交互作用的。好的消息是，我们拥有大量的数据来实现这一目标，如微阵列，序列等等。但是，基于我们现有的学习算法，我们还无法实现这一目标，而，拥有主算法，这一目标将得以实现。

  ![1472129873-6828-57bd6f6bd471c](http://mobile.witkey.com/ueditor/php/upload/image/20161001/1475290671454243.jpg)

- 第四个术语为**360度推荐系统**。 就推荐系统而言，作为一名消费者，我希望能够有一种关于我自己的一个完备的360度推荐模型，这种模型能够学习我产生的所有数据，这一模型比任何小型模型都更了解我，因而能够为我提供更好地推荐服务，不仅能够推荐一些细枝末节的事物，也能够为我推荐工作，房子，专业等。拥有这样一个推荐系统，好比拥有一个 生命中的挚友，能够为你生活中的每一步提供宝贵意见。为了达到这一目标，我们不仅仅需要不断增长的数据，还需要强大的算法来学习人类这一丰富多彩的模型。


# [大神Yann LeCun亲授：如何自学深度学习技术并少走弯路](http://www.leiphone.com/news/201612/Sjkmer9Kto5ILxFk.html)

Facebook 的博客上发布了一条新消息，放出大神 Yann LeCun 亲自讲解 AI 知识的三弹视频。然而如果 AI 领域的专业读者，稍微点开视频一看，便知道这好像是一个高中老师在讲科普课的风格。

三弹视频凑成一个系列，风格十分活泼，Yann LeCun 的讲解里穿插动画，并没有太多技术性的内容。LeCun 在视频里就明确表示，这次主要是给大众普及关于深度学习的基本原理，希望可以鼓励年轻人、高中生对该领域有更多了解，激发他们来探索这一领域的兴趣。

Yann Lecun 的三个视频主要讲述了个人工[智能](http://www.leiphone.com/)的基础技术：

- 监督学习最常用，关键是“调参”
- 机器学习，用模板来进行图像识别
- 深度学习新方法：卷积[神经网络](http://www.leiphone.com/news/201505/t3T1XQy2g3spCUdd.html)

**导语：Facebook博客上放出大神 Yann LeCun 亲自讲解AI知识的三弹视频，这科普性的风格，是美国政界、学术界、产业界在向下一代AI人才培养发力。                

一名 AI 专家值多少钱？

> “基于我个人经验，一名计算机领域的 AI 专家对于企业的价值，**至少为 500-1000 万美元**。为了争夺这些少数的人才，正在开展竞标大战。”

这是卡耐基梅隆大学计算机科学院院长 Andrew Moore 教授在 11 月 30 日美国参议院听证会上 ，所说的话。

![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/58416684f0ee9.jpg?imageMogr2/format/jpg/quality/90)

这场听证会名为“AI 破晓”（The Dawn of Artificial Intelligence），由参议员泰德·科鲁兹主持，主题是探讨[人工智能](http://www.leiphone.com/category/ai)当前的形势，对政策的影响及其对商业形态的改变。共有 5 位 AI 专家出席，分别是：

> - Eric Horvitz（微软研究实验室总经理，人工智能伙伴关系委员会临时共同主席）
> - Andrew Moore（卡耐基梅隆大学计算机科学院院长）
> - Andrew Futreal（德州大学安德森癌症中心基因医学教授）
> - Greg Brockman（OpenAI CTO及其联合创始人）
> - Steve Chien（加州理工学院、NASA 喷气推进实验室高级研究科学家）

在 Moore 教授看来，**美国政府应该从高中阶段开始为人工智能产业积蓄研究人员了，而这个人才储备需求为 100 万名高中生**。这并不是 Moore 教授一个人的观点，吴恩达也表示赞同。

![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/58414dab28644.png?imageMogr2/format/jpg/quality/90)

无独有偶，仅隔一天，Facebook 的博客上发布了一条新消息，放出大神 Yann LeCun 亲自讲解 AI 知识的三弹视频。然而如果 AI 领域的专业读者，稍微点开视频一看，便知道这好像是一个高中老师在讲科普课的风格。

三弹视频凑成一个系列，风格十分活泼，Yann LeCun 的讲解里穿插动画，并没有太多技术性的内容。LeCun 在视频里就明确表示，**这次主要是给大众普及关于深度学习的基本原理，希望可以鼓励年轻人、高中生对该领域有更多了解，激发他们来探索这一领域的兴趣。**

![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/58414367e2e39.png?imageMogr2/format/jpg/quality/90)

所以这样看来，无论是美国的学术界、政府还是产业界，都普遍有一种要把 AI 的种子广泛播种到下一代的氛围。

虽然是科普性的视频，但大神的思路可见一斑。就像 Moore 教授所说的，真正的 AI 专家只是非常少的一波群体，其实如今的 AI 从业者仍旧处在一个“学习”阶段。

那么，到底 Yann LeCun 的三弹视频里讲了什么内容呢？

雷锋网(公众号：雷锋网)根据 Yann LeCun 讲解总结成下文，供读者参阅，底部更是附上原英文视频。（另外在几天前，雷锋网整理了 Yann  LeCun 教授在 Quora 上关于“如何自学深度学习技术”的回答，非常具有可操作性，感兴趣的读者可移步: [大神Yann LeCun亲授：如何自学深度学习技术并少走弯路](http://www.leiphone.com/news/201611/cWf2B23wdy6XLa21.html)）

## 监督学习最常用，关键是“调参”

很多人，对于智能机器非常着迷，而我们的实现方法其实非常简单。现在我跟大家解释一下它当中到底是如何工作的。

其实大部分人已经在日常生活中使用 AI 系统了，只不过他们都不知道而已，这里面的应用包括自动驾驶、购买建议、游戏等。

我们最常用的机器训练模型，就是**监督学习（Supervised learning）**。

举一个典型的例子，如果你想建造一个识别图像的机器，让它识别图像里的狗和汽车。那么你就需要给这个机器看几百万张含有狗和汽车的图片，并告诉机器里面是否有狗或汽车，这就是一个“训练”的过程。

在训练之前，这个机器只是产生随机的答案，当你给它显示一张汽车或狗的图片时，你都不知道它会怎么回答。如果它答对了，可能只是运气好罢了；如它答错了，这时候得人为纠正一下（调参数）。

![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/584143c94cdb6.gif)

所以其中的一个关键就是，首先就是建造一个机器系统，然后就是调整内部参数或者结构，这样下一次你再展示图片的时候，系统就会答出正确答案了。

这就所谓的“学习型算法”，其关键就是在于“调整参数”。几百万张图片这样训练下来，不断地调整参数，最终机器会弄清楚“汽车”和“狗”之间的区别。当一张全新的照片给机器看时，它这时多半会给出正确答案。

我们把这个过程称为**“泛化能力”（Generalization ability）**，指的是，机器能够识别出跟训练素材相似的，但从未见过的东西（The ability to recognize things that are similar to what the machine has been trained on but has never seen）。

## 机器学习，用模板来进行图像识别

计算机往往依照一串指令来运行，这一串指令就叫做“算法”（Algorithm）。清洗盘子，也是要遵循“算法”的：先从一摞盘子里选出一个放入水池中，然后擦拭清洗，然后烘干，最后放置在架子上。这个过程不断重复，就是一种很简单的“算法”。

 ![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/5841447ddc6ba.gif)

那么我们如何为图像识别写一个“算法”呢？比如，如何区别图像里的汽车和狗？

计算机通常采用的方法，是用数字来表示图片，每一个数字代表特定区域像素的亮度。汽车的像素数组和狗的像素数组如图，这样就可以写一段代码来区别汽车和狗。

![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/584144b9a8b22.png?imageMogr2/format/jpg/quality/90)

很多年来我们做的事情，就是建立大量的图片库，将已识别出的图像和等待识别的图像进行比较，如果匹配上时，计算机就可以判定图片里面到底是汽车还是狗。

但问题是，这个方法所需要的模板数量太巨大了，就汽车和狗而言，需要所有可能的位置、颜色、姿态的狗和汽车，这是非常不实际的。

但机器学习不一样，我们并不对机器进行编程，而是用图片对其进行训练。我们来举个最简单的例子，让机器区分两个字母。我们看到下图里，分别是字母 D 和字母 C（黑色块构成字母轮廓）。 ![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/5841451389f77.png?imageMogr2/format/jpg/quality/90)

每张图片包含 9（3*3）个像素，我们分别给像素赋值，黑色=1，白色=0，从而得到两张字母图片的像素矩阵。

接着，我们只让系统做一件很简单的事情：计算出像素权重（Weights）之和。

![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/584147f947f6b.gif)

具体而言，我们需要两个部分：**像素值矩阵和权重模板，让这二者相乘得出结果。我们假定，如果结果>0，即判定为字母 C，如结果<0，即判定为字母D。**

像素值矩阵很好设定，接下来就是得出一个有效的区分二者的权重模板，这是通过人工调节得到的。

当看到字母 C 时，人工告诉机器把 C 的权值调大。于是学习系统把字母 C 黑色像素对应的模板的权值增加为 1，白色像素对应的部分保持为 0。

![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/58414873594e7.gif)

同时将字母 D 的权值调小。

![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/58414a693e022.png?imageMogr2/format/jpg/quality/90)

最终得到的模板权值中，正数（1）位置独属于字母C，负数（-1）位置独属于字母D。这就是一个很完美的将字母 C 和字母 D 区分的模板。

 ![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/58414aaa3aae1.png?imageMogr2/format/jpg/quality/90)

现在我们重新给系统一个字母C 的图片，计算机将新图与终极模板相乘，得到的 9个像素里的值，这些值相加得到的值=2。这时，2>0，所以计算机判断其为字母 C。 

![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/58414b19859ea.png?imageMogr2/format/jpg/quality/90)

同样，如果新图是字母D，那么所得结果为-1，-1<0，所以计算机判断其为字母D。

 ![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/58414b22b0830.png?imageMogr2/format/jpg/quality/90)

现实中的分类问题要比区别字母 C 和字母 D 更费时、更复杂，而对模板的设定也更具有挑战，但是模板法是一种非常基础的原理。

## 深度学习新方法：卷积神经网络

在深度学习领域，我们使用一种特殊的方法：**卷积神经网络(Convolutional Neural Network, CNN)** 。有趣的是，这种网络结构，是受到哺乳动物的视觉皮层启发。

一个物体可以有多个角度的照片，比如我要给这个剪刀拍照，各个角度得到的图片是不一样的。

![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/58415aa0546d8.gif)

如果我要让计算机识别出这个剪刀，那么就要以这个洞为主要特征，无论剪刀出现在照片的哪个位置，系统都能依据这个“洞”找出这个剪刀。

![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/58415a996a40e.gif)

这个“洞”只是这个剪刀的特征之一，我们可以对一个物体提取多个特征，让系统来锁定它。CNN 的特殊之处在于，我们并不需要人工来提取这些“特征”。CNN 的第一层，有几百个探测器（Detectors），它们自己学习并提取出几百个“特征”。

![Yann LeCun连发三弹：人人都懂的深度学习基本原理（附视频）](http://static.leiphone.com/uploads/new/article/740_740/201612/58415ac7a72c6.gif)

这种自我学习的方法，应用在很多领域，包括图像识别、自动驾驶、[语音识别](http://www.leiphone.com/news/201412/SPIrQG1uFa6jWMVZ.html)、翻译等。

Yann LeCun 表示：

> 这个视频不是课程，只是让普通人能够真正理解“深度学习”技术背后的基本原理，这或许能够鼓励年轻人、高中生对此有更丰富的了解，让他们对此产生兴趣，之后或许能在网上听一些课程，甚至日后在大学里学习相关课程。
>
> 我认为，让公众对深度学习技术有所了解，是很重要的。

所以，Facebook 已经要在培养青少年人才方面发力了，雷锋网大胆推测，莫非明年就要出现深度学习技术的高中生竞赛了？

从政界、学术界到产业界，美国都在向着“AI 破晓”大胆迈步，中国其实不乏在 AI 领域的专家大牛，是否也有一天，向 Yann LeCun 一样亲切地向大众普及 AI 知识，推动基础教育的发展呢？

PS： Yann LeCun三弹视频。



导语：Yann LeCun是Quora上非常踊跃的答者。有人问：你最喜欢的机器学习算法是什么？，LeCun 的回答是Backdrop。                

![大神Yann LeCun亲授：如何自学深度学习技术并少走弯路](http://static.leiphone.com/uploads/new/article/740_740/201611/583cfbbc6297c.jpg?imageMogr2/format/jpg/quality/90)

编者按：深度学习领域泰斗级人物 Yann LeCun 是 Quora上非常踊跃的答者，他乐于分享自己的心得体会。例如，有人问“你最喜欢的机器学习算法是什么？”，Yann LeCun 的回答是==“Backdrop==”。深度学习是新兴领域，很多人想要学习，也不知如何入手，所以 Quora上有很多关于“如何学习深度学习技术”的问题，Yann LeCun 在一些问题下面给出了一些自己的见解，雷锋网(公众号：雷锋网)据此整理编辑成本文，供读者参考。

![大神Yann LeCun亲授：如何自学深度学习技术并少走弯路](http://static.leiphone.com/uploads/new/article/740_740/201611/583d4bc4507bf.png?imageMogr2/format/jpg/quality/90)

## **问：自学机器学习技术，你有哪些建议？**

在网上有很多关于Machine Learning 的材料、教程和视频课程，包括 Coursera 上的一些大学课程。这里我主要讲讲深度学习领域。

你可以在网上听一些指导性课程和演讲，对深度学习有一个大致的了解。里面我比较推荐的有：

- 2015年5月《自然》上刊登的一篇概述性论文《深度学习》（Deep learning），由我自己、Yoshua Bengio 、Geoff Hinton共同撰写。（网址：[http://www.nature.com/nature/journal/v521/n7553/abs/nature14539.html](http://www.nature.com/nature/journal/v521/n7553/abs/nature14539.html)）
- 系统性的课本方面，我推荐由 Goodfellow、Bengio 和 Courville共同撰写的《深度学习》（Deep learning）（这个在网上有HTML版本，本书旨在帮助学生和从业人员入门机器学习，尤其是深度学习领域。HTML版本已经编辑完成，并且永久免费。网址：[http://www.deeplearningbook.org/](http://www.deeplearningbook.org/)）
- 我曾在巴黎法兰西公学院开课，其中有8堂课是关于深度学习，当时是用法语讲课，现在加上了英文版本。

> 法语版网址：[Accueil](https://www.college-de-france.fr/site/yann-lecun/) 
>
> 英语版网址：[Home](https://www.college-de-france.fr/site/en-yann-lecun/course-2016-04-15-11h00.htm)

- Coursera 上面有 Geoff Hinton 关于[神经网络](http://www.leiphone.com/news/201505/t3T1XQy2g3spCUdd.html)的视频课程（不过从现在的角度看，内容稍微有点过时了）
- 2012 年 IPAM 上针对研究生的“深度学习和特征学习夏季课程”（这个夏季课程的授课老师包括 Geoff Hinton 、Yann LeCun、吴恩达、Yoshua Bengio等众多深度学习专家，历时半个多月时间，网上有完整视频录像，网址：[http://www.ipam.ucla.edu/programs/summer-schools/graduate-summer-school-deep-learning-feature-learning/?tab=schedule](http://www.ipam.ucla.edu/programs/summer-schools/graduate-summer-school-deep-learning-feature-learning/?tab=schedule)）
- 2015 年我在纽约大学开了一门“深度学习”的课程，当时录成视频放到了网上，但是由于愚蠢的法律原因，视频现在已经不在了，但 PPT 还在。2017 年春天我会重新在纽约大学教这门课。网址：[http://cilvr.nyu.edu/doku.php?id=deeplearning2015%3Aschedule](http://cilvr.nyu.edu/doku.php?id=deeplearning2015%3Aschedule)）
- 2015年在加拿大蒙特利尔市举行了“深度学习夏季课程”（该课程的对象为：已经具备的机器学习基本知识的研究生、业界工程师和研究人员，授课量十分丰富。网址：[http://videolectures.net/deeplearning2015_montreal/](http://videolectures.net/deeplearning2015_montreal/)）
- 另外，我还推荐一些关于特定平台的使用教程，比如Torch、TensorFlow 和 Theano。

## 问：如果一名本科生想要成为深度学习领域的研究型科学家，你有什么建议？

首先，尽你所能，把所有具有连续性的数学和物理课都上一遍。**如果必须要在“iOS 编程”和“量子力学”之间选一门，一定要选后者**。在任何情况下，都要上**微积分**（I）、 微积分（II）, 微积分（III）、**线性代数**、**概率论**和**统计学**，另外尽可能多的去听**物理学**的课程。同时，还是要**确保学习编程**。

为什么物理学这么重要？因为物理学发明了很多数学方法，来给真实世界建模。比如，**贝叶斯推理（BayesIan inference）**在本质上与**统计力学（Statistical Mechanics）**是相同的，**反向传播算法（ Backpropagation）**可以看作是经典力学里**拉格朗日算符（Lagrangian）**的一种简单应用。图模型里的**前向算法（ Forward Algorithm）**是一种广泛应用于量子力学的**路径积分（[Path](http://www.leiphone.com/tag/path) Integral）**。物理，能够教你如何使用**傅里叶变换**（“**海森伯不确定原理**”的基石）、**最大熵原理**、**配分函数**、**蒙特卡洛法**、**热处理**、**波尔兹曼分布**、**动力系统**、**混沌**等等。

1.  选一个你感兴趣的与 AI 有关的问题。
2.  然后独立对这个问题进行思考。
3.  一旦你形成了自己的想法，就开始阅读围绕这个问题的相关文献。
4.  你将会发现（a）你之前的想法有点幼稚，但是（b）你对该问题的看法开始有点不一样了。
5.  在你就读的学校里，找到一个教授，他可以帮你把想法具体化。这或许有点困难，因为教授们都很忙，没有多少时间来指导本科生。有很多空余时间的教授往往很年轻，而那些年纪比较大的教授，又往往不再活跃在研究圈子里。
6.  如果你找到一个合适的教授，但他没有空余时间指导你，那么你可以转而去“勾搭”他/她实验室里的博士后或博士生。
7.  问问这个教授，是否可以让你去参加他/她实验室里的会议和研讨，或者只是在他们开会的时候旁听也行。
8.  在你本科毕业之前，尝试着写一篇关于你研究工作的论文，或者在网上公布一些开源代码。
9.  现在，你可以去申请  PhD 项目了。**不要去管所谓的学校“排名”，一定要找你感兴趣领域里有声誉的教授，他论文你很喜欢或钦佩**。
10.  你可以同时申请几个学校的 PhD 项目，当然选择的时候参考上条标准。在申请信里，你要提到你很希望跟这个教授一起工作，但是也愿意与其他教授一起。
11.  问一问你的本科教授，请他帮你写一封推荐信。**如果你的本科教授与你所申请的 PhD 项目教授认识，那么将是非常有利的**。
12.  如果你没有录取到自己心仪的 PhD 项目，可以到Facebook或谷歌工作，并且尝试去FAIR 或Google Brain 实验室做一个工程师，来协助实验室里科学家的工作。
13.  发表与公司实验室里课题有关的论文，然后重新申请 PhD 项目，并且让 FAIR 或 Google Brain 实验室里的科学家帮你写推荐信。

## **问：在未来5-10年内，AI 将可能朝哪些方向发展？**

有很多人在致力于不同的领域，并取得了非常好的进展：

1.  **深度学习与推理和规划相结合**。

2.  **基于模型的深度强化学习（涉及到无监管预测型学习）**。

3.  **经由可辨的记忆模块巩固加强的递归神经网络（例如，记忆网络）**：

               a. [**记忆网络(FAIR)**](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lMkTx0EAAAAJ&sortby=pubdate&citation_for_view=lMkTx0EAAAAJ%3AumqufdRvDiIC)
               b. [**堆栈增强的RNN(FAIR)**](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oBu8kMMAAAAJ&sortby=pubdate&citation_for_view=oBu8kMMAAAAJ%3AgKiMpY-AVTkC)
               c. [**神经图录机(DeepMind)**](https://arxiv.org/abs/1410.5401)
               d. [**端对端型MemNN (FAIR/NYU)**](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lMkTx0EAAAAJ&sortby=pubdate&citation_for_view=lMkTx0EAAAAJ%3AKbBQZpvPDL4C)

4.  **经过对抗性训练得到的生成型（预测）模型**。

5.  “**微程序设计**”：其核心思想----将程序（或电路）看作**可通过Backdrop进行训练的微模块**。这一思想表明深度学习不仅可以学会识别模型（如前馈神经网），而且可以生成算法（如循环算法，递归算法，子程序算法等）。从DeepMind、FAIR及其他资源中可获得一些相关方面的文章，但是，这些仅仅是初级阶段的成果。

6.  **分层规划与分层强化学习**：这是学习将一个复杂的任务拆分成一些简单的子任务的问题所在，是所有[智能](http://www.leiphone.com/)系统要满足的要求。

7.  **对外界事物的无监管学习预测模型（例如，视频预测）**。

如果未来几年 AI 能在这些方向取得重大发展，那么将会涌现大量更为智慧的AI智能体，应用于对话系统、问答、适应性的[机器人](http://www.leiphone.com/category/robot)控制与规划等领域 。

==构建出无监督学习方法，这是一大挑战==。但这将允许大型神经网络在没有直接人工注释数据的情况下，通过看视频、阅读书本便能够“学习现实世界是如何运转的”。

这将最终衍生出对现实世界有足够了解的机器，它们开始具有人类的“常识”。要实现这一目标，可能会花费5年、10年、20年，甚至更久的时间，我们尚不能确定具体的期限。

# DeepMind CEO称，通用人工智能还有很长的路要走

尽管DeepMind的AlphaGo击败了人类近十年来最伟大的围棋选手，但这家被Google收购的人工智能公司的CEO Mustafa Suleyman仍然[认为](https://techcrunch.com/2016/12/05/deepmind-ceo-mustafa-suleyman-says-general-ai-is-still-a-long-way-off)，人类距离实现通用AI还有很长一段路要走。

Suleyman是在英国伦敦举行的Disrupt London大会上做出这番表示的。大概还需要多久呢？Suleyman认为可能还需要几十年。而一旦一件事情需要20年或者几十年才能实现的话，往往意味着是无法确切衡量的，所以在至此之前DeepMind的关注点仍然会放在特定问题上——尽管公司创立的初衷是因为“**我们的复杂社会问题愈发陷入了困境**，”而DeepMind的目标是“==解决智能并世界更美好==。”

那通用AI会不会像科幻电影里面的样子呢？“说到想象未来的样子，很多想象很有趣有很娱乐性，但跟我们正在开发的系统并没有太多相似之处。我没法想出来有哪一部电影会让我想到：是的，AI看起来就是这样的。”

尽管人类距离通用AI或者所谓的奇点尚需时日，但是已经有人呼吁需要早日探讨[AI伦理以及人类与AI的关系](http://36kr.com/p/5056582.html)了。这方面纽约客的一篇长文就从人类与动物的关系展开了有益的[探讨](http://36kr.com/p/5057786.html)。

Suleyman还被问到了会不会把人类自身的缺陷传递给机器学习算法的问题。这个问题显然是针对了美国大选中社交媒体算法传播[假新闻](http://36kr.com/p/5057020.html)的问题。Suleyman回答说：

我对这些事是这么考虑的，那就是==我们注定要把我们的偏见和判断投射到我们的技术系统上==。如果我们作为设计师和技术专家不去有意识地考虑如何开发那些系统的话，那我们就会不自觉地把同样的偏见引入到系统里面。

Suleyman还谈到了DeepMind在健康方面的工作。目前该公司正在与英国国民健康服务（NHS）合作一个项目，进行急性肾衰竭的早期检测工作。但有批评人士指出双方的协作并不止披露的范围。此外，DeepMind还在与摩菲眼科医院合作，寻求利用该医院的眼球扫描资料更好更快的诊断眼疾。批评者质疑，DeepMInd跟Google的关系可能会导致病人的信任问题。不过NHS基本上使用的是自己的算法，而DeepMind则主要聚焦在前端应用上。Suleyman解释说这主要是因为双方的合作才开始1年，还没到展开进一步协作的地步。而且公司的合作时有协议在身的，可以确保院方才能拥有数据。并且DeepMind愿意尽可能向第三方审计者保持透明度。

此外，DeepMind还在会上宣布成立了DeepMind Lab，这是一个3D游戏式的AI平台，是专门针对基于代理的AI研究而设立的。DeepMind内部此前已经在使用该平台（原名叫做Labyrinth），现在正式把它开放出来供所有AI研究者使用。未来数日将会在GitHub上将代码和游戏环境的若干地图开源出来。

# **AI那么大，我们来说点具体的**

如果AI是“风”，那么医疗健康可能是那个“口”

编者按：本文来自微信公众号”金沙江创投“（ID:GSR-Ventures），作者林仁俊、张清，36氪经授权发布。

这个时间点有点尴尬，**悲观点说是资本寒冬，中立点的说法是互联网进入了下半场**。无论投资人或是创业者，无时无刻不在思考：下一个风口在哪里？在众多方向或是概念中，AI之热，无需多言。然而，即便AI就是下一个风口，它也太过宽泛。今天，我们来讲点具体的，比如AI与医疗。如果AI是“风”，那么医疗或者说大健康领域会不会是那个“口”？本文作者林仁俊（Richard Lim）为金沙江创投董事总经理；张清为金沙江创投合伙人，专注于医疗健康、生命科学和新科技交叉领域。

近几年，纵观人工智能的大版图，医疗健康已经成长为最热门的领域之一。2012年以来，共有15亿美金投入到188家初创公司。2015年，公司数量增长高达60%，而2016年将再次刷新历史数据。今年二季度已经出现了如Flatiron，iCarbonX（碳云智能）以及Butterfly Network这样的独角兽级别公司。

看来，资本早就以实际行动对这个领域表示了青睐。深究其本质，当医疗这一繁复而保守的传统领域，遇上人工智能这一欣欣向荣的科技创新，两者如何碰撞出最大的价值和突破？这是我们一直试图回答的问题。

要回答这个问题，首先得把人工智能和医疗两者分别做一个基本面的梳理和研究。

下面，我们来分享金沙江的研究和基本观点。

## AI是什么：究竟有多智能？

回顾AI的历史发展：John McCarthy在1956年的The Dartmouth Conference上首次提出人工智能的概念；其演变从以“推理”为重点到以“知识”为重点，再到以“学习”为重点。机器学习成为最凸显的一个分支，应用领域包括：**数据挖掘、计算机视觉、自然语言处理、推理能力、知识呈现、感知以及通用智能**——我们的终极目标。

经历过三起三落的人工智能，现在能够走出寒冬，主要受益于三个进步：**大数据的产生**；**算法的进步**，尤其是深度学习的技术，能够大量地处理未标记的数据、无监督地训练以及有监督地反向支持运算（如聚类）；以及**GPU对计算速度的支持**。

今年3月的Alpha Go极好的验证了一个道理：==对于大量、重复、有迹可循的数据来说，计算机远远胜于人类==。当前，人工智能并非是真正意义上的智能。更妥帖的定义，**应该说是一个高级的概率统计学方法**，提供了一个强有力的工具，来处理现实中诸多不确定性。参数越多， 变化越明显，结构越复杂，直截了当的原始分析法就越不可靠。曾经令人不知所措的随机和混沌，第一次有了不错的解决方法。

## 医疗：无数个复杂、动态更新的数据库？

再看医疗：**医疗健康和生命科学的复杂程度也许能够满足深度学习的胃口**。其诸多方面都可以借力于人工智能，例如**风险识别、行为监测/干涉、影像诊断、医院管理**，到**虚拟助手、营养学、精神疾病、精准治疗**等。下图有一个很好的总结，可以看到这个领域枝繁叶茂的蓬勃发展。

![](https://pic.36krcnd.com/201612/05090708/d31l4j370lpcj20s!1200)

**对于个体，从基因、分子结构，到细胞、组织、器官、系统和人体，生理和病理在时空层面的变化，无时无刻不在产生大量的数据**。随手翻翻医院的电子病历系统，对于每一个患者的每一次就诊，从社会信息、主诉症状、既往病史、家族病史、检查结果，到初步诊断、治疗计划和随访记录，都是一个复杂、动态更新的数据库。

医生看病是一个病人、一个病人来看的，电子病例对于医生而言，更多的是一个便捷记事本和备忘录，而非一个信息宝藏。因为医生不可能将全部信息汇总，并迅速地测试各种模型，来验证某些理论、发现某种规律。作为医疗主体，医生的视角是专注于一个病人，了解并跟踪其生理变化过程。一名优秀的医生，一天能看的病例也极为有限，很快就达到瓶颈，即便不吃不睡，也最多在百人的量级。稍有复杂的多系统性疾病，一两例可能就让医生吃不消了。原因何在？可能要引用前文所说，在大量、重复、有迹可循的数据领域，计算机远远胜于人类。

这仅仅是从个体的角度来看。从疾病演化的角度，从医疗资源调配的角度，从诊治规范不断更新变化的角度，从数据类型和体量的角度等等，医疗健康的量级实在太庞大。仅仅是信息汇总的过程就不容易，更何况要基于这些信息作出决策、采取行动呢？

不断延长医学院学习的时间，不断增加住院医师培训的时间和内容，不断新建医院和科研机构，真的是解决问题的方法吗？如果不是，那么，我们需要什么样的方法，才能改进这个不可持续的现状呢？这个问题的答案，价值万亿、利在千秋。

## 人工智能的逻辑也许碰巧满足了医学知识的特点……

**针对大量、重复、有迹可循的数据，针对不确定性、随机性和混沌的本质，针对动态演变、推陈出新的知识，助力于信息统计、推理决策、监督反馈等诸多方面**。随着医疗信息电子化的完善，让很多愿景成为可能。

回顾历史，第一场AI在医学领域的大会是1975年6月，The First Rutgers AIM Workshop。当时引用了因果、分类、关联、规则以及基于框架的模型来分析。Edward Hance Shortliffe医生是这个领域的先驱，开发了MYCIN系统，成立了American Medical informatics Association，第一个学术团体。但AI在医学领域的发展却或多或少有些阻力。

MYCIN是用来诊断菌血症并提供治疗方案的一套体系，拥有各种症状以及细菌谱的庞大数据库。它比医学生甚至医生都要优秀，但其局限性在于，缺少人类的常识和直觉，对医生、医院以及操作流程很陌生，没有病人、医生、医院、死亡、康复、复发等信息，这就极大限制了其使用范围。

当下，Google，Facebook，BAT等领军科技公司都在这个交叉点有所布局。例如，“百度医疗大脑”主要是在医疗数据和专业文献的基础上，设计出人工智能化的产品，模拟医生问诊的流程，并给出最终建议，在这个过程中收集、汇总、分类和整理病人的描述，辅助医生问诊。**庞大的神经网络被赋予了超强的记忆能力和计算能力，使得智能诊断成为可能，在日常诊疗过程中成为医生的得力助手**。

这只是冰山一角。但当传统、沉睡的行业被唤醒时，这的确是一个令人激动的时点。我们会精挑细选地和大家分享案例，在之后的文字中讲几个好故事。

## One more thing…

**科技本身难以等价于价值或者影响力**。==创新、创业的核心永远是围绕未满足的需求和真实而顽固的痛点==。抓住这些本质问题，再来看是否能够借力于新技术来满足需求和解决痛点。关于AI与医疗，我们期待你的真知灼见或是创业方向的探讨。

# **Google 提供的不再是搜索结果了，它提供的是答案**

**深度神经网络正在重塑了整个科技界**。

如果你用手机在 Google 上搜索“世界上时速度最快的鸟是什么？”它会告诉你答案是 “游隼”。“据Youtube上的视频记载，迄今为止游隼最快的飞行速度是389km/h。”

这是正确答案，但是这个答案并不是来自Google的数据库。当你问这个问题的时候，Google搜索引擎准确地找到了YouTube上一个介绍世界上飞得最快的五种鸟的视频，再从中提取出你想要的信息，然而它并不会提及其他四种鸟。同样地，如当你问“光明节有几天？”或者“图腾有多长？”，搜索引擎知道你问的是“太阳马戏团”的表演，表演有两个半小时，包括半小时的休息时间。

谷歌回答这些问题是基于深度神经网络——人工智能的一种形式，它已经快速地重塑了整个科技界，包括其他的科技巨头，从Facebook到微软。==深度神经网络是一款模式识别系统，可以通过分析大量数据学习特定的任务==。在这里，深度神经网络就学会了从远端转述相关网页上的内容，并提取你想要的信息。

这些“句子压缩算法”使搜索引擎在桌面上有生命地呈现了出来。他们所处理的是对于人类来说很简单但是传统意义上对机器很难的问题。这展现了在自然语言解读，理解并回答人类语言的领域，深层学习是多么领先。关于Google的句子压缩算法，其搜索产品经理David Orr说”你必须使用神经网络，至少这是我们能够发现的唯一一种实现方式。我们必须使用所有已有的科技。”

更不要说有一群有着高学历的人们参与其中。Google所用于训练神经网络的数据都是由一大群有着博士学位的语言学家人工收集而来的。这群语言学家被称为Pygmalion。实际上，**Google机器是通过一遍又一遍地学习人类如何从一大段文字中提取有用信息来实现其功能的**。这样艰苦的努力学习显示出了深层学习的强大之处，也显现出其限制性。要训练一个这样的人工智能系统，你需要非常多的依靠人类智能筛选出的数据。而要获得这样的数据并不轻松或廉价。而这种需要并不会随着时间的推移而减少。

为了训练 Google 的问答大脑，Orr 和Google还使用了以前的新闻故事，这样机器就可以学习到题目是如何总结其文章的。但是现在，Google仍然需要这群语言学家的工作。他们不仅仅是示范句子压缩，实际上更多地是标记文章的各个部分以帮助神经网更好的理解人类语言。 Pygmalion团队的将近100名语言学家从全球招募而来，他们的产出被 Orr称为“金数据”，以前的新闻故事被称为“银数据”。银数据仍然有用，因为其数据量很大。但是金数据是必须的。Pygmalion的负责人Linne Ha表示该团队在未来几年还会不断扩大。

这样的人工辅助式AI被称为“监管学习”。它展现了神经网络是如何运作的。所有公司都可以做这样的东西——或者它会自发形成。全世界的网络用户已经在无数张有猫的照片中标记出了无数只猫，因此这就使神经网络学习识别猫更容易。但是在其他情况下，研究人员没有办法，只有依靠人类标记数据。

**训练这样一个系统需要大量的人工筛选数据**。

深层学习初创公司Skymind的创始人Chris Nicholson说从长远看来，这种人类手工标记的方式不可取。“这不是未来，”他评论道：“这是一项极其枯燥的工作。我有着博士学位，我想不出还有什么事情比这个枯燥了。”除非Google的语言学家们的工作涵盖了所有语言为止，这个系统都不算真正意义上的有用，考虑到这点，人类手工标记方式的局限性尤其明显。Orr说，该团队涵盖了20至30种语言。但是有希望的是像Google这样一个公司最终会走向更加自主的“无监管学习”AI。

==“无监管学习”意味着机器可以从未标记数据中学习==，这些未标记的数据包括大量从互联网和其他渠道获得的数字信息。这样的研究已经在Google、Facebook和OpenAI（Elon Musk创立的机器学习初创公司）这些公司展开了。但是，仍任重而道远，如今，AI仍然需要人类的辅助。

# 为了训练人工智能系统，OpenAI 创造了一个名为 Universe 的虚拟世界

在训练人工智能的时候，研究人员常常会构建一个虚拟世界，例如加拿大阿尔伯塔大学的研究人员提供了 Atari 学习环境，让人工智能系统玩 Atari 的老游戏，微软提供了基于 Minecraft 的虚拟世界 Malmo。如今，旧金山人工智能实验室 OpenAI 宣布了全新的虚拟世界 Universe。

在 Universe 的庞大世界里，人工智能系统能够使用软件、玩游戏、浏览网页。Universe 是开放的平台，而且多数代码都是开源的，任何人都能够使用它。这意味着任何应用都能接到 Universe 上面，而人工智能系统可以与之互动。通过这种方式，人工智能系统可以学会使用各种不同的应用。

![](http://ifanr-cdn.b0.upaiyun.com/wp-content/uploads/2016/12/artificial-intelligence-1024x643.jpg)

OpenAI 希望，Universe 能够推动机器“普通智力”的发展。“一个 AI 系统应该能够解决你抛给它的任何问题。” OpenAI 的研究员 Ilya Sutkever 对[ Wired 网站](https://www.wired.com/2016/12/openais-universe-computers-learn-use-apps-like-humans/)说。

在 Universe 中，人工智能系统通过 VNC（虚拟网络计算机）与虚拟世界互动。在不断的试错中，它将知道如何获得高分、赢得游戏，或者获取其他类型的奖励。这被称作是“强化学习”（reinforcement learning）。值得注意的是，由于人工智能系统可以方便地在不同应用间转移，它们能锻炼自身的“普通智力”。它们能在某个应用上学到某项技能，然后将其运用到其它应用上。Sukever 说，OpenAI 已经开始构建这样的人工智能系统。

![](http://ifanr-cdn.b0.upaiyun.com/wp-content/uploads/2016/12/Cognitive_Computing-1024x576.jpg)

目前，OpenAI 在 Universe 中添加了上千个游戏，同时，它还与微软合作，想要把 Malmo 连接到 Universe 中。与此同时，OpenAI 的研究人员也在扩展 Universe 的世界。除了游戏之外，他们还想让人工智能系统学会使用浏览器。

问题在于，用浏览器训练“普通智力” 是一件更难的事情。在玩游戏的时候，人工智能有一个明确目标，就是获得更高分数，但是，网络服务是没有分数的。研究人员必须给出其它的奖励，而且，他们并不确定这些奖励能否帮助人工智能系统的成长。

在研究人员看来，无论虚拟世界，还是现实世界，处理问题的能力其实是相通的。如果人工智能系统能完成虚拟世界里的各种任务，那么，它们就拥有了人类一样的“普通智力”，可以处理现实世界的各种事情了。

# **聊天机器人模仿人类的局限性**

**聊天机器人的最终目的不是为了模仿人类，而是为了让它们能创造性地解决人类难题**。

编者按：最近几个月，聊天机器人遭受到不少批评。它们被形容成哑巴、令人沮丧、一无是处、完全是浪费时间的聊天机器。本文作者[David Cancel ](http://venturebeat.com/author/david-gerhardt-drift/) 对聊天机器人持支持观点。

虽然，这些批评无可厚非，因为确实有不少这样哑巴式的机器人存在。但有一条反馈我觉得说的不对。它认为当今聊天机器人的缺点是不够人性化。除非它们能够达到人类的智力水平，否则就不具备任何实际价值。

一位批评家最近写道：“**最完美的聊天机器人应该天衣无缝，即用户也无法分辨它到底是机器人还是人类**。”

但我觉得这个解决方案根本不合理。既然我有人类客服了，为什么我还要用机器人客服，并让客户相信它是人类呢？

==设计聊天机器人目的并不是为了让其完美地模仿人类，而是让它完成人类没法做的工作==，或者一些重复繁琐的活（比如捣鼓数字和搜索数据库）。

设计一个神似人类的聊天机器人会让你跌进一个“诡异之谷”。“诡异之谷”是机器人学和审美学上的概念，指人们看到某个神似人类的机器人时心中的反感情绪。一般来说，人们喜欢看到一些机器人，或非人类物体上的一些人类特征（比如两只眼睛，一个微笑）。倘若机器人做得太过逼真，我们就会瘆得慌。

这种情况也同样适用于聊天机器人。想想你第一次与机器人Jabberwacky,  ALICE, 或 [SmarterChild](http://venturebeat.com/2016/06/15/the-trouble-with-bots-a-parents-musings-on-smarterchild/)聊天时的场景。也许有这么几个时刻，机器人的表现与人类别无二异，你都吓坏了，对吧？所以，与其把聊天机器人仅当成人类智力和人类行为的复制品，我们不如将其列为一项独立的技术。

历史在与我们作对。

因为在传统上，人工智能（AI）的定义总与人的智能息息相关。可以看看谷歌上AI的首次定义：“**==人工智能指能够执行需要人类智力才能胜任的工作的计算机系统理论和演进==**。”

人类当前对AI的理解，以及对聊天机器人未来功能的期望，都无疑受到了阿兰·图灵论文《计算机与智能》的影响。在这篇论文中，图灵向世界介绍了后来举世闻名的机器智力测试，即图灵测试，这项测试认为，机器可以被称作智能的条件是，在与人类一对一的对话中能够伪装成人类成功欺骗对方。

从AI的早期研究起，我们对AI的衡量标准一直都是人。

然而，还有另一个阵营的AI研究者，这些研究者认为AI的衡量标准应该完全不同。他们提到其他的技术，比如人工飞行器，人类并没有完全遵照鸟类的飞行机理来制造飞机。既然莱特兄弟的飞机不用像鸟一样拍打翅膀就能飞行，我们为何要预设聊天机器人也必须像人一样交流才能实现人工智能？

关于这方面的AI定义，看看亚马逊Alexa（一家专门发布世界排名的网站）就足矣。它是这么定义AI的：==AI指能够创造性解决问题的计算机程序的计算机科学分支==。

看到区别了没？此处的AI并非要求它能向人一样解决问题，而是创造性地解决问题。**我们不是为了模仿人类解决问题的过程，而是为了找出最佳，效率最高的解决方案**。

这就是我公司对AI的发展定位。我们并不想设计只模仿人类的聊天机器人，而是设计一种能把特定目标成功率升至最大的机器人。这就是我们对AI的定义：**聊天机器人能不断吸取经验自我学习，对所处理的事务越来越擅长**。

最后当我们把这些机器人投向市场时，我们不希望客户想：“*哇哦，这个机器人好逼真啊*。”我们希望他们会这么想：“==哇哦，这个机器人真厉害，它是一个出色的帮手==。”如果我们想让机器人实现全部潜能，就该让机器人永远保持机器人的身份。

# 比情商，情感智能电脑可能已经超越人类了

创新型企业已经开始使用电脑系统来提高或是辅助人类的情商了。

编者按：目前，智能电脑炙手可热。作者 [Andrew Thomson](https://techcrunch.com/contributor/andrew-thomson/) 向我们介绍了智能电脑在情感计算领域的应用，并谈论了自己的看法。

从《我，机器人》《机械姬》到《摩根》，类似基于机器人可以理解、运算并且做出人类情感反应的主题电影已经出现在荧幕上几十年了。但是，大家可能有个误解，那就是打造一个精通情感的机器人在如今是可以实现的。现实中，电脑其实已经增强，甚至是替代了某些人类的情商(EQ)。

甚至令人惊奇的是，正因为电脑系统缺少情感，所以情感智能的电脑才变得如此炙手可热——智能情感电脑不像人类，人们并非始终擅长读解他人的情感，因为他们有时会错过一些情绪的信号或者被谎言所欺骗。

根据Tomas Chamorro-Premuzic所说，机器人并不需要有感觉才能做出情感的反应。事实上，与人类所理解的不同，高情商更多的是与一些低层次的情感相挂钩，==高情商指的是一个人可以控制情感带来的连锁反应，并避免感情的干扰，以做出最理性的反应==。

在情感计算的领域，传感器和其他的设备在观察与分析面部特点、手势、语言和身体状态等方面已经做得越来越到位了。创新型企业在一些产业中已经开始使用电脑系统来提高或是辅助人类的情商了。

## 管理

在华尔街这样的高压力环境中，股票交易员掌握着其雇主上百万美元的资产，分秒间所做的决定就可以成就或是毁掉其职业生涯。

雇员的情绪状态有时决定着这他们是否会犯下某些代价巨大的错误，或者其实他们已经犯下了这样的错误。纵观历史，某些产业的管理文化中并没有过多的考虑雇员的情绪状态。

然而，一些银行巨头，比如摩根大通和美国银行，正在与电脑协同协作来监控并促进公司的表现以及执行力。

据彭博报道，数量可观的银行已经开展了和Humanyze的合作，Humanyze是一个由麻省理工大学毕业生组成的创业项目，它旨在**通过一个胸章传感器来实现对演讲、活动和紧张值的变化做出相关实时数据**。这听起来挺像奥威尔的《1984》一书中的情节，胸章中带有麦克风以及贴近的传感器，通过分析人的表现情况来提高团队的效率值。这个设备将会使得管理人员去对那些力不从心的雇员作出果断的调换甚至是开除的决定。当然也会突出表现积极的人员，把他们作为团队培训当中的模范来激励其他成员。

## 体贴驾驶

如果你也曾坐在出租车后座因为看到司机的突然转向而感到过惊悚，那么你或许会对自动驾驶汽车的前景感到十分兴奋，因为自动驾驶汽车可以根据预设的交规安全驾驶。当自动驾驶汽车开始取代人工驾驶汽车之时，自动驾驶系统或许比你想象中的更加负责。

BRAIQ是一个创业公司，旨在**传授自动化汽车如何观察乘客的舒适度并学会找到乘客喜欢的驾驶方式**。这种个性化调教不仅提高了乘客的舒适度，也培养了他们对自动驾驶科技的信赖。

现有的客舱传感器已经可以提供乘客对于汽车驾驶行为的感受反馈了——比如加速、刹车或者人工驾驶时人们不同的感觉。经过收集并分析这些生物大数据，人工智能能够更好地做出反应来提高乘客的舒适度。BRAIQ的软件有效地在人工智能基础上加入了一层情感智能。

新科技同样为自动驾驶汽车可以进行意识交流提供了可能。当你想让行人穿行时挥手或是超车前晃大灯，这些行为都可以通过其它方式来表现。Drive.ai 已经打造了一套深度学习的人工智能，使得自动驾驶汽车可以将这些意识通过灯光、声音和动作来表现出来。

新技术使用深度学习的软件来通过传感器得知汽车周围的各种变化，并根据情况作出反应。为了可以有效地和行人以及其他驾驶者进行互动，汽车必须学会利用移动以及声音来告知其下一个反应；举个例子，晃大灯来让某些行人先走，或者前后摆动来告知其汽车将会向前驾驶了。 

## 顾客服务

Cotigo通过分析电话服务中心的电话员们与其顾客的语言以及对话语气变化动态图，来实时引导以帮助专业人员能更好地与顾客进行联系与沟通。

当顾客情绪比较消极时，通过引导，中介在交谈中变得更加有感情、自信、更具专业性以及更有效率。而这些调整则帮助中介达成了目标，使得顾客最终购买了产品并达成了交易。通话员通过实时状态栏可以监控对方的反应并在实时对话中进行提前干预。当顾客有消极情绪时，通话员会被系统主动告知。

Cogito在每一通电话中都给予了中介电话员客观的分析，在与顾客打交道中，优秀的业务员会脱颖而出并且也为未来的相关产业培训提供了成功范例。

## 法律执行

现如今，全世界的执法机构以及政府部门依旧使用着测谎仪。然而，如果测量多次重复使用的专业问题，那么得到的结果也并不准确，或者甚至是错误的。

Nuralogix已经打造出了一种人眼无法察觉到的情感阅读器。这项科技运用了透皮光学成像以及先进的机器算法，通过对面部血液流动的信息评估来挖掘人类隐藏的情感波动。在法律强制的假设下，检察官可以询问直接的问题，并且可以通过被审讯人无法控制的面部变化来获取真正的信息。

与之相同，麻省理工研究者刚刚宣布开发出了一个号称EQ-Radio的设备。==开发者声称其对人类情感的判断准确率高达87%==。这个设备**获取人体的无线信号，然后结合算法与其心跳图、呼吸变化图，得出最终的情绪判断**。现在，这项科技已经可以判断参与者的喜怒悲等情感。相信在未来，通过技术的提升，它也可以被作为测谎仪来使用。

当想到人类未来将会被那些检测我们情感的机器所支配时，我不禁毛骨悚然。然而与其将这些技术限制在科学实验室里，还不如将其广泛地应用于我们的家中、汽车里以及办公室。

# 2017年，语音交互和 AI 发展的 7 种预测

期待行业标准的出现

编者按：语音交互及 AI 大大改善了我们的生活，并将进一步发展。对此，本文作者 [Grant Owens](http://venturebeat.com/author/grant-owens-critical-mass/) 向我们介绍了七个需要关注的讯息及预测。

与2016年的其他热点话题不同的是，语音交互和AI没有让我感到乏味。我希望你也这样觉得，因为在2017年我们将会看到更多关于这方面的讯息。下面就是我们需要关注的：

## **1.标准的出现**

随着标准和直观功能的出现，并当每一个数据设计师都意识到这有多重要时，语音交互会大幅度提升。我们如今所定义的和创造的语音交互助理模型，如Alexa和Siri，会长时间影响着未来。试想一下过去20年流行的交互模型——我们在app里是如何浏览网页、app里常见的图标、表单和手势。我们与语音助理交流的标准也会以同样的方式出现。

## **2.语音AI将挑战Google在搜索市场的霸主地位**

语音交互体验预示着在 Google 占据主导地位的搜索市场中的竞争者有了一丝喘息的机会。最重要的是，语音交互的搜索结果是基于上下文且准确的。虽然这还是遵循“最好的算法”赢得胜利这一惯例，但是如今所有的算法都很不错了。就像所有人都习惯于到Google搜索信息一样，人们也会很快习惯用一款不是由Google控制的语音交互助理。事实上微软的Bing就排在Amazon的Echo、苹果的Siri以及微软自己的Cortana之后。我个人不认为Google会因此下马——以上这些公司在这一领域运营的很艰难，但是，还是那句话，这是一次机会。新的参赛者想要偷偷夺去顾客太平常不过了。

## **3.育儿建议**

你是或者曾经是新手爸妈吗？如果不是，让我给你提前描述一下吧：新手爸妈会手忙脚乱。语音交互完美地匹配有小孩的家庭的需要，除了可以不受打扰地给宝宝洗澡做饭外，它还可以避免这样的情况——每一个爸妈都会告诉你如果在小朋友周围想要使用手机，结果就是手机会被抢夺走，被用作磨牙玩具然后把它朝猫扔过去。可能你不知道，换电话可是很贵的。想要知道怎么提升声音吗？问新手爸妈。

## **4. AirPods实现与AI的交流**

我认为苹果的AirPods和Google Glass很类似，但是有更少的负面社会偏见危险。AirPods被称作是为你的耳朵打造的电脑，可以始终在线、时刻准备着与相关内容保持联系。苹果简单地将赌注押在了非可视化连接上——至少是在可视化穿戴科技成熟以前。在2017年我们会看到这款新产品将在AI助理领域变得越来越有用。

## **5.品牌个性将会走向多个平台**

如果Max Headroom在世的话，他将铭记即将发生在2017年的事情。语音交互及AI与自然语言交谈越接近，我们可以赋予虚拟代理的个性化特点就越多。制作独有的个性和大量的语音对于一个核心品牌是至关重要的，潜移默化地赋予一个品牌新的个性也会改变人们的看法以及吸引新的用户。无论是哪种情况，都是在为他们的语音产品能在2017年闪亮登场做努力，但与此同时，他们更期待的是在多个频道、平台和app上都可以占据一角。在不远的未来，我们会通过数字语音体验看到新的电视品牌个性化发展。

## **6.周边硬件支持的出现**

Sir i现在可以在多个app内使用。这明确地预示着我们正在走向一个由“声音激活”的未来。唯一的问题就是，这其中的很多产品都没有设计听力和口语功能。多用途设备的麦克风比不上专门设备（如受人欢迎的Amazon Echo和Google Home speaker.）的麦克风的质量和能力。我们会看到PC配备语音交互软件，但是这势必将淘汰那些不那么好的设备。我期待看到苹果发布一款这类专门的周边设备。

## **7.你的CMS开始倾听你的话了**

这也许是很多人最后才想到的一点，但是却是公司最早注意到的一点。主要网站的内容管理系统（CMS）和数字管理系统（DAM）的现状会因消费需要减少而悲伤地失败。因为这些公司还只是在围绕文字、表单以及图片来搭建基础。很多公司都没有为未来的3至5年做好准备，当他们在2017年开始准备提供语音激活服务时，其中的差距就会显现出来。这样是行不通的！如果一家公司希望可以在不同的平台和交互上提供产品相关的语音内容，那就必须从现在开始，为即将到来的未来做搭建准备。现在CMS 已经成为了内容云市场的核心，它必将加快语音交互的进程。

# **现在是 AI 辅助人类，未来可能是人类辅助 AI**

问题来了，我们如何正确使用人工智能客服？

编者按：人工智能（AI）和自然语言理解（NLU）在快速发展，并且在过去几年有了明显进展。本文作者 David Pichsenmeister 认为，靠自动化语音聊天程式来提供全自动支持服务的那天还没有到来。

因此，人类的参与在每一个成功的客户服务聊天程式都必不可少。不同的客户服务团队采用的是不同人机合作方式。

## **1. 预先选择式**

这是人机最基本的交互模式。当一段谈话开始时，用户首先选择需要人工服务还是自动化语音聊天程式。

选择自动化语音聊天程式的好处是节省了等待时间。自动化语音聊天程式也许可以立即解决用户的问题，而不用浪费时间等待人工服务。

特别是当你的公司新安装了自动化语音聊天程式想要做测试时，这一选项有助于正确判断在不强迫用户的状态下他们是否愿意使用自动化语音聊天程式。

ChatShopper是一款常用的自动化语音聊天程式，它很早就被投入使用了。该程序让用户在自动化语音聊天程式和人工服务之间做选择，并且一开始时就向用户说明人工服务最多需要等待10分钟。大约80%的用户都会选择自动化语音聊天程式（即使很多人都问过什么是自动化语音聊天程式）。

AI／ NLU需要程度：无

人工参与程度：低至中（等待时间决定）

开发成本：低

运营成本：中至高

## **2. 人工接管式**

这一方案和上一个很相似。每位用户都以和自动化语音聊天程式交流开始，但是程式始终提供一个可以让客户选择人工服务的出口。这可以通过不同方式实现。

比如办法之一是使自动化语音聊天程式，让它只针对交互元素如聊天按钮做回答。这就意味着每一次的回答都是不断地将服务引向人工服务。从技术角度来说这是最容易实现的，因为该过程只有两种不同的交互控制原：用户界面元素和文字信息。

另外一种方式就是让自动化语音聊天程式针对所有输入都采用默认回答，但同时用户可在对话的任何时候要求人工服务。

从用户体验的角度来说实现接管的方式有很多。在人工服务期间，自动化语音聊天程式需要停止，不能回答任何问题。

在我看来这个方案更合适，在自动化语音聊天程式和人工服务之间有清晰的界限，因为你不能同时与两者交谈。

人工接管式最大的好处就是自动化语音聊天程式不需要有自然语言理解。简单的任务可以（但不一定）设计到用户界面元素，或者是采用关键词和模式匹配的方式进行设计，当任务更复杂时就需要人工服务了。

AI／ NLU需要程度：无

人工参与程度：低至中（由等待时间决定）

开发成本：低

运营成本：中至高

## **3. AI辅助式人工服务式**

自动化语音聊天程式辅助背后的想法是用户本身实际上不用打任何字。所有的信息都转发给人工服务。自动化语音聊天程式的作用就是分析用户每一条信息并提取实际内容和用户的想法。

因此，结果标签可以自动添加到对话上，自动化语音聊天程式可以为人工服务提供建议的“罐头”回答。如果人工服务认为这样的回答合适，他们只需轻轻一点就可以立即发出回复了。如果人工服务认为“罐头”回答不合适，人工服务可以编辑“罐头”信息，也可以自己输入新的信息。无论是编辑后的还是新输入的信息都会被用来训练自动化语音聊天程式。

根据公司或者客服团队的大小不同，自动化语音聊天程式可以判断哪支团队或者哪位人工客服最适合来回复某咨询。

AI／ NLU需要程度：中

人工参与程度：中

开发成本：中

运营成本：中

## **4. 人工辅助式AI式**

这是AI辅助式人工服务的自然进化。和AI辅助式人工服务一样，每一条信息都由AI分析和归类。然而最主要的区别点是AI的建议回复的可信度是否达到一定程度（可信度>=90%），达到一定程度后信息将会自动发出。

只有低可信度的信息才会被转发到人工服务处审核并回复，同样地，相关回复会被用来训练自动化语音聊天程式。这个方案的缺点就是需要大量的人工客服从而使回复时间缩到最短，特别是当用户认为自己其实是在和自动化语音聊天程式对话时。另外，还需要一些人工客服来监管自动化语音聊天程式。

AI／ NLU需要程度：高

人工参与程度：高

开发成本：高

运营成本：高

## **未来展望**

现在面临的问题之一是：许多自动化语音聊天程式开发者不愿意花时间在对话设计和训练上。机器学习和AI已经处于一个良好阶段了，但是许多团队和开发者仍然不能良好地模拟对话。用客服大数据或者是新产生的对话训练自动化语音聊天程式都可以改善这种情况。

我期待NLU和AI可以超越过去几年的发展速度，同时也希望自动化语音聊天程式的开发者可以在人工客服的帮助下在自动化语音聊天程式训练上多做努力。

在不远的将来，我们将在客服团队里看到一个大的转变。人工客服不再负责回答简单的顾客咨询，而将转变为自动化语音聊天程式的监管者。

# **弱人工智能时代，如何让机器准确识别一个人？**

人工智能发展了这么多年，为什么依然处于弱人工智能阶段？

如果说你是这两年才闻及人工智能一词，那么只能证明你Out了。因为早在1956年，以麦卡赛、明斯基、罗切斯特和申农等为首的一批年轻科学家，就已经共同研究和探讨用机器模拟智能的一系列问题，并首次提出了“人工智能”这一说法，也标志着“人工智能”这门新兴学科的正式诞生。

但很遗憾，人工智能发展了这么多年，今天依然处于弱人工智能的阶段。值得幸运的是，支撑人工智能的大数据，清晰的领域界限，顶尖的AI科学家和科技公司，都在推动着人工智能进程的快速发展。

近日，36氪就采访到悉尼大学教授陶大程博士。作为人工智能和信息科学领域国际知名学者，陶博士已当选为欧洲科学院院士、电气与电子工程师学会(IEEE)会士，并获得澳洲国家科学最高荣誉尤里卡奖。他所研究的两大领域是**机器视觉与机器学习**，研究的问题包括**大规模图像数据的检索与分类、人脸识别与动画、精细化分类、人体姿态估计、行为分析、事件检测、多视角学习、多任务学习、标签噪声模型、矩阵分解、特征工程**等。

不再需要设置密码，指纹便可以解锁手机；不必携带银行卡，刷脸即可完成支付；无需键盘提交问题，说出来，答案就告诉你。==人工智能的目的是为了更好地服务人类==。其中最重要的一环便是，如何让机器准确识别一个人。

## “刷脸”时代还有多远？

手机 “刷脸”支付、“刷脸”开机等各种“刷脸”服务，其核心技术便是计算机视觉领域颇为大热的人脸识别。最早的人脸识别是以图像里面人脸器官的尺寸作为特征进行匹配。后来出现了众多基于表观的特征，又引入了一些统计的方法，例如主成分分析、变形模板和后来的线性判别分析等。2007年左右发布的LFW数据库包含有大量自然真实场景下的人脸图像，传统特征和分类器的方法不再奏效。但随着深度学习技术和大数据的引入，LFW数据库上的人脸识别准确率目前已经可达到99%以上。

### 那么现有的人脸识别技术是否已经攻克了所有核心问题呢？

陶博士简析了近年来很多与人脸识别相关的国际比赛，包括测试人脸识别算法在监控场景下性能的PaSC比赛，和测试人脸识别算法进行海量人脸检索性能的Megaface比赛。比赛的结果表明现有的人脸识别算法在特定应用上仍需要进一步提升，才能够满足实际需求。

但是这并未打击我们对这一问题的研究信心。通过参加国际比赛，各科技公司和高校不断地展示自己的技术实力，同时也对人脸识别的研究起到了非常大的导向作用。例如，比赛结果可以帮助很多研究团队快速分析最新的研究问题和方法，及时调整研究方向和手段，使得这个领域可以以更快的速度发展。值得一提的是，陶博士的团队在2016 年获得了PaSC的冠军，在另一国际比赛ActivityNet（大规模活动识别挑战赛）中亦收获冠军。

## 人体姿态估计发展这么多年，为何依然普及难？

谈及人体姿态估计，陶博士表示这是一个很传统的话题，目前研究成果不是很乐观，一方面技术成本高昂，对硬件设备高度依赖，导致难以得到推广，另一方面达不到高精度的识别。

回顾人体姿态估计的发展史，目前工业界，尤其是电影制作行业，最常见的技术是**Motion capture（动作捕捉）**，也就是通过穿戴多个关键点传感器，并记录其对应三维空间坐标来实现捕捉人体的动作姿态。但是，目前使用Motion Capture系统的成本非常昂贵，而且需要穿戴特殊装置才能使用，因此该技术难于得到推广。

近些年来，通过获取场景中的深度信息来估计人体姿态也有一定的进展，但该技术也依赖于硬件设备例如深度摄像机 Kinect或者双目摄像机，而且深度信息的获取易受环境因素影响（如光照等）；由于以上技术对硬件设备高度依赖，因此无法处理普通摄像机拍摄的视频。例如当我们需要通过估计Michael Jackson视频的姿态来辅助舞蹈训练，由于这些视频都是通过普通单目摄像机录制的，因此无法直接使用上述的那些方法。

在陶博士看来，==人体姿态估计最大的技术难点在于如何去捕捉这些关节点的局部外观信息，以及如何通过学习他们之间的空间关系进行建模来实现精确定位==。

因为就目前来看，人体姿态估计的方法主要是通过精确定位人体活动关节点的位置来估计人体的当前姿态，例如肩关节、髋关节。但是由于人的着装会变化，身体形态也会变化，偶尔还有遮挡的情况，这些因素都带来了极大的挑战。

在今年的刚结束的与Imagenet联合举办的COCO人体关键点定位比赛，Mean AP 在标准集的评估最高只有60.5%。值得一提的是，在这次比赛当中，陶博士的团队提交了一个快速模型的结果并获得第三的名次（仅次于CMU和谷歌）。赛后他们提交了正常模型的结果，在标准集的评估获得了61.8%的Mean AP。

## 多视角学习，让你不再重蹈“盲人摸象”

**人体的很多特征都可以被用来进行个人身份的识别**，包括指纹、虹膜、人脸以及步态等。然而哪种特征能够最好地帮助机器准确识别一个人呢？

在陶博士带领团队研究的过程中，他发现描述一个物体、一个事情的时候，可能需要多个角度来描述，这个就类似于盲人摸象，不同的角度会得出不同的结论。如果所有盲人能够进行有效的沟通，把所有的结论综合到一起，就有可能得到一个大象的完整刻画，这就是为什么要进行多视角学习。

“==多视角学习的目的就是把这样多种不同类型的信息融合在一起：既要避免融合后的信息缺失，又要去除不同类型信息中的冗余和噪声，有效帮助机器更准确全面的去理解、处理我们的问题==”，陶教授告诉36氪。

他同时表示，因为有不同类型的传感器，不同类型的特征，每个传感器或者每一个特征对于一个事件或者物体的刻画，实际上都是局限的。

“**如果能够把这些信息有效的整合在一起，就能够给出一个物体或者一个事件合理、有效的刻画**”，陶博士说。

陶博士的团队用理论分析表明组合多个视角将为完好空间的学习带来足够的信息。同时，借用鲁棒统计的知识，使得算法能够增强对野点的鲁棒性。“我们提出了一个新的多视角稳定性的定义，并在多视角稳定性和函数空间复杂度的基础上分析了算法的泛化能力。我们发现**多视角之间的互补性能够有利于改善算法的稳定性和泛化性**”，陶博士这样概括他们团队取得的最新进展。

但是所获取的、所采集到的数据可能会有噪声或损坏情况，这将导致不同的视角信息是不完整的或者是受干扰的。

为了让这种学术上的概念更容易理解，陶博士举了这样一个例子：

> 这就好像卫星在天上绕着地球转，扫描地球表面的信息，实际上卫星的载荷由前视、下视和后视传感器组成，每一个就是我们其中一个视角，某一个传感器坏了之后我们不能把卫星舍弃，但卫星成像时获取的视角信息就已经是不完整的，是缺失的。

那么一旦遇到这种情况该如何解决？办法倒是有，陶博士的团队已经在尝试了。

陶博士表示，解决不完整视角学习问题的关键是挖掘多个视角之间的联系，使得不完整的视角可以在其它完整视角的帮助下恢复出来。通过假设不同的视角可以由一个完备的空间生成，得以完成不完整视角下的多视角学习。

事实上，以上讨论了这么多技术性的干货，都逃离不了机器学习、计算机视觉的范畴。这些技术迄今为止落地能够被我们感知的非机器人莫属，中国的机器人创业更是此起彼伏。

陶博士则认为，每一种创业模式都是值得的，前提是**你的创业方式能够匹配你的创业目标**，同时还应该尽可能的满足其他创业模式对外界的需求，软件的发展需要硬件的支撑，平台的发展更是需要软硬件相结合。

“Android、Linux之类的开放平台的成功告诉我们，机器人的发展是需要大众的，而不只是某些高科技人员的小团体”，陶大程接着说道。

但问题是，在当下弱人工智能的时代，暂且不提怎样能够使得机器识别一个完整的人，就连一个几千块的机器人都很难有人买，更别提大规模普及。

陶博士给相关的创业者们提出了一些建议：

- 硬件方面，希望机器人**能够拥有较高的自由度**，从而向用户展现出最直接的视觉美感，更好的贴近人类生活会更容易让人产生情感和信任；
- 软件方面，智能机器人都会拥有自己的操作系统和平台，我们需要考虑的就是**如何让更多的应用嵌入到机器人平台上，使机器人能够不断的更新自我**；
- 在销售机器人的时候，提倡一种在IT界广为流传的社区文化，**将机器人平台像iOS、Android那样向用户开放，吸引应用开发者进来，推动机器人平台的发展**。

最后，谈及中国与国外科技公司在人工层面的差异，在国外生活多年的陶博士表示，以往科技发展历程中，中国的科技公司都是通过引进国外的科技才完成产品的研发，这样的现象曾经存在过，但是在当下的科技潮流下，中国公司在人工智能领域的研发能力已经非常可观。

“很多先进的技术现在也都被华人所了解和掌握，甚至突破，这可以从每年人工智能领域的顶级会议中看到”，陶博士补充道。

所以他认为，**中国人是有能力研发出世界领先水平的先进的人工智能系统**。中国公司想要在科技潮流下生存下来，重要的一点就是如何聚集到一批专业的人工智能研究人员，利用最先进的技术，来帮助公司产品的研发。

# [**Gartner**](http://www.afenxi.com/topic/gartner)**2017年十大技术趋势**

**品觉导读：**

- [智能物件](http://www.afenxi.com/topic/%e6%99%ba%e8%83%bd%e7%89%a9%e4%bb%b6)是指超出刚性编程模型范畴的物理实体，通过应用AI和[机器学习](http://www.afenxi.com/topic/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0)来实现高级行为，并与周围环境和人类更加自然地交互。随着无人机、无人驾驶汽车和智能家电等智能物件不断普及，Gartner预计各自为政的智能物件将转变为相互协作的智能物件模型。


- 三到五年内，将有数以亿计的事物用数字孪生模型来呈现。企业将利用数字孪生模型主动修复和安排设备服务、规划制造流程、运作工厂、预测设备故障或提高运营效率、加强产品开发。因此，数字孪生模型最终将取代技工与传统监测设备和控制装置（比如压力计和压力阀）的组合。
- Gartner确定了实现数字企业新功能和商业模式的五个要点——信息系统、客户体验、分析与智能、物联网以及企业生态系统。每家企业均会是这五种数字技术平台中的某种混合体。

**原文翻译：**

Gartner大力强调人工智能（AI）和算法的未来影响力，难怪该公司说这项技术将是2017年最具战略性和潜在颠覆性的技术之一。

在Gartner Symposium/ITxpo大会上，Gartner副总裁兼资深研究员大卫·卡利（David Cearley）详细介绍了该公司预测的2017年重大技术趋势，包括数据科学技术如何发展到了高级机器学习的阶段，以及人工智能正在如何帮助创造能够学习和适应的硬件和软件智能系统。其他重要趋势包括物理和数字环境融合的影响，以及数字技术平台对企业的影响。

“**应用AI和高级机器学习催生了一系列的智能实现**，包括物理设备（机器人，自动驾驶汽车，消费电子产品）以及应用程序和服务（虚拟个人助理，智能顾问）。”卡利说，“这些实现将以新一类智能应用程序和智能物件的形式呈现，并为各种各样的网格设备及现有软件和服务解决方案提供嵌入式智能。”

Gartner执行副总裁、研究主管兼资深研究员达尔·普拉默（Daryl Plummer）证实了机器智能的巨大影响力。他说，到2020年，算法将会积极地改变全球10多亿工作者的行为。

“**情境化算法进步神速，已经能实现多种行为干预**，比如**心理学、神经科学和认知科学**。人类往往会受到情绪的支配和环境的影响，导致他们做出不理性的行为。算法能积极地改变这种行为，方法就是使用庞大的聚合记忆库来增强算法的智能。记忆库中包含了被用于服务社会并经过检验的知识。”普拉默说，“这将帮助工作者‘记住’任何事情，或者把他们从来都不知道的事情及时告诉他们，让他们能够客观地完成手上的工作，同时也能更好地享受生活。利用算法可能会使人感到‘毛骨悚然’，但如果我们善加利用，它能给很多行业带来改变。”

以下便是Gartner预测的2017年十大战略技术趋势：

- **AI和高级机器学习：**AI和高级机器学习由很多技术（比如深度学习、神经网络、自然语言处理）组成。更先进的技术将超越基于规则的传统算法，创造**能够理解、学习、预测、适应甚至有望自主运作的系统**。这就是智能机器显得“智能”的原因。

- **智能应用程序**：像虚拟个人助理这样的智能应用程序可以发挥人类助理的某些职能，使日常任务变得更容易（比如对电子邮件进行优先排序），提高用户效率（通过突出最重要的内容和互动）。虚拟客户助理等其他智能应用程序更加专擅于销售和客服等领域的任务。因此，这些智能应用程序有潜力改变工作的性质和职场的结构。

  “未来十年，几乎所有的应用程序、应用和服务都将包含某种程度的AI。”卡利说，“AI和机器学习在应用程序和服务方面的应用将不断发展壮大，这将成为一个长期趋势。”

- **智能物件**：智能物件是指超出刚性编程模型范畴的物理实体，通过应用AI和机器学习来实现高级行为，并与周围环境和人类更加自然地交互。随着无人机、无人驾驶汽车和智能家电等智能物件不断普及，Gartner预计各自为政的智能物件将转变为相互协作的智能物件模型。

- **虚拟和增强现实**：虚拟现实（VR）和增强现实（AR）等沉浸式技术改变了人与人、人与软件系统的交互方式。“从现在直到2021年，沉浸式消费和商业内容的格局以及应用将发生巨大变化。”卡利说，“VR和AR功能将与数字网格融合，形成更加无缝的设备系统，通过超级个性化和相互关联的应用程序和服务，向用户提供信息流。多种移动、可穿戴、物联网和多传感器环境的跨界结合，将使沉浸式应用超出孤立和单人体验的范畴。房间和空间将与物体交互，它们将通过网格连接，与沉浸式虚拟世界协同工作。”

- **数字孪生模型**：数字孪生模型是物理实体或系统的动态软件模型，依靠传感器数据来理解自身状态、对变化做出响应、改进操作和增加价值。数字孪生结合了元数据（比如类别、构成和结构）、条件或状态（比如位置和温度）、事件数据（比如时间序列）和分析（比如算法和规则）。

  三到五年内，将有数以亿计的事物用数字孪生模型来呈现。企业将利用数字孪生模型主动修复和安排设备服务、规划制造流程、运作工厂、预测设备故障或提高运营效率、加强产品开发。因此，数字孪生模型最终将取代技工与传统监测设备和控制装置（比如压力计和压力阀）的组合。

- **区块链和分布式账本**：区块链是一种分布式账本，里面的（使用比特币或其他代币进行的）价值交换交易按交易顺序归类成“块”。每个块均采用加密的信任和保证机制，链接至前一个块，并记录在P2P网络上。区块链和分布式账本的概念越来越受到关注，因为它们有望改变行业经营模式。虽然目前对该技术的宣传主要围绕在金融服务业方面，但还有很多其他的可能用途，包括**音乐发行、身份验证、所有权登记和供应链**。

- **会话系统：**目前，会话界面的重点放在聊天机器人和支持麦克风的设备，比如扬声器、智能手机、平板电脑、个人电脑和汽车上。然而，数字网格包含的端点越来越多，人们通过这些端点访问应用程序和信息，或者与他人、社会群体、政府和企业互动。设备网格已不再局限于传统的台式计算机和多类设备，而是涵盖了人类可能与之互动的各种端点。随着设备网格不断发展，连接模式还将进一步增多，设备之间更大程度的协作互动将会出现，为不间断的环境数字化新体验奠定基础。

- **网格应用程序和服务架构：**在网格应用程序和服务架构（MASA）中，移动应用程序、网络应用程序、桌面应用程序和物联网应用程序会连接到广泛的后端服务网格，创造出用户所看到的“应用”。该架构可封装服务，提供应用程序编程接口（API），贯穿不同层级，突破企业通过服务的组合与再利用在对服务的敏捷性与扩展性的需求间寻求平衡的界限。MASA让用户能够优化数字网格中目标端点（比如台式电脑、智能手机和汽车）的解决方案，并在切换不同信道时拥有不间断的使用体验。

- **数字技术平台：**数字技术平台为数字企业提供基本的构建模块，是塑造数字企业的关键因素。Gartner确定了实现数字企业新功能和商业模式的五个要点——**信息系统、客户体验、分析与智能、物联网以及企业生态系统**。每家企业均会是这五种数字技术平台中的某种混合体。这些平台为数字企业提供基本的构建模块，是塑造数字企业的关键因素。

- **自适应安全架构：**智能数字网格、相关数字技术平台和应用架构营造出了一个复杂度前所未有的安全世界。“**成熟的安全技术应该被用作为保护物联网平台的最低标准**。”卡利说，“监控用户和实体行为则是一个重要的补充，尤其是在物联网的使用场景中。然而，对很多IT安全人员来说，物联网的先进之处反而是滋生新漏洞的新领域，常常需要新的补救工具和程序，在打造物联网平台时必须把它们考虑在内。”


# 大数据获取+计算工具+计算平台的能力=人工智能

# **聊天机器人为什么需要进行深度学习？**

**依靠深度学习可以解决聊天机器人的瓶颈问题**

编者按：本文作者 Sergei Burkov 是俄罗斯莫斯科物理技术学院博士，也是旅游推荐智能机器人公司 Alterra.ai 创始人兼首席执行官。

聊天机器人现在非常热门，但是当我们谈到“聊天机器人”时，会发现它有两个完全不同的类型：**一种是配置对话用户界面的智能虚拟助手**，另一种，则是**依赖屏幕按键图像用户界面的非智能菜单驱动的程序**。相比于前者，以菜单驱动的聊天程序的确拥有不少劣势，用户接受度也不高，比如他们无法支持深度链接、创新性较低、同时也缺乏内部机器人之间的“bot-to-bot”通讯协议。相反，智能聊天助手则为上述问题带来了解决方案，它们无需新协议或应用程序接口就能实现彼此间的通讯，而且也不依赖于类似于 Google Assistant 这样的“主机器人”。更重要的是，人们用自然语言就能与之交互。

## 机器人要用自然语言实现交互

过去，每家公司都需要有一个官方网站，以后他们都需要一个专属的会话式机器人。但是在绝大多数情况下，你不会直接与它们对话，用户可能会首先与一个“主机器人”进行交互，比如谷歌的 Google Assistant、三星的 Viv、以及亚马逊的 Alexa。主机器人会判断哪一个“下属”机器人有能力处理你的请求，再把你的请求转发给它们。

举个例子，假如你想要在巴黎预定一个酒店，你只需说：

谷歌，我下周日想去巴黎，请帮我预订一个每晚不超过 200 美元的四星级酒店，里面要有免费的 Wi-Fi 和健身房服务，还有，我要住五天。

此时，Google Assistant 会找到一个旅行代理服务机器人（比如 Expedia、Booking.com、或是 Alterrra 等），然后把这个请求转发过去，如果“接收方机器人”足够智能，能够理解用户请求，那么就能完成一笔酒店预订业务。

关键是，“主机器人”和“接收方机器人”之间也能够使用自然语言彼此交流。再比如，当你和全球私人旅行指南出版商《Lonely Planet》旗下的聊天机器人对话，想问问它阿姆斯特丹有哪些著名的旅游景点，你只需问说：

下周二阿姆斯特丹的天气怎么样啊？

此时《Lonely Planet》机器人会把你的请求转发给 Weather.com 机器人，如果后者有能力回答这种自然语言问题，那么就会把答案传递过来。换句话说，英语将变成未来机器人彼此之前的“通讯协议”。

## 聊天机器人会变成另一个“亚马逊土耳其机器人”吗？

看上去，人工智能技术对聊天机器人非常有帮助。但可能也不一定，因为我们还有另外一个选择：由人工支持的聊天代理服务，比如[亚马逊的土耳其机器人](https://www.zhihu.com/question/20279895?sort=created)模型。事实上，现在不少初创公司已经采用了这种方式，但它却是一个死胡同。

为什么这么说呢？其实还是人类本身的问题——无法实现规模化拓展，速度也太慢，成本更是无比昂贵。而且我们没有足够多的人力，来支持数以百万计的机器人服务世界上每家公司。人类愿意回到手工劳动力时代吗？想象一下，假如亚马逊每笔交易都是通过现场销售人员来为客户提供服务，他们能够承受得了吗？所以结果很明显，企业未来只能选择人工智能，否则距离破产就不远了。

## 传统的自然语言处理技术还能发挥作用吗？

自然语言处理算法有两大类：**传统自然语言处理**和**深度学习**。

**传统自然语言处理涉及大量编码**。你必须要预测用户在每个场景下可能会说的词汇和短语、识别说话类型、再提取预定义的关键词，等等。换句话说，传统自然语言处理有很多规则，很多正则表达式，以及大量的硬编码。所以，你需要花费大量时间写代码，调试程序bug。但是，一旦用户在对话时偏离了预期路径，之前所设定的规则就很容易会被打破，这就是为什么许多机器人让人感到非常愚蠢的原因。

**我们不得不构建大量智能虚拟助手，让它们去维护自然语言对话**。那么问题是，我们能够用传统自然语言处理来实现这个功能吗？貌似看上去不太可能——毕竟难度太大，而且也十分耗时。更重要的是，地球上可能没有那么多程序员来写代码。

## 依靠深度学习来解决聊天机器人的瓶颈问题

幸运的是，现在我们有一个替代方案，这个技术给人们带来了希望，它就是深度学习！相比于特别编写一个明确的规则，现在我们只需要构建一个人工神经网络，然后给它提供培训语言。

然而，构建人工神经网络并不简单，你**需要把不同的算法和解决方案缝接在一起**。好的一面是，当你完成的时候所有工作后，会得到一个可以理解自然语言的神奇机器。如果你注意到它出现了某些错误，完全不需要编写新代码来解决问题——只需给它提供更多学习样本就可以了。而且，你也不需要重新给“机器人大脑”编程，当你有了这样一种机器，会发现团队的工作效率大幅提升，过去需要花费数年时间才能完成的产品，现在即便人手不足也能快速推出。

不幸的是，我们现在还没有这样神奇的机器，然而很多公司都正在朝这个方向努力。现在几乎所有的聊天机器人设计框架都是基于自然语言处理的软件开发包，而不是深度学习技术。换句话说，如今的聊天机器人依然类似于传统的劳动密集型服务行业，但是随着深度学习技术的不断发展，我们应该很快就能看到隧道尽头的曙光了！

---

# 【AI 原力觉醒】《纽约时报》两万字长文，深度剖析谷歌大脑简史

2016-12-15 新智元

来源：NYT

作者：Gideon Lewis-Kraus

编译：胡祥杰、王楠、朱焕、刘小芹

## 序言：谷歌机器翻译的威力

（文／Gideon Lewis-Kraus）11月的一个周五晚上，东京大学著名的人机交互教授 Jun Rekimoto 正准备在线上进行一次报告。忽然，他在社交网络上发现一个消息，谷歌翻译忽然之间有了巨大的提升。他亲自访问了谷歌翻译的页面开始体验。他被震惊了。躺到床上后，谷歌翻译的威力还萦绕在他脑海中，让他无法停止想象。

他起身在自己的博客上写下了自己的发现。首先，他比较了两位日本翻译家所翻译的《伟大的盖茨比》中的几句话与谷歌翻译的结果。他认为，谷歌翻译的结果在日语上非常流畅。他认为，谷歌的翻译虽然有些不自然，但是比起翻译家的作品，对他个人而言，却更加易懂。

随后，他又在谷歌翻译上输入日文（海明威的作品日文版），进而翻译为英文，结果发现机器翻译与海明威英文原著有着惊人的相似度。

四天之后，大量的记者、企业家和广告商汇集到了谷歌位于伦敦的工程办公室，这里会有一个特殊的消息公布，大家都开始猜测是不是会发布翻译工具包。

伦敦市长 Sadiq Khan 首先发言，随后，谷歌首席执行官 Sundar Pichai 上台。Pichai 在伦敦的任务有一部分是为谷歌新的大楼举行典礼。他曾经在多个场合中提到，==谷歌的未来，是要以“AI为先”==。这句话的实际含义非常复杂，也引来了诸多推测。而实际上，**这句话的含义，指的是很快这家公司的产品代表的将不再是传统计算机编程的成果，而是“机器学习”**。

谷歌很少提到的一个部门——谷歌大脑，创建于5年前，遵循的这样一条简单的原理：==人工的“神经网络”能通过试错，来熟知世界，正如婴儿所做的那样，这将为机器带来一些像人一样的灵活性==。这一概念并不新鲜，它出现在20世纪40年代早期，但是绝大部分计算机科学家认为这是很难实现的、甚至是神秘的。2011年开始，谷歌大脑开始用这一方法进军人工智能，希望能解决传统方法尝试了数十年都没有突破的难题。语音识别此前一直做得不好，但是谷歌大脑采用新方法后，让安卓手机上的语音识别几乎做到了人类水平。在图像识别上也是如此，一年多以前，谷歌大脑首次把这一技术应用到了商业化的产品中。

谷歌翻译从2006年开始推出，已经成为谷歌最可信最流行的产品之一。Pichai 在演讲中提到，难民危机使得谷歌再次意识到，跨地区性的翻译多么重要。他背后的显示屏展示了最近在谷歌上阿拉伯语和德语之间的翻译请求数量在增多。

谷歌决心围绕AI重组公司，是整个产业界机器学习热的第一个重要证明。**在过去的4年间，至少有6家公司——谷歌、Facebook、苹果、亚马逊和微软，以及百度，都在抢夺AI人才，特别是在大学中**。企业对资源和自由的承诺，已经吸引了一些学术界人士。起薪7位数也不再是什么新鲜事。另外，学术会议参会人数几乎翻了四倍。他们关注的不再是零碎的创新，而是要控制作为整体的代表的计算平台——==普遍性的、无处不在的人工智能==。

“人工智能”一词被提起时，好像它的意思是不言而喻的，但它一直都是争议的根源。想象一下，如果你回到20世纪70年代，在街上拦住一个人，拿出一个智能手机，向他展示谷歌地图。一旦你设法说服她，你不是一个奇怪穿着的巫师，从你的口袋里拿出的不是一个黑色护身符，而只是一个比阿波罗穿梭机更强大的电脑，谷歌地图几乎肯定似可以让他认为是“人工智能”的一个好例子。在一个非常真实的意义上，它确实是。它可以做任何人类在地图上能做的工作，比如让你从你的酒店到机场，而且它可以做得更快更可靠。它也可以做人类显然不能做的事情：它可以评估交通，计划最好的路线，在你走错路时重新定位自己。

 Pichai 在演讲中重新区分了现在的AI 应用和通用人工智能的目标。**通用人工智能将不是关于具体指令的遵守，而是==带有阐释性和理解性的推动==。它将成为一种通用的工具，为通用环境、通用目的而设计。Pichai认为，谷歌的未来所仰仗的，就是类似通用人工智能的这种东西。想象一下，如果你能告诉谷歌地图，我要去机场，但是我还要在半路去给侄子买礼物。然后让它给你计划路线。这就是一种更通用版本的智能，一个无处不在的助手。就像电影《Her》中描述的那样，她能知道所有的事情，比如，你侄子的年龄、你通常会在礼物上花费多少、怎么找到一家营业的商店。这一般是亲密的朋友会知道的事。但是，一个真正智能的地图还能知道更多，它知道你真正想要什么。根据你此前的行为会给你做出判断。**

现在流行的AI助手：苹果的Siri、Facebook的M和亚马逊的Echo，都是机器学习的产物，有着相同的作用。企业的机器学习梦想是无穷尽的，他们的目的是对消费者有更深的洞察。 

下文讲述的故事，就是从一两个人，到三四个人，再到最后100多人的谷歌大脑，是如何在这一方向上取得巨大进展的。

## 第一部分：会学习的机器

### 谷歌大脑的诞生

虽然 Jeff Dean 的头衔是高级研究员（senior fellow），实际上确实谷歌大脑的大脑。Dean 身材消瘦，瘦长的脸上眼窝深陷，透露着一股热诚。作为医学人类学家和公共卫生流行病学家的儿子，Dean 从小周游世界——美国的明尼苏达州、夏威夷、波士顿、阿肯色州，此外日内瓦、乌干达、索马里、亚特兰大等地，他在高中和大学期间写的软件被世界卫生组织拿去用。他 25 岁左右，也就是 1999 年以来就一直在 Google 工作，从那时起，他在几乎参与了开发所有重大项目的核心软件系统。关于他的种种传说 Jeff Dean Facts 在公司里成了一种文化。

2011 年初的一天，Dean 遇到了吴恩达，那时候吴恩达还是斯坦福计算机科学教授，是谷歌的顾问。吴恩达告诉了 Dean 他自己帮助在谷歌内部建立的一个项目——Project Marvin（以著名的 AI 先驱马文·明斯基命名），用于研究“神经网络”，模仿人类大脑结构的数字网格。Dean 1990 年在明尼苏达大学读本科时也做过类似技术的原始版，当时那段时间神经网络还算流行。现在，在过去的五年中，从事神经网络研究的学者数量已经开始再次增长，从很少几个到几十个。吴恩达告诉 Dean，由谷歌 X 实验室支持的 Project Marvin 已经取得了一些好的结果。

Dean 对这个项目很感兴趣，于是拿出他 20% 的时间参与进来——每个 Google 员工都要拿出 20% 的时间从事自己核心业务以外的工作。很快，Dean 建议吴恩达邀请有神经科学背景的同事Greg Corrado 加入，那时候 Corrado 听说过人工神经网络，但了解不多。后来，吴恩达最好的一个研究生 Quoc Le 也作为项目的第一个实习生加入了团队。到那时，一些 Google 工程师开始用 **Google Brain** 称呼 Project Marvin。

从“人工智能”这个词在 1956 年夏天达特茅斯会议诞生时起，大多数研究人员一直认为创造 AI 的最佳方法是*写一个非常大的、全面的程序，包含了逻辑推理的规则和有关世界的充分的知识*。这种观点通常被称为“*符号 AI*”，它对认知的定义是基于符号逻辑的。

**符号 AI 有两个主要问题。一是非常耗费人力和时间，二是只有在规则和定义非常清楚的领域才能有用：比如数学或国际象棋。**使用符号 AI 做机器翻译效果极差，因为语言虽有规则，但复杂多变，并且还有很多例外。但对于数学和国际象棋来说，符号 AI 工作得很好，而符号 AI 的支持者也认为，没有什么比数学和国际象棋更能代表“通用智能”。

1961年一部纪录片的节选，强调人工智能研究长期以来的观点：*如果可以编程计算机模拟高阶认知任务（比如数学或象棋），就能沿着这种方法最终会开发出类似于意识的东西*。来源：Roberto Pieraccini/YouTube/NYT

但符号 AI 系统能做的事情是有限的。20世纪80年代，CMU 的一位机器人研究员指出，让计算机做成人能做的事情很简单，但让计算机做一岁儿童做的事情几乎不可能，比如拿起一个球或识别一只猫。到20世纪90年代，尽管在国际象棋上取得了很大的进步，我们仍然离通用人工智能很是遥远。

**关于 AI 还有一个不同的看法，这种观点认为计算机将从底层（数据）而不是从顶层（规则）学习。这个概念可追溯到20世纪40年代初，当时研究人员发现灵活自如智能的最佳模型就是人类大脑本身。**说到底，大脑只是由神经元组成的，神经元之间可以相互通电（或不通电）。单个神经元并不重要，重要的是神经元的整体连接。这种简单的结构为大脑提供了很多优势，能够适应环境。==大脑可以在信息很差或缺失的情况下工作；可以承受重大的损害，也不会完全失去控制；可以以非常有效的方式存储大量的知识；可以清楚区分不同的模式，同时又保留足够的混乱以处理歧义==。

你可以用电子元件模拟这种结构，1943 年的实验表明，简单的人工神经元网络可以执行基本的逻辑运算。这些电子元件至少在理论上，可以学习我们人类做事的方式。在生活中，我们会通过各种试错改变神经元对之间的突触连接的强弱。人工神经网络也可以做到类似的事情，通过不断试错，改变人工神经元之间的数字关系。人工神经网络不需要使用固定的规则预编程，它可以改变自身以反映所吸收的数据中的模式。

**这种对人工智能的看法可以说是演化论而不是创造论**。如果你想要一个灵活的机制，能够适应环境，你最开始就不想灌输它固定的规则。你可以从非常基本的能力——感官知觉和运动控制开始，希望更高的技能有机地出现。人类不是通过背诵字典和语法书学习理解语言，所以为什么要让计算机这样做呢？

谷歌大脑是第一个对上述想法进行商用投资的机构。Dean、Corrado 和吴恩达（兼职）开始合作，立即就取得了进展。他们从最近的理论大纲以及自20世纪80年代和90年代的想法中吸取灵感，并利用谷歌无与伦比的数据储备和庞大的计算基础设施。他们将大量“标记”数据输入网络，计算机的输出不断改进，愈发接近现实。

“==动物演化出眼睛是一个巨大的发展==，”Dean 有一天告诉我。我们像往常一样坐在会议室里，Dean 在白板上画了一条繁复弯曲的时间线，表现 Google Brain 以及这个团队与神经网络的历史关系。“现在计算机也有眼睛了。我们可以以此为基础让计算机理解照片。机器人将得到彻底地改变。机器人将能够在一个未知的环境中，处理许多不同的问题上。”他们在机器人身上开发的这些能力可能看起来很原始，但其意义却是深远的。

### 多伦多大学教授 Hinton 成为谷歌的实习生

Geoffrey Hinton 在谷歌多伦多办公室。他的想法为谷歌神经网络机器翻译方法奠定了基础。来源：Brian Finke for The New York Times

Dean 表示，Google Brain 成立后一年左右，开发具有一岁儿童智力的机器的实验取得了巨大的进展。谷歌的语音识别团队将其旧系统的一部分改为神经网络，并且效果得到很大提升，甚至取得了近 20 年中最好的成果。谷歌物体识别系统的能力也提高了一个数量级。这不是因为Google Brain 团队成员在短短一年间产生了一系列超棒的新想法，而是因为谷歌终于投入了资源——计算机和越来越多的人力。

Google Brain 成立的第二年，Geoffrey Hinton 加入了，而吴恩达则离开（现在是百度首席科学家，领导 1300 人规模的 AI 团队）。Hinton 当时只想离开多伦多大学在谷歌待三个月，所以由于各种原因，谷歌不得不被聘他为实习生。在实习生培训过程中，辅导人员会说“输入你的 LDAP（及用户登录码）”，Hinton 会举手问：“什么是 LDAP？”在场所有二十几岁的年轻人，只知道人工智能的皮毛，都在想“那个老家伙是谁？为什么他连 LDAP 都不懂？”

Hinton 说，直到有一天，有人在午餐时对他说“Hinton 教授！我选修了你的课！你在这里做什么？”自此以后，再也没有人质疑 Hinton 作为实习生的存在。

几个月后，Hinton 和他的两个学生在 ImageNet 大型图像识别竞赛中取得了惊人的成果，让计算机不仅识别出猴子，而且区分蜘蛛猴和吼猴，以及各种各样不同品种的猫。谷歌很快就向 Hinton和他的学生提出了Offer。他们也都接受了。“**我以为他们对我们的知识产权感兴趣**，”Hinton 说：“==结果他们对我们这几个人感兴趣==。”

Hinton 出身于一个古老的英国家族。他的曾祖父 George Boole 在符号逻辑方面的基础工作为计算机专业打下基础；Hinton 的另一个曾祖父是著名的外科医生，Hinton 的父亲是一个热爱冒险家的昆虫学家，Hinton 父亲的表哥在 Los Alamos 研究所工作，等等等等。Hinton 先后在剑桥大学和爱丁堡大学学习，然后在卡内基梅隆大学读博士，最后到了多伦多大学，现在 Hinton 大部分时间都在多伦多大学。（Hinton 的工作长期以来一直受到加拿大政府的慷慨支持。）我在 Hinton 的办公室访问了他。Hinton 说话睿智诡异，比如“计算机会比美国人更早理解讽刺”。

Hinton 从上世纪 60 年代末在剑桥大学读本科开始，一直致力于研究神经网络，也被认为是该领域的先驱。很长时间以来，每当 Hinton 说起机器学习，人们都用不屑的眼神看着他。神经网络一度被视为学术死路，主要是由于感知机（Perceptron）这个当时得到过度吹捧的概念。感知机是康奈尔心理学家 Frank Rosenblatt 在 20 世纪 50 年代末开发的一个人工神经网络。当时《纽约时报》报道，感知机项目自助者美国海军期望它“能够走路、说话、会看、会写，会生产（reproduce）自己，意识到自己的存在”。结果这些感知机基本都没实现。马文·明斯基（Marvin Minsky）在 1954 年普林斯顿的论文中以神经网络为研究主题，但他对 Rosenblatt 关于神经范式所做的夸张说法已经厌倦了。（明斯基也在争取国防部的研究资金。）后来，明斯基与 MIT 的同事合作出版了一本书，证明有一些非常简单的问题是感知器永远不能解决的。

明斯基当时对感知机的批评只涉及只有一个“层”的网络，也就是在输入和输出之间只有一层神经网络——后来明斯基阐述了与当代深度学习非常相似的想法。但是，当时 Hinton 就已经知道，如果使用很多层神经网络，就可以执行复杂的任务。简单说，**神经网络就是一台机器，能够从数据中发现模式并以此进行分类或预测**。**有一层神经网络，你可以找到简单的模式；有多层神经网络，就可以找出模式中的模式**。以图像识别为例，执行图像识别的神经网络主要使用“卷积神经网络”（这在 1998 年的一篇开创性论文中阐述的概念，该论文的主要作者、法国人 Yann LeCun 跟着 Hinton 在多伦多大学做了博士后，现任 Facebook 人工智能实验室负责人），网络的第一层学习识别图像非常基本的视觉效果“边缘”，也就是一个像素旁边没有什么任何东西（反之亦然）。接下来网络的每一层都在前一层中寻找模式。边缘的模式可以是圆形，也可以是矩形。圆形或矩形的图案可能是面部，等等。这种方法类似于人眼将信息组合在一起的方式，从视网膜中的光线感受器返回信息到大脑的视觉皮层。在每个步骤中，不立即相关的细节被丢弃。如果几个边缘和圆圈合在一起成为一张脸，你不会在乎在视野中这张脸的位置；你只会在乎它是一张脸。

1993 年的一段视频演示，展示 Yann LeCun 卷积神经网络的早期版本，这个系统到 20 世纪 90 年代末处理美国所有支票的10%~20%。类似的技术现在用于驱动大多数最先进的图像识别系统。来源：Yann LeCun/YouTube/NYT

多层也即“深度”神经网络的问题是试错法部分非常复杂。单层的网络很容易，多层的训练起来就复杂了。Hinton 和其他几个人发明了一个方法（或者说，改进了一个旧的方法）解决这个多层出错的问题，那是在 20 世纪 70 年代末到 80 年代，为此计算机科学家对神经网络的兴趣又短暂地复燃了一会儿。“人们对此非常兴奋，”Hinton 说：“但我们把它夸大了。”于是，计算机科学家很快回到了认为像 Hinton 那样的人是怪人和神秘主义者的状态。

不过，这些想法在哲学家和心理学家之间仍然很受欢迎，他们称之为“**连接主义**”或“**并行分布式处理**”。尽管加拿大政府很慷慨，但就是没有足够的计算机力或足够多的数据。Hinton 表示，支持我们想法的人不断说：“是的，只要有一个大的机器就会工作了，但这不是一个非常有说服力的论据。”

### 深度学习的深度解读

当Pichai在说谷歌将以”AI为先“时，他并不仅仅在描述公司的商业战略，也同时把这一长久以来都没有起到多大作用的概念扔给了公司。Pichai在资源上的分配保证了像Jeff Dean和Hinton之类的人，有足够的计算能力和数据，来取得可靠的进展。一个人类的大脑保守估计有1000亿个排列着的神经元。每一个神经元与10万个类似的神经元相连，也就是说，突触的数量在100万亿到1000万亿之间。对于20世纪40年代提出的一个简单的人工智能神经网络来说，即使要简单的复制这一网络都是不可想象的。我们现在离建造这样一个网络依然还有很远的路要走，但是，谷歌大脑的投资，至少可以让人工神经网络可以与大脑的某一切片功能相当。

要理解扩展性（Scale）为什么那么重要，你需要理解更多的细节，也就是，机器究竟对数据作做了什么？我们对AI的普遍性的恐惧，大都来源于认为它们会像一个神秘的学者一般在图书馆挖掘学习知识，然后，从前只会裁纸的机器或许有一天能像对待一只蚂蚁或者莴苣一样对待人类。但这并不是AI 的工作方式。**它们所做的全部事情都是搜索信息，寻找共同点，最开始是基本的模式，随后会变复杂，最后，最大的危险在于，我们所喂给它们的信息从一开始就是错误或者带有偏见的**。

**“知道什么”和“做什么”的权衡具有真正的文化及社会影响**。在聚会上，Schuster 走到我跟前，诉说向媒体解释他们的论文的挫折。他问我：“你看了最早出来的新闻吗？”他复述早报上的一个标题，一个字一个字地指着念：“谷歌说AI翻译已经与人类无差”。在论文即将完成的最后几周，团队没停下过奋斗。Schuster 经常重复地向人解释，论文表达的是“谷歌翻译比以前好多了，但还不如人类好”。他表达的很明确，他们的努力不是说要替代人类，而是辅助人类。

### 识别猫脸的论文

在谷歌大脑成立的第一年到第二年间，他们让机器掌握一岁小孩的技能的努力幸运地达成了，所以，他们的团队也从谷歌X实验室“毕业”，转变为更大的研究机构。（谷歌X的主管曾经说过，谷歌大脑负担了所有X实验室的成本支出。）他们的人数在当时仍然少于10个人，对于最终会实现什么，也只有一些模糊的感觉。但是，即便是在当时，他们的思想也走在了前面，想着接下来会发生什么。人类的思维中，首先学习的是形状，比如说一个球，然后也会很舒服地接受所学到的知识，停留一段时间，但是迟早的电脑会需要问关于这个球的事，这就过渡到了语言。

在这一方向上，谷歌大脑做的第一件事是“识别猫”，这也是令谷歌大脑声名大噪的一件事。“识别猫”的论文展示的是，带有超过10亿个“突触”连接的神经网络，这比当时任何公开的神经网络模型都要大好几百倍，但是与人类的大脑相比，依然小了好几个数量级。这一神经网络能识别原始的、费标签的数据，并识别高难度的人类概念。谷歌大脑的研究者向神经网络展示了几百万帧静态的Youtube 视频，然后，神经网络的感觉中枢开始运转，分离出了一个稳定的模型。和所有的小孩一样，这一模型能毫不犹豫地识别出猫的脸。

研究员从未把关于猫的先验知识编程输入到机器中，机器直接与现实世界交互并且抓住了“猫”这一概念。（**研究者发现，这一神经网络就好像核磁共振成像一般，猫的脸部的阴影会激活人工神经元，让它们产生集体的唤醒**。）

 当时，绝大多数机器的学习都受到标签数据的数量限制。“识别猫”的论文展示了，机器同样能识别原始的非标签数据，有时候或许是人类自身都还没建立起知识的数据。这一研究看起来并不仅仅是让机器识别猫脸的巨大进步，对于人工智能的整体发展都有很大意义。

“识别猫”的研究第一作者是Quoc Le。Le 又矮又瘦，说话轻柔但语速极快，他从小在越南长大，父母都是农民，小时候家里甚至都没有电。但是，他在数学上的天赋显然来自他的童年时期。20世纪90年代，他还在上学时，就曾经尝试开发聊天机器人。他在想，这会有多困难呢？

“但是实际上”，他告诉《纽约时报》的记者，“这非常难”。

随后，他离开了越南到澳大利亚的堪培拉大学学习，主要研究计算机视觉一类的AI任务。当时，这一领域使用的方法，是要给机器填入大量的关于事物的定义性概念，这让他觉得像是在作弊。Le 当时并不知道，或者说不是清楚地知道，世界上另外一些地方至少有几十名计算机科学家和他一样，也同时在情不自禁地想象：机器是能够从零开始学习的。

2006年，Le 在德国的马克斯普朗克研究所生物控制部门任职。在那里的一个读书小组中，他看到了Geoffrey Hinton 的两篇论文，他觉得自己的双眼瞬间明亮了。

“当时有很大的争议”，他告诉我说，“非常非常大的争议”。他看了一眼自己画在白板上曲线，又轻声重复到，“我从来没有见到过那么大的争议。”

 他记得自己在阅读小组中站起来，并说：“这就是未来。” 他回忆说，在当时，这并不是一个很受欢迎的决定。他在澳大利亚的旧导师曾写邮件问他，“你为什么做了这个决定？”

 “当时我并没有想到好的答案，我只是好奇”，他说，“（论文）提出了一个很成功的范式，但是老实说，我只是对这一范式感到好奇。”随后，他去了斯坦福，加入了吴恩达的团队，开始追求Hinton的理念。“2010年年底，我已经非常确信，会有一些事情发生了。”

随后，他到伦敦开始第一份实习，并完成了毕业论文，这也是“识别猫”的论文的前身。

在一个简单的层面上，Le想看看计算机是否可以被训练，从而自己识别对于给定图像绝对必要的信息。他给神经网络填入了一个他从YouTube采取的静态片段。然后他告诉神经网络丢弃图像中包含的一些信息，虽然他没有指定应该或不应该丢弃的东西。机器抛弃了一些信息，最初是随机的。然后他告诉计算机：“刚才是开玩笑！现在重新创建初始图像，你只是根据你保留的信息进行显示。“就像他要求机器找到一种方法来”总结图像，然后从摘要再回溯到最初的图像。如果摘要是基于不相关的数据 ， 如天空的颜色，而不是胡须 ， 机器就不能执行好的重建。

机器的反应跟远古时期的人类很像，他们对于一只老虎的印象，是在自己看见狰狞的老虎时跑开的过程中留下的。但是，与人类的祖先不同的是，Le的神经网络，需要进行一次一次又一次的尝试。每一次，从数学的层面上，都会选择对不同的信息进行优化，然后表现会越来越好。

但是，神经网络是黑箱。它确实产生了一个模型，但是模型本身通常很难被人类理解或者观察到。

Le 并没有觉得“猫脸识别”的成果让他变得更有发言权，但是，他感受到了一种动力，这种研究也许跟他早年希望开发的聊天机器人有联系。在“识别猫”的论文发表以后，他意识到，如果你能让一个神经网络对照片进行总结，你也可以让它对一些句子进行总结。在接下来的两年中，这些想法一直缠绕着Le，以及他在谷歌大脑的同事——Thomas Mikolov。

有一段时间，他们与谷歌的高管分享同一个办公室。后来有一天他们从管理员处得到一封电子邮件，要求他们不要再让团队成员在Larry Page和Sergey Brin的套房前面的沙发上睡觉。后来，他们终于在街道对面分到了一个办公室。

在谈到Mikolov 时，Le变得很严肃，但是又不断提起他们的合作。后来才知道，原来Mikolov 后来去了Facebook。

![](http://mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb12jpibIgFOT8LqTn52Lnaic1Qvxe5WrSfGaBdxiblaGqESbRYVAcaqv9M7uPibsV89L391gSfaqppgEw/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)

> Google Brain 团队成员 2012年合影，他们著名的“计算机识别猫脸”展示了神经网络分析未标记数据的能力。来源：谷歌

他们在这段时间试图设计出的神经网络架构，不仅可以适应简单的照片分类，这是静态的，而且还复杂的结构，随着时间的推移变化的，如语言或音乐。这些概念许多是在20世纪90年代首次提出的。Le和他的同事回到了那些长期被忽视的概念中，看看他们可以收集什么。他们知道，一旦你建立了一个具有基本语言预测能力的设施，你就可以继续做其他各种智能的事情， 例如预测一个合适的电子邮件回复，或预测一个智能的谈话的流s程。你就可以侧重于那种看起来很像思维的能力，至少从表面看是这样的。

## 第二部分：语言机器

### 语言学的转折

谷歌大脑中现在有上百名的成员，但是它看起来并不像是一个有着明显的层级结构的部分，而是更像一个俱乐部或者学术团体，或者一个小酒吧。团队成员不少是来自谷歌整个体系中最自由、最受敬仰的员工。他们现在在一个两层蛋壳建筑中办公，有巨大的窗户：他们的小厨房有一个桌式足球我从来没有见过使用； Rock Band 我从来没有见过使用；和一个Go工具箱我看到使用了几次。 

 我在6月份第一次到谷歌大脑办公室时，还有许多空余的办公位，但是现在已经全满了。

谷歌大脑的成长使得 Jeff Dean对公司如何处理需求感到有些担忧。他希望避免在谷歌被称为“成功灾难”——这种情况指的是，公司的理论研究能力超过了实际开发产品的能力。某一天，他在做了一些计算后，向高管作了汇报，只用了两页的PPT。 

“如果未来每个人每天都对自己的安卓手机说话三分钟，”他告诉高管，“（由此产生的数据计算需求）就是我们所需要的机器数量。”未来，他们需要把自己的全球计算配置翻2-3倍。

“这也就是说，你必须建造新的大楼，”Jeff Dean 在说这话时，带了明显的犹豫和斟酌。

但是，他们显然还有另一个选择——设计出大规模生产的，能在不同的数据中心分散使用的新芯片。加快运算速度。这些芯片被称为TPU。这些芯片比传统芯片在精确度上要低一些。但是运算速度更快。从`12.246 X 64.392` 变为 `12 X 64` 。

在数学层面上，神经网络只是数百或数千或数万的矩阵乘法，以连续不断的形式出现。所以，让计算更快比更准确要重要。

**通常，Dean说，“专用硬件是个坏创意。它通常只可以加速一件事。但是由于神经网络的通用性，你可以利用这个专用硬件来处理很多其他事情。”**

就在芯片设计接近完工时，Le 和他的两位同事终于证明了神经网络可能可以处理语言结构。他描绘了一个“**词嵌入**”的概念，这一概念出现已经有10年了。也就是说，当你对图像进行总结时，你可以分隔图像，来分阶段组成总结，比如边缘、圆圈等等。当你用相同的方式对语言进行总结，你最重要的是要制造出关于距离的多维度地图。机器不会像人类一样去“分析”数据，使用语言规则来区分是名词还是动词。它们只是转化和改变或者组合地图中的词。

如果你能把所有法语中的词和所有英语重点词放在一起，至少在理论上，你可以训练一个神经网络，来学习如何把一个句子放到空间中，并产生一个类似的句子。 

你要做的是把这些数百万的英语句子作为输入，把可能的法语句子作为输出，在多次训练后，模型能是被出相关的词语组合模型，这和图像识别中的像素模型是一样的。然后你就能给机器一个英语句子，让他它产出一个与之匹配的法语句子。

词和像素最大的不一样在在于，图中的像素是一次性能全部拿到的，但是，**词的出现是根据时间渐进的。你需要让网络“记住”这种连续性，或者序列性**。2014年9月，有三篇论文发表，一篇是Le写的，另外两篇来自加拿大和德国，这些论文至少提供了完成这些任务所需要的理论工具。这些研究让谷歌大脑中的一些项目成为了可能，比如研究机器如何生成艺术作品和音乐的Magenta。研究也为机器翻译等实用性应用打下了基础。Hinton 对《纽约时报》的记者说，他本来认为这些研究要至少5年或者更多的时间才能做成。

### 伏击

Le 的论文显示神经翻译是可行的，但他只使用了一个相对较小的公共数据集。（所谓的小只是相对于Google的体量而言。这个数据集实际上是世界上最大的公共数据集。十年来，原有的Google Translate已经收集了上百到上千倍的生成数据。）更重要的是，Le的模型对长于约七个字句子的效果不是很好。

谷歌大脑的研究科学家 Mike Schuster 接手了指挥棒。他知道，如果谷歌没有找到一种方法来扩展这些理论洞见至生产水平，那么别人会。这个项目花了他接下来的两年。 “你会认为，” Schuster 说，“要翻译东西，你只需得到数据，运行实验，你就完成了，但实际不是这样的。"

 Schuster 是个紧张、专注、不显老的人，长着一个晒黑的、活塞形的脑袋，窄肩，长迷彩短裤垂至膝盖之下，脚踏绿色 Nike Flyknits 鞋。他的模样看起来好像早上他刚从莲蕊中醒来，抓起他那小而无边的椭圆眼镜，像松鼠吃橡子般补充了卡路里，并在来办公室的路上完成了一个轻松的沙漠十项全能。在现实中，他告诉我，他骑行了18英里来上班。

Schuster 在前西德的重工业区杜伊斯堡长大，研究电气工程，然后前往京都从事早期的神经网络。在20世纪90年代，他用来运行实验的神经网络机像会议室一样庞大; 它要花费数百万美元，必须训练几个星期，却只能做一些你现在可以一小时内在电脑桌面能做到的事。他在1997年发表了一片文章，在之后的十五年里几乎无人引用；而今年，这篇论文已被引用了大约150次。他不失幽默，但他经常露出严厉的表情，我认为这种表情体现了他的德国式克制和日本式克制的结合。

 Schuster 必须处理的问题是缠结性的。首先，Le的代码是定制化的，它与Google当时开发的新开源机器学习平台TensorFlow不兼容。Jeff Dean在2015年秋天向Schuster指派了另外两位工程师，Wu Yonghui和Zhifeng Chen。他们花了两个月的时间把Le的结果复制到新系统。Le 也在附近，但即使Le本人也不是总能理解项目的进展。

 正如 Schuster 所说，“有些东西的进展不是能完全意识到的。工程师自己也不知道新系统为什么行得通。”

今年二月，谷歌的研究机构 ——该机构是谷歌的一个较为散漫的部门，大约 1000 名员工，致力于前瞻性和不可分类的研究 —— 在旧金山威斯汀酒店的联合广场上召集骨干进行外出静思会，酒店的豪华程度略逊于谷歌在一英里外的自家店铺。上午进行了几轮“闪电会谈”，快速交流了研究前沿，下午则在跨部门的“互促性讨论”中度过。谷歌希望静思会可以带来不可预测的、间接的、贝尔实验室式的交流，以让谷歌这个成熟的公司保持多产。 

在午餐时间，Corrado 和 Dean 结伴寻找谷歌翻译的主任 Macduff Hughes。Hughes正在独自吃饭，Corrado和Dean从两侧截住了他。正如Corrado所说，“我们伏击了Hughes"。

“嘿，”Corrado 对屏住呼吸、面露怀疑的 Hughes 说： “我们有东西告诉你。”

他们告诉Hughes，2016年似乎很适合用神经网络对谷歌翻译—— 由数十名工程师10多年积累的代码 ——进行大修。旧系统采用的是所有机器翻译系统已经用了30年的工作方式：它从每个连续句子中分出片段，在一个大型统计词库中查找这些词，然后应用一组后处理规则以附加适当的词缀，并重新排列以产生意义。这种方法被称为“基于短语的统计机器翻译”，因为当系统到达下一个短语时，它并不知道上一个短语是什么。这也就是 Google Translate的输出有时看起来像一大包冰冻磁铁的原因。Google Brain引入的大修，将使它能一次性阅读和渲染整个句子，让它能捕捉语境，以及某种近似于意义的东西。

项目带来的利益似乎很低：谷歌翻译产生的收入很低，而且这种状况大概会持续下去。对大多数英语用户来说，即便服务性能实现了彻底升级，他们也只会将之视为预期之内的进步。但这个团队要证明，实现人类质量的机器翻译不仅具有短期必要性，而且会带来长远的革命性发展。在不远的将来，它将对公司的业务战略至关重要。谷歌估计，50％的互联网使用英语，这可能占世界人口的20％。如果谷歌要在中国—— 在中国搜索引擎流量的大部分份额属于其竞争对手百度——或印度进行竞争，体面的机器翻译将是基础设施不可或缺的一部分。百度本身已经在2015年7月发表了一篇关于神经机器翻译可能性的开创性文章。

在更遥远的、可推测的未来，机器翻译也许是朝向一个具有人类语言能力的通用计算设施的第一步。而这将代表通向真正人工智能的一个重大拐点。 

硅谷的大多数人都知道机器学习的前景正在快速接近，所以Hughes也预计到了他会被机器学习团队的人伏击。但他仍然感到怀疑。他是一个温和，固执、一头灰发的中年男子。他是一个老牌的流水线型工程师，那种在1970年代的波音公司能看到的工程师。他的牛仔裤口袋里经常塞着奇形怪状的工具，好像他正要去测量磁带或热电偶，和许多为他工作的年轻人不同，他有自己的柜子。他知道在谷歌和其他地方的各种人一直在尝试进行应用层面的神经翻译工作，这些工作已持续多年但没什么进展。

Hughes 听了 Corrado和Dean的建议，最后他谨慎地说，也许他们可以把计划延迟到三年之年之后。

Dean不这么认为。他说， “我们可以在年底之前做到这一点，如果我们全神贯注去做的话。”人们如此喜欢和钦佩Dean的一个原因是，他长期以来总是能全神贯注地办成事。另一个原因是，当他真诚地说出“只要我们全神贯注就能办成”的时候，他一点也不怕尴尬。

休斯很确定，这种系统转换不会在短时间内发生。但他也不拒绝尝试。他回去后告诉他的团队： “让我们为2016年做准备吧。我不会是那个说Jeff Dean无法带来改变的人。”

一个月后，他们终于能够运行一个并行实验以比较Schuster的新系统和Hughes的旧系统。Schuster想用英语 - 法语语言对来测试它，但Hughes建议他尝试别的语言对。 “英语 - 法语翻译已经很好了，改进不会很明显。” 

这是一个令Schuster无法抗拒的挑战。评估机器翻译的基准度量被称为BLEU分数，它将机器翻译与大量可靠的人类翻译的平均值进行比较。当时，英语 - 法语的最佳BLEU分数值高达20多。将分数提升一个点，将被认为是非常好的改进；提升两个点就会被认为是是杰出的。

**在英语到法语语言对上面，神经系统相比旧系统带来了高达 7 分的改进**。 

Hughes告诉Schuster的团队，在过去四年里，他们在自己的系统中从没有出现过这么强劲的改进。 

为了确保这不是一个侥幸，他们也雇人进行人工对比。在用户体验得分系统中，样本句子的分值从0到6，神经系统带来的平均改善达0.4，这大致相当于旧系统在其整个生命周期中带来的总增益。

3月中旬，Hughes 给他的团队发了一封电子邮件：旧系统上的所有项目都将立即暂停。

### 让概念成为产品

在那之前，神经翻译团队只有三个人 ——Schuster、Wu 和 Chen ——但随着Hughes的支持，更广泛的团队开始合并。他们星期三下午 2 点在 Schuster 的引领下来到了位于Quartz Lake 的Google Brain办公室内的一个角落房间。会议有十几人参加。当Hughes或Corrado在场时，他们往往是唯一的两名英语母语人士。工程师们有的讲中文，越南语，有的讲波兰语，俄语，阿拉伯语，德语或日语，虽然在现实中他们大多使用高效的混杂语数学来交流。在Google，人们并不总是清楚谁正在组织开会，但这一次的会议目的则很清楚。

即便如此，他们需要采取的步骤仍不是完全清楚。 “其中有很多不确定性 —— 整个过程的不确定性，”Schuster告诉我。 “软件，数据，硬件，人。” 他伸出他长而宽松的手臂，轻轻在肘部弯曲，这就像在大海里游泳，你只能看到这远。“他把他的手伸出到胸前8英寸那么远。 “目标在某处，或许它就在那里。”

大多数Google的会议室都配有视频会议显示器，当闲置时，会显示极高分辨率的Google+照片，包括田园风光、北极光或帝国议会大厦的照片。Schuster向其中一个屏幕打了个手势，那个屏幕上正显示着华盛顿纪念碑的夜间一瞬。

“外人会认为，每个人都有双筒望远镜，可以看到前方。“

让他们到达此地的理论工作已经用光，但要把它变成一个可行的产品 ——这被学术科学家称为“纯粹的”工程的部分——仍非常难。首先，他们需要确保他们在良好的数据上进行训练。 Google用来进行“阅读”训练的数十亿词语料主要是由中等复杂性的完整句子组成，这些句子就像你可能在海明威作品里读到的那些。其中一些是公共领域文献，统计机器翻译的最初语料是加拿大议会的数百万页完整双语记录。然而，它的大部分是从10年来由热心者众包的人类翻译作品中筛选而来。该团队的语料仓库里有9700万个互不相同的英语“词”。但是一旦他们删除了表情符号、拼写错误和冗余，剩下的工作词汇只有大约16万。

而后，团队必须重新去关注用户实际想要翻译哪些内容，而这通常并非标准而合理的语言。谷歌发现很多人并不使用谷歌翻译来翻译完整、复杂的句子。他们用它来翻译古怪的小碎片般的语言。如果你希望网络能够处理用户查询的数据流，你就必须确保能在这个方向上前进。神经网络对用于训练的数据非常敏感。正如Hughes向我提到的：“神经翻译系统正在学习一切。它就像一个孩子。 ”他笑道。“它会说，‘ 哦爸爸发疯的时候才会这么说话！ ’ 你必须要小心。” 

不管怎样，他们需要确保整个事情快速可靠，从而不给用户带来困扰。在2月，神经系统翻译10个字的句子需要10秒钟。公司不可能向用户推出这么慢的东西。翻译小组开始对一小部分用户进行延迟实验，假装翻译时间会延迟，以观察用户的忍耐程度。他们发现，如果翻译时间只延长了两倍甚至五倍，便不会被用户注意到。如果延长了八倍，就会被注意到。团队不需要确保所有语言都是这样。在（如法语或中文等）高流量语言的情况下，翻译服务几乎不会放慢速度。团队想知道，对于那些更模糊的语言翻译，用户不会因为轻微的延迟而拒绝更好的翻译质量。他们希望能防止人们放弃使用翻译、也防止人们转去使用竞争对手的翻译服务。

Schuster承认,他并不知道他们是否能够使它变得足够快。他记得在餐室中他曾对Chen说：“肯定有一些我们不知道的东西能使它变得足够快，但我不知道它是什么。”

不过，他知道他们需要用更多的计算机——更多的图形处理器来重新配置神经网络进行训练。

Hughes去问Schuster的想法： “我们是不是应该要求一千台GPU？” 

Schuster回答，“为什么不是2000台？” 

十天后，他们拿到了新加的2000个GPU处理器。 

到4月份，原来的三人阵容已变成超过30人。其中一些人，如Le，来自Google Brain；也有许多人来自 Google Translate。 5月，Hughes为每对语言配置了一种临时主管，每个主管都将进展结果录入一个大型共享的绩效评估电子表格。任何时候，都有至少20个人正在进行他们自己的独立的、长达一周的实验和处理意外问题。有一次某个模型开始毫无理由地把所有的数字从句子中剔除。经过了几个月才解决这个问题。 “人们几乎气得要大吼。”舒斯特说。

到春季末期，各组的工作都聚集在一起。团队引入了一些诸如“word-piece” 模型， “coverage penalty”， “length normalization” 之类的东西。Schuster说，每个部分都把结果改进了几个百分点，但合起来它们有显著的效果。一旦模型被标准化，它将是一个单一的多语言模型，将随时间而改进，而不是目前使用的150个不同的翻译模型。不过， 当创造一个工具通过机器学习来实现普遍化时，实现自动化的过程总是需要超出寻常的人类天分和努力。这个项目也是如此：每层要多少神经元？ 1024还是512？要多少层？一次运行多少句子？训练多久？很多决定都依赖内心深处的直觉。

“我们做了数百次实验，”Schuster告诉我，“直到有一天我们知道，我们可以在一个星期后停止训练。你总是会问：我们什么时候能停下来？我怎么知道我完成了？你永远不知道你做完了。机器学习的机制从来不是完美的。你需要训练，在某些时候你必须停止。这是这个系统的一个非常令人痛苦的特质。对一些人来说这很难。这是有点像艺术 ，像用画笔作画。有些人做得更好，有些人做的比较糟。”

到5月份，Google Brain团队了解到，他们唯一能够使系统作为产品快速实现的方法是，在T.P.U.上运行Dean所要求的专用芯片。正如Chen所说：“我们甚至不知道代码是否能工作。但是我们知道如果没有T.P.U.，肯定是干不成的。”他记得，他们曾经一个接一个地去向Dean请求，“请为我们保留一些T.P.U.的份额”。Dean为他们保留了份额。然而，T.P.U.无法顺利工作。Wu花了两个月坐在硬件团队的人的旁边，试图找出这是为什么。他们不只是调试模型，他们也调试芯片。神经翻译项目将成为对这整个基础设施投资概念的一个验证。

6月的一个星期三，Quartz lake办公室的会议上，人们对百度发表在领域核心期刊上的一篇文章议论纷纷。Schuster 让会议室恢复了秩序。 “是的，百度出了一篇新论文。感觉就像有人看透了我们做的东西——论文有类似的结构，类似的结果。”百度公司的BLEU分数基本吻合 Google 在2月和3月内部测试中取得的成绩。 Le并未感到不快。他的结论是，这是一个迹象，表明谷歌是在正确的轨道上。 “这个系统与我们的系统非常相似。”他安静地说。

Google团队知道。如果他们早些时候发布了他们的结果，可能会打败他们的竞争对手，但正如舒斯特所说：“启动产品比发布论文更重要。人们会说，'哦，这个发现是我先做到的。”但到了最后，谁会关心呢？'"

然而，这确实要求他们必须更好地研发自己的翻译服务。Hughes希望，他们甚至不用告诉用户他们已经更换了系统。他们只需等待，看看社交媒体是否会发现这些巨大的改进。

“我们不想说这是一个新的系统，”他告诉我。劳动节之后第二天下午5:36，他们向10％的用户推出了中文到英语的神经翻译服务，没有将切换告诉任何人。 “我们想确保它能行得通。最理想的情况是，它在Twitter上引起了爆炸：'你看过谷歌翻译有多棒吗？'”

### 庆祝

在缺乏季节感的硅谷，只有两个感知季节的方法，一是小厨房里水果的变化——仲夏时期是杏李，早秋换成梨和柿子——二是技术进步的曲折。9月下旬一个天气温暖得让人不自在的周一下午，团队的论文终于发布了。论文有 31 位作者。第二天，谷歌大脑和翻译团队的成员们聚在一起，在翻译部门的小厨房开了一个小小的庆祝会。

夏威夷风格的小厨房的一面墙是一幅有纹理的海滩照片，以及一个小小的装饰着花环的茅草屋似的服务台，中间有一只毛绒鹦鹉，天花板上挂着纸灯笼一样的装饰。那天早上，他们庆祝翻译团队成立十周年，有许多已经在新部门的前团队成员过去了。某种程度上，他们也是庆祝十年的合作努力，在那一天终于得以中途休息。两个团队的工程师和计算机科学家们似乎都很高兴。

“这就像在泥海里游泳，目之所及只有这么远。”Schuster 伸手在胸前比划了大约8英寸。

谷歌的神经翻译终于成功了。在庆祝会之前，团队已经测试了1800万条汉英翻译。翻译团队的一位工程师拿着手机到处跑，试图用百度翻译测试汉英整句翻译。任何人听他讲话他都很高兴。他说：“如果同时输入两个以上的字符，它就会超时！”（百度说从来没有用户报告过这个问题。）

消息传得很快，接下来的几周，谷歌已经将神经翻译引入到谷歌翻译的中译英。有些人猜测这是谷歌取得好结果的唯一的语言对。但当时庆祝会上的每个人都已经知道，他们所取得的成就将在11月公之于众。不过到那时，团队的许多人可能已经进入其他项目。

Hughes 清了清嗓子，走进这间夏威夷风情的小酒吧。他穿着一件褪色的绿色polo衫，领子有点皱，腹部位置染上了暗色的汗渍。他说，最后有一个问题，然后是最最后还有一个问题，说了论文中存在的一个严重的测试误差，以及系统中有一个奇怪的与符号有关的 bug。但一切都解决了，或者至少是暂时已经解决了。庆祝会上人们都安静了。Hughes 开会非常高效，他对唠唠叨叨或者一面之词的容忍度很低，但场面的严肃让他停下来。他承认他可能是在比喻，但他认为强调事实很重要，他说，神经翻译项目本身就是“使用不同语言的团队成员之间的合作”。

他继续说道，神经翻译项目是一个“向前的阶跃”，即一种并不连续的进步，是垂直的飞跃，而不是平滑曲线式的进步。与翻译相关的不只是两个团队之间的合作，而且是从理论到现实的实现。他举起香槟：

“为了沟通，”他说，“以及合作！”

工程师们聚在一起，互相看看，发出略显慎重的欢呼声和掌声。

Jeff Dean 与 Corrado 和 Schuster 一起站在小厨房的中央，他的手插在口袋里，肩膀微微内耸。Dean 注意到他的在场令气氛有些凝重，他以非常有他的特点的低调方式，轻快、简洁地补充了一句。

他说，他们同时做成了两件事：“做研究，以及，我估计，在5亿人之前做成了。”

大家都笑了，不是因为这句话夸张了，而是因为它一点也不夸张。

### 结语：会说话的机器

也许历史上最有名的对人工智能的批判，或者说是以它的名义的断言，即暗示了翻译的问题。1980年伯克利哲学家 John Searle 提出“中文房间”（Chinese Room）实验，借以反驳强人工智能的观点。在 Searle 的思想实验中，一个对汉语一窍不通，只说英语的人被关在一间只有一个开口的封闭房间中。房间里有一本用英文写成的手册，指示该如何处理收到的汉语讯息及如何用汉语相应地回复。房外的人不断向房间内递进用中文写成的问题。房内的人便按照手册的说明，查找到合适的指示，将相应的中文字符组合成对问题的解答，并将答案递出房间。房内的人很快就熟悉手册指示的内容，他的答案也很快变得“与中文母语者的难以区分”。难道房内的人“理解”了中文吗？Searle 认为显然不是。

在上述过程中，房外人的角色相当于程序员，房中人相当于计算机，而手册则相当于计算机程序：每当房外人（程序员）给出一个输入，房内的人（计算机）便依照手册（程序）给出一个答复（输出）。而正如房中人不可能通过手册理解中文一样，计算机也不可能通过程序来获得理解力。Searle 后来写道，这个计算机的隐喻，引出了这样一种观点：“有正确的输入和输出，并且被正确编程的数字计算机，将因此具有心智，正如人类具有心智一般。”

**但即使像谷歌这样庞大的创新机构也将面临这种自动化浪潮的威胁，一旦机器能够从人类的话语学习，即使是程序员这类的舒适工作都将受到威胁。**

编译来源：http://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html?_r=0

---

# 人工智能范式转移与传统职业的消失

2017/01/04阅读 588 评论 0收藏 1

产品总监修炼之道开课，BAT大咖教你突破职业瓶颈，实现向产品总监的真正飞跃。[了解详情](https://www.qidianla.com/course/zongjian.html?channel=topdetail)

> 容易被取代的职业是哪些只有“硬技能”的职业，重复劳动、可预见、有明确流程和方法论的工作，而“软实力”，比如对事物之间的关联性有深入理解的，感性的，则处于相对安全的范围。但，未来不会有永久的安全区域。

1899年，爱迪生听福特介绍完汽车之后表示：马的末日已经来临。不过汽车在大街上畅通无阻奔驰之前，还是遇到了很大的阻力。当时乘坐马车的人不喜欢汽车，马车夫和马车铺老板更是恨透了汽车。在英国甚至有一个交通法规叫“红旗法”（1858-1896年），蒸汽汽车市内限速2英里/小时以下，郊外限速4英里/小时以下。旧金山也曾规定汽车在市内行驶的速度不能超过8英里/小时。对汽车的歧视不仅包括汽车不能超过马车速度，还有马车与汽车相遇时，汽车要停车为马车让路，马车夫甚至可以要求汽车司机发动机熄火，让马车安静通过。

但不管什么法令，汽车最终还是取代了马车，成为20世纪以来人类最主要的交通工具之一。人工智能对未来各种职业变化产生的影响，只会更加彻底。人工智能代表了更高的生产力，不管行业工会和政策如何压制，最终它还是会胜出。

那么，如何看待人工智能近期的加速？人工智能的变化对哪类职业会产生影响？

## 一、机器学习范式的转变

人工智能之所以变热、加速，很重要的原因是机器学习取得了重大的突破，而这个突破在于思考问题方式的转变。比如**深度学习不再试图对整个世界建模，而是对大脑进行建模**。范式的转移带来全新的突破。这加速了生产力的提升，加速了职业的变化，有的职业将消失，甚至绝大多数目前的职业都将消失，而新的职业将诞生。

从1956年提出人工智能概念到2016年，刚好60年，人工智能走到突破点上。人工智能的三驾马车：==算法、算力和数据==。算法有了很大的进步，深度学习技术可以大量处理未标记非结构化的数据，可以无监督训练及有监督的反向支持运算等；算力方面，GPU的大发展为人工智能的计算速度提供了基础支持。而数据是所有人工智能之源。所有的决策，所有的行为，最终归结为数据。

从具体的发展来看，目前**语音识别、图像识别、自然语言处理、自动驾驶**都有了实实在在的长足进步。

首先图像识别正确率的提高，图像识别的错误率减少到了7%，语音识别错误率减少到4%。图像识别相当机器的眼睛，它通过图像识别能够看到世界。在人工智能基准测试ImageNet上，微软、谷歌和百度都曾经取得过5%以内的识别错误率，这是一个很了不起的成绩，因为人眼识别的错误率大概为5.1%。其次，语音识别率大大幅提高。在国内百度、搜狗和科大讯飞对外公布语音识别准确率均达到97%。

更重要的是机器学习的方法让它变得越来越犀利。之前人工智能靠的是穷举法。比如图像识别要靠通过设立规则开发系统来识别物体，比如猫、狗等动物。自然语言处理则需要通过语言学家们把语法规则编写出来，并设计程序开发来完成。机器学习则换一个模式解决这个问题。把规则问题转换为数据问题。比如说，让要机器学习“猫”，传统的方式把识别的规则写出来。而机器学习则让自己去学习：从一定数量的标记为“猫”的图片和没有标记为“猫”的图片中，让神经网络去把“猫”找出来。之前由于算力和数据没有办法解决学习问题，但今天，这都不是问题。

==数据对规则形成了碾压==。甚至人工智能学家宣称：“每解雇一名语言学家，语音识别机器的表现就提高了一点。” 由于这是一个通用的方法论，这样机器学习就可应用到所有数据的领域，比如金融科技，通过机器学习找到高风险人群的特征。

## 二、机器学习范式转移加剧对传统职业的冲击

机器学习，尤其是深度学习的快速发展让很多工作面临被取代的局面，这个进程还在加快。更可怕的是，==未来人工智能将在数据分析上比人类更聪明==。这也意味着人类不仅仅在一些机械的工作上被取代，甚至一些复杂的计算工作也会被取代。

**容易被取代的工作包括纯机械体力劳动、有明确方法论和逻辑及流程的职业**。==难以被取代的工作，主要是关于人的体验、感性、暂时没有明确方法论和流程可以解决的行业和职业==。比如创意娱乐艺术类。

未来可能今天的绝大多数职业都要消失，这里也没有办法穷举。目前看来显而易见的一些行业和职业很快就要受到冲击。

### 翻译

谷歌神经网络翻译（Neural Machine Translation）从2014年开始，仅仅两年的时间，就发生了翻天覆地的变化，英语和法语，英语和西班牙的互译质量达到了90%以上。百度翻译采用的则是深度学习和统计结合的翻译系统，同时还加收入了语言处理、语音交互的场景，目前支持超过28种语言互译。微软也曾发布微软翻译（Microsoft Translator），实现9中语言实时语音转文本的翻译。

像谷歌和百度等采用神经网络翻译系统之后，能够让翻译不仅仅是按字句进行，而是可以根据一篇文章大意对文章进行分析，极大降低了错误率。

目前谷歌翻译、百度翻译还不够完美，但是每年都在进步，估计过了五年十年，比普通人类翻译做得还好。

为什么？因为这是机器学习范式转变带来的变化。**机器翻译实现了从统计式的翻译转向了神经网络翻译**。也就是从统计，从穷举，从规则转向了机器学习。机器学习的方法意味着翻译的效果会越来越好。这才是从事翻译工作的人们需要担心的问题。

### 记者

大多数记者写稿的工作也可能被取代。比如美联社有90%的文章采用机器写手的文章。腾讯也开发了机器人写作新闻稿，按照算法在最快时间生成稿件，瞬时将重要资讯和解读发布给用户。

目前看，机器人写稿，一般来说，可以做一些消息类稿件，比如刚才提到的美联社新闻稿，腾讯的新闻稿。对于大多数只是发布新闻消息的记者来说，这个职业很快就面临被淘汰的局面。这符合刚才提到的不仅仅是机械性的体力劳动，机械性的脑力劳动岗位也会被替代。大多数记者的写稿行为，本质是都是机械性的脑力劳动。基于机器学习的写稿行为，它会比人类更快，且随着给予的数据喂养更多，会比普通人类记者写得更加出色。

目前看只有**对于事件的深度解读和分析**，暂时还是人类的优势领域。

### 司机

人类历史上，曾经强壮的男人最受欢迎。在原始的部落，强壮男人狩猎、保护族人免受外族欺凌，在原始社会、部落社会、农业社会，甚至在工业社会都是最受欢迎的职场人士。但是今天，强健的体魄面临来自不知疲倦更加强壮的机器人的冲击。

**重复性体力劳动的重要性一直降低，而且被取代也是迟早的事情**。比如无人驾驶作为人工智能最大的应用。它对司机这个职业产生根本性的威胁。不仅是Uber和滴滴这样的出行应用公司，而且特斯拉、百度、谷歌也在大力发展无人驾驶汽车。无人驾驶汽车的应用几乎涉及到了所有人工智能的方面，比如**图像识别**、**语音识别**、**自然语言处理**等。对于Uber和滴滴来说，要想继续向上走，必须让无人驾驶成为优化整个交通出行的核心，最终让出行体验做到极致。

而对于特斯拉、百度和谷歌这样的企业来说，重要的不仅仅是无人驾驶的硬件或者无人驾驶的软件能力。核心的还是前面提到的理念，这些企业的无人驾驶汽车是建立在“机器学习”基础上的。比如特斯拉已经收集了超过20多亿公里的车辆行驶数据，包括了不同路况和天气下的行驶数据，这些数据每天都在大规模增加。这些大数据通过学习的机制为其他所有的汽车赋予能力，也就是说这是一个怪兽。由分布在全球不同的地区的汽车个体不停地上传不同的数据，而这些数据又回报给各个个体，最终进化成为一个更加高效有用的自动驾驶汽车。

百度和谷歌也有类似的思路，百度有一个**输出人工智能大脑**的战略，除了自行研发百度无人汽车之外，还跟不同的汽车厂商合作，输出汽车大脑的服务，对于百度和谷歌来说，这样的方式能够以更快的速度获得数据。对于这些企业来说，最快的速度获得数据永远是最高的战略。

虽然真正的无人驾驶可能还需要五年十年的时间，但是这个趋势已经不可逆转。未来的出租车司机、滴滴或许Uber的司机、大货车司机等都要面临职业消失的局面。美国有200万名大货车司机，即使有特朗普的保护，最终来说，生产力发展的趋势也不是不可逆。无人驾驶汽车比货车司机更安全、可靠、听话、不知疲倦且容易管理。

### 工厂工人

**机器人取代工厂工人是必然**，就像美国目前的农业人口占总人口的1%一样，未来工人也不会超过总人口的1%，曾经马克思书里描述的社会中坚力量工人阶级将随着技术的变迁而消失。甚至马克思主义的赖以存在的资本主义矛盾论理论基础也将消失，他所描述的资本主义经济的核心问题在于供需信息的不对称，传导太慢，导致了经济危机，而人工智能的数据匹配将彻底改变这一问题，这意味着是不是很多经济学家也要失业了？因为从高度不透明，==不确定的社会经济逐渐走向有计划可预期的社会经济==。这里唯一不确定的是人性。

三全之前有2万多名职工，用手工包汤圆和水饺，但现在以前几千吨的汤圆水饺都由机器人完成。日本软银的孙正义早已开始布局未来，软银公司一家有超过3000万机器人，24小时不眠不休地干活，一个机器人抵好几个普通工人，目前成本仅900元，而中国的劳动力工资至少也得3000元以上。人工智能的发展将会引发产业的转移，产业将不一定在人力成本低的发展中国家发展，而可能会回流到发达国家。

诸如此类的案例只会越来越多。可以问问自己，自己的职业是不是处在被人工智能取代的区域？

## 三、结语

容易被取代的职业是哪些只有“==硬技能==”的职业，**重复劳动、可预见、有明确流程和方法论的工作**，而“==软实力==”，比如**对事物之间的关联性有深入理解的，感性的，则处于相对安全的范围**。但，==未来不会有永久的安全区域==。

为了不那么容易被淘汰，应该怎么做？**既然是不可逆转的趋势，首先了解它，然后接纳它，最后努力成为它的一部分**。

怎么成为它的一部分？比如你是一位产品经理，有没有考虑过人工智能时代，作为产品经理的职业会不会不一样？是不是需要学会跟科学家沟通？比如你是传统的金融风控专家，如果机器学习应用到了金融科技，能够通过机器学习的方式更好地确定高风险人群的特征，那么，原来的经验是否还奏效？又比如是一位父母，如何进行教育？如何让自己的孩子在在未来二三十年的人工智能时代能够有机会参与？现有的教育理念可能都需要重新审视，要有个性化的教育，除了基础教育，更加重视发挥个人优势。==理性思维强的人，要加大对物理和数学基础的学习，而感性思维强的人，发挥自己的创意、娱乐的等天赋。未来或许不再有中间道路，To be or not to be!==（蓝狐笔记）

 

作者：蓝狐笔记，微信公众号：lanhubiji

---

# **人工智能究竟有多“人工”？**

[boxi](http://36kr.com/user/1694)

 · 16小时前

 · 行业新闻

Master让人不禁猜想人工智能究竟有多智能，但AI幕布背后的情况却让人猜想人工智能究竟有多人工？

不久前在60场对垒中横扫人类围棋顶尖选手的Master（AlphaGo二代）再次令世人震惊，没想到人工智能已经如此智能、如此强大了。不过《哈佛商业评论》最近的一篇[文章](https://hbr.org/2017/01/the-humans-working-behind-the-ai-curtain)却关注了人工智能的另一半：“人工”。

文章从去年夏天Facebook制造的一场公关风暴谈起。尽管Facebook最近在美国总统大选中的对“[假新闻](http://36kr.com/p/5057020.html)”的不作为引起了大众的非议，但是在去年夏天，大家的口风却是完全不同的。当时大家发现，除了“无偏见”的算法以外，其实Facebook还有一支“编辑队伍”来确定出现在趋势话题的内容。这提出了一个明显存在却被人刻意回避的问题：标榜速度快、全能、中立的AI其实还是离不开人，只是你看不见罢了。那么人工智能背后的人工成分究竟有多大呢？

为此，微软研究院的研究团队用了三个月的时间去观察印度班加罗尔的一位中年妇女Kala。Kala是两个小孩的母亲，平时她的工作就是坐在与丈夫共享的临时家庭办公室电脑前，在网上挑选一些临时性的“按需”合同工作，也就是相当于网上的计件工作，或者所谓的零工经济。而她的儿子就在旁边写作业。她工作的时候会把儿子叫到电脑屏幕前，指着上面的英文问道：“这个词是不是不好的词？”Kala每周都要花几个小时来审核有疑问的内容样例并打上标签。这就是2016年人工智能幕后的情形。有时候她要替Google、Facebook、Twitter以及微软等技术公司训练策划内容的算法。有时候则要在客户收到内容投诉时对用户生成的内容（UGC）做出判断，决定是否要撤掉有问题的内容。

这反映出一个大家经常忽视的事实：**人工智能目前还离不开人工**（尽管人工智能里面的人工并不是这个意义）。无论是Facebook的趋势话题，还是Amazon通过Alexa语音助手交付的Prime订单，或者是马上对客户投诉做出响应的聊天机器人，自动移除“恶意”内容的YouTube，其实，我们看到的那些自诩为AI驱动的产品/服务/应用都离不开人工。那些人坐在电脑屏幕前，付费应答那些通过众包系统API分配给自己的查询或者请求。事实上，人工智能的“全自动”程度就像《魔境仙踪》里面的那些伟大的巫师一样，不过是幕后有人工操纵罢了。他们是隐藏在人工智能包装下的真真正正的人工——一个由合同工组成的新世界。人和AI的混合正在重塑着零售、营销以及客户服务业。Amazon的土耳其机器人（Mechanical Turk）完美地诠释了这一点，或者这台高大上的自助签注机的注解更加形象：

AI与人的结合不会很快消失，因为在AI无法胜任的地方就要靠人来坚持到底。实际上，自从工业革命以来，人类社会就一直存在这种因为技术进步而创造出新的人类工作的现象。微软研究院资深研究员Mary L. Gray与Siddharth Suri把这种现象称为是“**自动化最后一公里悖论**”：随着AI取得进展，这也会导致新型的有人参与的任务出现，这些任务会使得为此准备的临时工劳动力市场快速创造和消失。经济学家预测，到2033年，技术创新将会把30%的全职工作转化成通过自动化和人工劳动力结合“按需”完成的增强服务。简而言之，就是AI一方面会消灭部分工作，同时也将打开新的就业机会，而那些机会将重新定义什么样的工作是人干得最好的。这些**通过机器人和背后的人共同提供的AI辅助型增强服务**，其目的是要增强我们的日常生产力，但也会引发新的社会挑战——事实已经表明，AI也像我们人一样，在哪些内容应该出现在我们的社交媒体上、哪些不应该出现在社交媒体等问题上会犯难，因为这取决于我们的标准和价值观。

Facebook引入人工编辑来确定趋势话题的实质并不在于是否存在偏见的可能性，而在于目前的AI在没有人参与的情况下还不能正常工作——无论是新闻编撰还是复杂的送外卖订单的交付都是这样的情况。新闻流策划以及搜索结果的内容调整等都需要技术公司或者媒体公司雇人来对什么内容需要置顶或者撤下做出判断。尤其是一些刚刚冒出来的新词热词，AI光靠自己的算法和数据都是没有办法做出判断的。

但是在这些AI幕后的都是什么人呢？其中很多都是像Kala这样的人，很多都是普通百姓，独立或者通过临时代理机构接单，往往只能获得比较低的报酬（所以很多都是印度这样的国家的人接单）。很多人并不知道大量的内容调整工作其实都是外包给全球各地的合同工的。但是大家对这些人的培训水平、工作环境或者做出编辑决策的规定要求却知之甚少。对于Facebook那次“编辑团队”事故类似的事情，大家似乎没有问到点子上：社交媒体内容调整的具体做法是怎样的？究竟是谁负责编撰那些我们在社交媒体上看到的内容？这支“编辑团队”的信用和能力水平究竟如何？

微软研究院通过对全球众包工作近2年的研究发现，内容调整工作已经成为零工经济的稳定来源，而且技术界无论规模大小都有很多公司把成千上万什么东西该保留什么东西该删除的决定外包了出去，很多都要严重依赖于 Crowdflower 、Amazon Mechanical Turk这样的众包平台或者Clickworker这样的供应商管理系统。而承担这项工作的“临时工”需要训练算法来对做出一些对内容影响最大的决策之一，而且有时候他们还需要人工介入来做出这样的判断。后面这一点是很多人没有意识到的，也是需要引起重视的，因为我们都不想互联网成为垃圾内容横行的沼泽地。

所以我们需要认真考虑人力在AI驱动的服务当中扮演的角色。这批人需要得到足够的培训、支持以及补偿，才能够有意愿承担或者胜任这些非常乏味吃力但又非常重要的工作。除了趋势话题的编撰调整以外的大量未来工作都需要人类的创造性工作来引导AI提高速度、效率以及适用范围。第一步应该是提高技术公司的透明度，他们需要说清楚所谓的不用人参与的AI是不是这么回事。如果不是，我们需要知道，引进人进来的好处是什么。这些人是不是能够胜任这些工作，尤其是在这些工作会影响到公众利益的时候。

当然，引入人的很大一部分原因在于算法的不完美。但就像德哈维兰彗星型客机事故分析中人们发现的一样，[结构没法做到完美，结构天生就有瑕疵](http://36kr.com/p/5057403.html)，而工程设计的目标不是保证机身没有裂隙，而是能够容忍裂隙。同样地，算法设计的精髓不是消除所有的错误，而是要让结果在面对错误时具有鲁棒性。在这个过程中，**我们不仅需要设计AI的人，也需要大量的人力来对AI进行训练**。这两方面的人都要求具备高素质。作为消费者，我们有权知道吐出新闻和媒体内容的AI的成分和制造过程是什么样的，就像我们对每天都要吃的食物的要求一样。作为公民，我们需要知道我的信息是从哪里来的。作为人类，我们应该始终清楚什么时候有人的干涉。这批AI幕后的人不应该被当作不存在，因为他们肩负着重大的责任。


















































