---
layout: post
title: 大数据
lead: 大数据学习
date: 2016-11-18T00:00:00.000Z
categories: 大数据
tagline: 大数据
tags:
  - 大数据
  - 人工智能
  - 机器学习
  - 深度学习
---

# 大数据

**大数据**：或称巨量资料，指的是数据规模巨大到**不能**通过目前的**i.i.d平稳随机分析方法**，在合理时间内达到撷取、管理与处理，并归纳成为数据应用与辅助决策的信息；**整体关联关系**而非因果关系；数据的统计分析或数据挖掘。

**什么是大数据**？我就说一个观点。我们说大数据通常体量巨大，一般不能用常规的统计学与平稳随机过程方法来处理，因为已经不满足i.i.d独立同分布假设了。而且通常只关注整体的关联关系，而不是因果关系。从这个角度来说，现在很多所谓的大数据分析都是炒概念，其实就是常规的统计分析或者说数据挖掘，不是真正含义上的大数据分析。

大数据是最近IT界最常用的术语之一。然而对大数据的定义也不尽相同，所有已知的论点例如结构化的和非结构化、大规模的数据等等都不够完整。大数据系统通常被认为具有数据的五个主要特征，通常称为数据的5 Vs。分别是大规模，多样性，高效性、准确性和价值性。

Tips：**所谓大数据，是指数据量庞大、产生数度快、结构多样的价值密度低的数据**。其中，数据量庞大是指数据规模超出了1,2台高性能主机所能处理范围;结构多样性是指除了关系型数据库能够处理的结构化数据还包含半结构化数据(如各类传感设备必如地镑、卫星、GPS设备等产生的纯文本格式的数据，还有良心网站NASA官网公布的txt格式的空间天气数据等成行成列的数据)和非结构化数据(视频、图像等)。这些数据的价值密度普遍较低(和具体的应用范围也有关系，比如NASA的数据，如果想知道某天的太阳射电情况，看当天发布的txt就好了，价值密度很高，但是这就不算大数据了，因为需要采集的数据量很小;如果想知道过去N年太阳射电的极值就需要处理很多数据，这些数据的价值密度就低了)，大数据处理的目的就是从价值密度的数据里把有价值的数据过滤分析出来。

## 大数据的5V基本特征

1. **Volume大规模**：==数据体量巨大，从TB级别上升到PB级别==；“在本(地)机数据采集和处理技术能力不足以为用户带来商业价值”。
2. **Varitety多样性**：==数据类型众多==；“高度变异的信息资产，在生产和消费时不进行严格定义的包括多种形式、类型和结构的组合。同时还包括以前的历史数据，由于技术的变革历史数据同样也成为多样性数据之一”。
3. **Velocity高效性**：==处理速度快，1秒定律，与传统数据挖掘技术本质不同==，；“高速的数据流I/O(生产和消费)，但主要聚焦在一个数据集内或多个数据集之间的数据生产的速率可变上”。
4. **Veracity准确性**：==真实、正确、准确、精确==。“要做出正确的商业决策，当务之急是在数据上进行的所有分析必须是正确和准确(精确)的”。
5. **Value价值性**：==价值密度低，但商业价值高==；“像电信，金融，电子商务，社交媒体等，已经认识到他们的数据是一个潜在的巨大的商机。他们可以预测用户行为，并推荐相关产品，提供危险交易预警服务，等等”。

**真正意义上的大数据分析是什么呢**？五个V特别重要，数据体量巨大，从TB级别上升到PB级别；数据类型众多；价值密度低，但商业价值高，也就是数据中大量都是垃圾，垃圾里面找金矿，很少很少，去找这个东西，这个是不能用传统方法处理的，因为大部分是非结构化和半结构化数据。事实上，结构化数据用传统数据挖掘手段就可以处理，现在很多人其实干的是这件事情。与其他IT系统一样，性能是大数据系统获得成功的关键。

## 大数据系统应包含的功能模块

大数据系统应该包含的功能模块，首先是能够从多种数据源获取数据的功能，数据的预处理(例如，清洗，验证等)，存储数据，数据处理、数据分析等(例如做预测分析，生成在线使用建议等等)，最后呈现和可视化的总结、汇总结果。

### 各种各样的数据源（Diverse Data Sources）

当今的IT生态系统，需要对各种不同种类来源的数据进行分析。这些来源可能是从在线Web应用程序，批量上传或feed，流媒体直播数据，来自工业、手持、家居传感的任何东西等等。

显然从不同数据源获取的数据具有不同的格式、使用不同的协议。例如，在线的Web应用程序可能会使用SOAP / XML格式通过HTTP发送数据，feed可能会来自于CSV文件，其他设备则可能使用MQTT通信协议。

由于这些单独的系统的性能是不在大数据系统的控制范围之内，并且通常这些系统都是外部应用程序，由第三方供应商或团队提供并维护，所以本文将不会在深入到这些系统的性能分析中去。

### 数据采集（Data Acquisition）

数据采集是各种来自不同数据源的数据进入大数据系统的第一步。这个步骤的性能将会直接决定在一个给定的时间段内大数据系统能够处理的数据量的能力。

这个过程包括**分析，验证，清洗，转换，去重**，然后存到适合你们公司的一个持久化设备中(硬盘、存储、云等)。

下面是一些性能方面的技巧：
- 来自不同数据源的传输应该是异步的。可以使用文件来传输、或者使用面向消息的(MoM)中间件来实现。由于数据异步传输，所以数据采集过程的吞吐量可以大大高于大数据系统的处理能力。**异步数据传输**同样可以在大数据系统和不同的数据源之间进行解耦。大数据基础架构设计使得其很容易进行动态伸缩，数据采集的峰值流量对于大数据系统来说算是安全的。
- 如果数据是直接从一些外部数据库中抽取的，确保拉取数据是使用**批量**的方式。
- 如果数据是从feed file解析，请务必**使用合适的解析器**。例如，如果从一个XML文件中读取也有不同的解析器像JDOM，SAX，DOM等。类似地，对于CSV，JSON和其它这样的格式，多个解析器和API是可供选择。选择能够符合需求的性能最好的。
- 优先使用**内置的验证解决方案**。大多数解析/验证工作流程的通常运行在服务器环境(ESB /应用服务器)中。大部分的场景基本上都有现成的标准校验工具。在大多数的情况下，这些标准的现成的工具一般来说要比你自己开发的工具性能要好很多。
- 类似地，如果数据XML格式的，优先使用XML(XSD)用于验证。
- 即使解析器或者校等流程使用自定义的脚本来完成，例如使用java优先还是应该使用内置的函数库或者开发框架。在大多数的情况下通常会比你开发任何自定义代码快得多。
- 尽量**提前滤掉无效数据**，以便后续的处理流程都不用在无效数据上浪费过多的计算能力。
- 大多数系统处理无效数据的做法通常是存放在一个专门的表中，请在系统建设之初考虑这部分的数据库存储和其他额外的存储开销。
- 如果来自数据源的数据需要清洗，例如去掉一些不需要的信息，尽量保持所有数据源的抽取程序**版本一致**，确保一次处理的是一个大批量的数据，而不是一条记录一条记录的来处理。一般来说数据清洗需要进行表关联。数据清洗中需要用到的静态数据关联一次，并且一次处理一个很大的批量就能够大幅提高数据处理效率。
- 数据去重非常重要这个过程决定了主键的是由哪些字段构成。通常主键都是时间戳或者id等可以追加的类型。一般情况下，每条记录都可能根据主键进行索引来更新，所以最好能够让**主键简单**一些，以保证在更新的时候检索的性能。
- 来自多个源接收的数据可以是不同的格式。有时，需要进行数据移植，使接收到的数据从多种格式转化成一种或一组**标准格式**。
- 和解析过程一样，我们建议使用内置的工具，相比于你自己从零开发的工具性能会提高很多。
- 数据移植的过程一般是数据处理过程中最复杂、最紧急、消耗资源最多的一步。因此，确保在这一过程中尽可能多的使用**并行计算**。
- 一旦所有的数据采集的上述活动完成后，转换后的数据通常存储在某些持久层，以便以后分析处理，综述，聚合等使用。
- 多种技术解决方案的存在是为了处理这种持久(RDBMS，NoSQL的分布式文件系统，如Hadoop和等)。
- 谨慎选择一个能够最大限度的满足需求的解决方案。

### 存储数据（Storage）

一旦所有的数据采集步骤完成后，数据将进入持久层。

在本节中将讨论一些**与数据数据存储性能相关的技巧包括物理存储优化和逻辑存储结构(数据模型)**。这些技巧适用于所有的数据处理过程，无论是一些解析函数生的或最终输出的数据还是预计算的汇总数据等。

- 首先选择**数据范式**。您对数据的建模方式对性能有直接的影响，例如像数据冗余，磁盘存储容量等方面。对于一些简单的文件导入数据库中的场景，你也许需要保持数据原始的格式，对于另外一些场景，如执行一些分析计算聚集等，你可能不需要将数据范式化。
- 大多数的大数据系统使用**NoSQL数据库**替代RDBMS处理数据。
- 不同的NoSQL数据库适用**不同的场景**，一部分在select时性能更好，有些是在插入或者更新性能更好。
- 数据库分为**行存储和列存储**。
- 具体的数据库选型依赖于你的**具体需求**(例如，你的应用程序的数据库读写比)。
- 同样每个数据库都会根据不同的配置从而控制这些数据库用于数据库**复制备份**或者严格保持数据一致性。
- 这些设置会直接影响数据库**性能**。在数据库技术选型前一定要注意。
- **压缩率、缓冲池、超时的大小，和缓存**的对于不同的NoSQL数据库来说配置都是不同的，同时对数据库性能的影响也是不一样的。
- **数据Sharding和分区**是这些数据库的另一个非常重要的功能。数据Sharding的方式能够对系统的性能产生巨大的影响，所以在数据Sharding和分区时请谨慎选择。
- 并非所有的NoSQL数据库都内置了支持**连接，排序，汇总，过滤器，索引**等。
- 如果有需要还是建议**使用内置的类似功能**，因为自己开发的还是不灵。
- NoSQLs内置了压缩、编解码器和数据移植工具。如果这些可以满足您的部分需求，那么优先选择使用这些内置的功能。这些工具可以执行各种各样的任务，如格式转换、压缩数据等，**使用内置的工具**不仅能够带来更好的性能还可以降低网络的使用率。
- 许多NoSQL数据库支持**多种类型的文件系统**。其中包括本地文件系统，分布式文件系统，甚至基于云的存储解决方案。
- 如果在交互式需求上有严格的要求，否则还是尽量尝试使用NoSQL**本地(内置)文件系统**(例如HBase 使用HDFS)。
- 这是因为，如果使用一些外部文件系统/格式，则需要对数据进行相应的**编解码/数据移植**。它将在整个读/写过程中增加原本不必要的冗余处理。
- 大数据系统的数据模型一般来说需要**根据需求用例来综合设计**。与此形成鲜明对比的是RDMBS数据建模技术基本都是设计成为一个通用的模型，用外键和表之间的关系用来描述数据实体与现实世界之间的交互。
- 在硬件一级，本地RAID模式也许不太适用。请考虑使用SAN存储。

### 数据处理和分析（Data Processing and Analysis）

第三步，在这一阶段中的一部分干净数据是去规范化的，包括对一些相关的数据集的数据进行一些排序，在规定的时间间隔内进行数据结果归集，执行机器学习算法，预测分析等。

数据处理和分析是一个大数据系统的核心。像**聚合，预测，聚集**，和其它这样的逻辑操作都需要在这一步完成。

本节讨论一些数据处理性能方面的技巧。需要注意的是大数据系统架构有两个组成部分，实时数据流处理和批量数据处理。本节涵盖数据处理的各个方面。

- 在细节评估和数据格式和模型后选择适当的**数据处理框架**。
- 其中一些框架适用于**批量数据处理**，而另外一些适用于**实时数据处理**。
- 同样一些框架使用**内存模式**，另外一些是基于**磁盘io处理模式**。
- 有些框架擅长**高度并行计算**，这样能够大大提高数据效率。
- 基于内存的框架性能明显优于基于磁盘io的框架，但是同时成本也可想而知。
- 概括地说，当务之急是选择一个**能够满足需求的框架**。否则就有可能既无法满足功能需求也无法满足非功能需求，当然也包括性能需求。
- 一些这些框架将数据划分成较小的块。这些小数据块由各个作业独立处理。协调器管理所有这些独立的子作业
- 在**数据分块**时需要当心。
- 该数据块越小，就会**产生越多的作业**，这样就会增加系统初始化作业和清理作业的负担。
- 如果数据块太大，**数据传输**可能需要很长时间才能完成。这也可能导致资源利用不均衡，长时间在一台服务器上运行一个大作业，而其他服务器就会等待。
- 不要忘了查看一个任务的作业总数。在必要时调整这个参数。
- 最好实时监控数据块的传输。在本机机型io的效率会更高，这么做也会带来一个副作用就是需要将数据块的冗余参数提高(一般hadoop默认是3份)这样又会反作用使得系统性能下降。
- 此外，**实时数据流需要与批量数据处理的结果进行合并**。设计系统时尽量减少对其他作业的影响。
- 大多数情况下**同一数据集需要经过多次计算**。这种情况可能是由于数据抓取等初始步骤就有报错，或者某些业务流程发生变化，值得一提的是旧数据也是如此。设计系统时需要注意这个地方的容错。
- 这意味着你可能需要存储原始数据的时间较长，因此需要更多的存储。
- 数据结果输出后应该保存成**用户期望看到的格式**。例如，如果最终的结果是用户要求按照每周的时间序列汇总输出，那么你就要将结果以周为单位进行汇总保存。
- 为了达到这个目标，大数据系统的数据库建模就要**在满足用例的前提下进行**。例如，大数据系统经常会输出一些结构化的数据表，这样在展示输出上就有很大的优势。
- 更常见的是，这可能会这将会让用户感觉到性能问题。例如用户只需要上周的数据汇总结果，如果在数据规模较大的时候按照每周来汇总数据，这样就会大大降低数据处理能力。
- 一些框架提供了**大数据查询懒评价**功能。在数据没有在其他地方被使用时效果不错。
- **实时监控系统的性能**，这样能够帮助你预估作业的完成时间。

### 数据的可视化和数据展示（Visualization and Presentation）

最后一个步骤，展示经过各个不同分析算法处理过的数据结果。该步骤包括从预先计算汇总的结果(或其他类似数据集)中的读取和用一种友好界面或者表格(图表等等)的形式展示出来。这样便于对于数据分析结果的理解。

精心设计的高性能大数据系统通过对数据的深入分析，能够**提供有价值战略指导**。这就是可视化的用武之地。良好的可视化帮助用户获取数据的多维度透视视图。

需要注意的是传统的BI和报告工具，或用于构建自定义报表系统无法大规模扩展满足大数据系统的可视化需求。同时，许多COTS可视化工具现已上市。

本文将不会对这些个别工具如何进行调节，而是聚焦在一些通用的技术，帮助您能**打造可视化层**。

- 确保可视化层显示的数据都是从最后的**汇总输出表**中取得的数据。这些总结表可以根据时间短进行汇总，建议使用分类或者用例进行汇总。这么做可以避免直接从可视化层读取整个原始数据。
- 这不仅最大限度地**减少数据传输**，而且当用户在线查看在报告时还有助于**避免性能卡顿**问题。
- 重分利用大化**可视化工具的缓存**。缓存可以对可视化层的整体性能产生非常不错的影响。
- **物化视图**是可以提高性能的另一个重要的技术。
- 大部分可视化工具允许通过**增加线程数来提高请求响应的速度**。如果资源足够、访问量较大那么这是提高系统性能的好办法。
- 尽量提前将数据进行**预处理**，如果一些数据必须在运行时计算请将运行时计算简化到最小。
- 可视化工具可以按照各种各样的展示方法对应**不同的读取策略**。其中一些是离线模式、提取模式或者在线连接模式。每种服务模式都是针对不同场景设计的。
- 同样，一些工具可以进行**增量数据同步**。这最大限度地减少了数据传输，并将整个可视化过程固化下来。
- 保持像图形，图表等使用最小的尺寸。
- 大多数可视化框架和工具的使用可缩放矢量图形(SVG)。*使用SVG复杂的布局可能会产生严重的性能影响*。

### 数据安全以及对于性能的影响

像任何IT系统一样安全性要求也对大数据系统的性能有很大的影响。在本节中，我们讨论一下安全对大数据平台性能的影响。

- 首先确保所有的**数据源都是经过认证的**。即使所有的数据源都是安全的，并且没有针对安全方面的需求，那么你可以灵活设计一个安全模块来配置实现。
- 数据进过一次认证，那么就**不要进行二次认证**。如果实在需要进行二次认证，那么使用一些类似于token的技术保存下来以便后续继续使用。这将节省数据一遍遍认证的开销。
- 您可能需要支持其他的认证方式，例如基于PKI解决方案或Kerberos。每一个都有不同的性能指标，在最终方案确定前需要将其考虑进去。
- 通常情况下**数据压缩**后进入大数据处理系统。这么做好处非常明显不细说。
- 针对不同算法的效率、对cpu的使用量你需要进行比较来选出一个传输量、cpu使用量等方面**均衡的压缩算法**。
- 同样，**评估加密逻辑和算法**，然后再选择。
- 明智的做法是**敏感信息始终进行限制**。
- 在审计跟踪表或登录时您可能需要维护记录或类似的访问，更新等不同的活动记录。这可能需要根据不同的监管策略和用户需求个性化的进行设计和修改。
- 注意，这种需求不仅增加了数据处理的复杂度，但会增加存储成本。
- **尽量使用下层提供的安全技术**，例如操作系统、数据库等。这些安全解决方案会比你自己设计开发性能要好很多。

# 大数据技能图谱

## 大数据处理框架

- Spark
> - RDD
> - Spark SQL
> - Spark Streaming
> - MLLib
- Hadoop
> - HDFS (分布式文件系统)
> - Mapreduce（计算框架）
> - Yarn（资源管理平台）
> - Pig（piglatin 语句到 mapreduce 的映射）
> - Hive（数据仓库，提供 SQL）
> - Mahout（机器学习算法的 mapreduce 实现库）
- Kafka
- Storm
- ELK
> - ElasticSearch
> - Logstash
> - Kibana

## 数据库

- SQL
- MySQL
- MongoDB
- Cassandra
- Redis
- SQLite
- bsddb
- HBase

## 编程语言

- Python
- R
- Ruby

## 数据分析挖掘

- MATLAB
- SPSS
- SAS

## 数据可视化

- R
- D3.js
- ECharts
- Excle

## 人工智能

- 聚类
- 时间序列
- 推荐系统
- 回归分析
- 文本挖掘
- 决策树
- 支持向量机
- 贝叶斯分类
- 神经网络

## 算法

一致性
- paxos
- raft
- gossip

数据结构
- 栈，队列，链表
- 散列表
- 二叉树，红黑树，B树
- 图

常用算法
- 排序（插入排序、桶排序、堆排序、快速排序）
- 最大子数组
- 最长公共子序列
- 最小生成树
- 最短路径
- 矩阵的存储和运算

## 云计算

- 云服务（SaaS、PaaS、IaaS）
- Openstack
- Docker

# 十大最热门的大数据技术

根据弗雷斯特研究公司发布的指数，这里给出最热的十个大数据技术：

- **预测分析**：随着现在硬件和软件解决方案的成熟，许多公司利用大数据技术来收集海量数据、训练模型、优化模型，并发布预测模型来提高业务水平或者避免风险；
- **NoSQL数据库**：非关系型数据库包括Key-value型（Redis）数据库、文档型（MonogoDB）数据库、图型（Neo4j）数据库；
- **搜索和知识发现**：支持信息的自动抽取，可以从多数据源洞察结构化数据和非结构化数据；
- **流式分析**：软件可以对多个高吞吐量的数据源进行实时的清洗、聚合和分析；
- **内存数据结构**：通过动态随机内存访问（DRAM）、Flash和SSD等分布式存储系统提供海量数据的低延时访问和处理；
- **分布式存储系统**：分布式存储是指存储节点大于一个、数据保存多副本以及高性能的计算网络；
- **数据可视化**：数据可视化技术是指对各类型数据源（包括Hadoop上的海量数据以及实时和接近实时的分布式数据）进行显示；
- **数据整合**：通过亚马逊弹性MR（EMR）、Hive、Pig、Spark、MapReduce、Couchbase、Hadoop和MongoDB等软件进行业务数据整合；
- **数据预处理**：数据整合是指对数据源进行清洗、裁剪，并共享多样化数据来加快数据分析；
- **数据校验**：对分布式存储系统和数据库上的海量、高频率数据集进行数据校验，去除非法数据，补全缺失。

# [中国工程院院士倪光南：把大数据当作生产力](http://www.36dsj.com/archives/69101)

大数据的四种能力，第一个是融合Fusion，就是数量和质量的提升。第二，云计算Cloud。第三，Insight，意思是我们可以说明察秋毫，有了大数据，世界万物的关系可以分析出来。第四，预见性。这四个能力是大数据给我们的，对政府科学治理体系的建设非常有价值。

大数据很多人说大数据是财富，这里我们说把它作为生产力，生产力肯定能够产生财富，但是生产力是不是比财富更合适?因为一些经济学家告诉我们，生产力是最基本的，生产力决定生产关系，至少有一些经济学家是这么说的，今天的理论是这么说的。所以我们把大数据作为生产力，可能比大数据作为一种财富更好、更全面一点。我们强调大数据生产力，会推动生产关系的发展，推动社会的发展，当然会创造无穷无尽的财富，供大家参考，我们喜欢说把大数据作为生产力，进入大数据时代意味着进入了一个新的生产驱动时代，所以将来对于我们整个思维的发展将会造成很大的变革。

大数据的四种能力，或者说大数据的四个价值。

**第一个是融合Fusion。当然包含了集成，集成意味着数据的物理上的聚集，量的聚集。**这里更加强调的质的变化，当而数据汇聚起来融合以后，它的价值会更加提升，远远比原始数据简单的算术相加要多。所以我们用了融合的意思，在中文上融合可能把它理解成汇聚加融合，就是数量和质量的提升，是大数据给我们提供的能力或者提供的价值。

**第二，云计算Cloud**。当大数据达到一定量的时候，你要迅速的利用它，在我们需要的时候随时能够利用，传统计算架构已经不适用了，这时候应用的是Cloud。而云计算提供这种能力，和大数据相适应，云计算是为大数据而生的，或者说大数据和云计算相辅相成，两者之间互相推动，互相促进，是一个非常典型的例子。

**第三，Insight，**意思是我们可以说明察秋毫，当你有了大数据，世界万物的关系你可以分析出来，很多人说我们不在意什么因果关系，我们在意的是关系。**谁和谁有关相性**，不管怎么样，我们有了大数据，可以发生过去没有想象到的，过去我们在商业上面啤酒和尿不湿之间发生关系了，现在我们大数据会结合新的规律，人类可以发现新的规律、新的原理或者新的科学的创造。毫无疑问，通过理论分析，通过计算机到大数据，这是万物之间关系的方式。

**第四，预见性**。Foresight大数据给我们一种预示性，可以更进一步。我们预测到将来什么时候会发生什么事情，非常有可能发生事件的预测，可以通过语境分析，可以预测时间上的推进。

这四个要求、四个价值、四个能力是大数据给我们的，以前是没有的，对我们非常有意义，对政府做科学治理体系的建设非常有价值。

政府利用大数据来做信息建设，这里是用某一个部委，可能有相当类似，从顶层到中央政府到地方一直到基层，一个部委的信息化的建设。作为一个中央的部委，它将会命令一个要求，达到一个目的，大致上有相当的普遍性。

底层我们要对待的是什么呢?三大块。

第一块毫无疑问，**大量的数据**，你将要面临的一个部委的数据，我们知道从地方来讲，有200多个地级市，2800个县镇乡，我们相信中国部委的信息化大数据系统难度要比目前世界上任何国家的信息系统或者电子政务系统更难。

第二，我们是一个**异构**，因为与历史的关系，**我们不可能在现在作为一个新的系统，我们是要集成历史上的信息系统。这些数据，这些信息系统可能是不同时期做的，**不同公司的，所以你发现异构是相当清楚的，是完全不同的异构系统，你要把它融合起来，是一个很大的挑战。

第三，是**部门上的保护**，各个部门之间很难融合。毫无疑问，东南西北不同的地区差别都很大，而且地理位置的差异，这是我们面临的挑战。

我们要做电子政务大数据，我们未来要达到什么目的呢?根据三个需求，我们要把它汇聚起来、集成起来、融合起来，把这些信息和大数据资源融合起来。

审计、监管，政府部门要做这些事情，我们大数据是用来支撑当前工作，使它更有效地完成得更好;这以前做不到，现在可以做到，如果大数据我们可以有科学决策。一个政策将会产生什么效果?我们对这个政策进行预测，可以看到这是可行还是不可行，包括怎么改进。这是对于政府的科学决策，给予科学的工具来支持。所以我想这几个地方比较重要，我们分别来讲这三块。

**第一块融合是很难的地方，**当你要建造一个信息系统，你不能把政府工作停下来，因为信息化你能说我把这个部门关掉，等我两年以后做好了再开吗?不可能。每天还要继续工作，不可停顿。**第一业务是不可以停顿的，信息系统必须在保证正常工作情况下进行**，所以采用什么对策呢?

其实我们要把数据的获取的手段用一种很巧妙的方式，在它运作的时候，我能抓取它，不是停下来我把它拷贝下，把政府的数据库清理出来把数据拿过来不行。政府照常工作，在政府运营的工作中谁去抓取数据？这套办法就是这个例子，具体操作上大家知道怎么做数据库，**不断地提取，不影响你正常工作，这是第一个挑战。**

第二块，所有的政府部门是遍布全国的，实际上采用的是几家中国的运营商。我们要谈合作一起做，并行的做，这个可以想像代价多一点。还有一点难的是不同的数据类型，因为历史上数据都不是一次建的，不同厂家，不同规格。比如说面临的数据，我们知道你可能是不同的结构，你的数据库不同厂商，你的资源定义是不一样的，你的数据模型是不一样的。所以当你要用一个数据的时候，你会发这个数据库要用，用一个方法收集组合，但另外一个又是完全不同的。这里提出了智能的数据切片，实际上用一种相当于影射，没有一个地方我投影投到另一个地方，不同的数据库投到另外的投影，最终效果一样，最终是新的办法解决。最后我们的数据并不是很好的，有的数据很多垃圾，不是很合理的，**你需要用一些很灵活的模型，各种演化的方法不断的改进。**

我们看到最后的效果，用这样的方式**我们支撑了1700个服务器，遍于全国的1700个服务器支撑这个系统。在200个城市里能够有3个PB的数据**，但是我觉得大概一年无非增加十几个PB，不断增加，而且大概覆盖到98%，还是相当大的覆盖。应该说是一个足够大的规模，这是目前的效果。

刚才讲未来满足监管审计的要求，相对来说比简单一点，我们知道原来上报数据，就是给领导上报，比如一星期我们知道每个部门不一样，一周也有，半个月也有，一个月也有。现在来讲就可以自动实时上报，不需要报表，实时的可以从系统里抓取你的数据。过去政策性很难保证，现在没有问题。以前你很难知道它变化，现在是实时数据，这点没有问题，现在可以有权限地分配，更加合理的应用，这个大家可以想象，有这样的数据信息系统以后对于信息监管毫无疑问有很大的影响。

可以达到的实时效果是10秒，可以在10秒钟把任何的数据提取出来，这对于管理来讲有很大的效果。此外我们知道所有的历史变化你也可以得到，而且我们知道权限可以明确地分配，谁可以获取哪些数据，不同的权限可以看到不同的结果，包括系统管理看不到重要的数据，这个需要有很好的权限分配。

最后是我们对预测的效果。过去这种信息系统是大数据系统所做不到的，我们希望未来要实现。过去因为信息孤岛的问题，现在**我们已经通过融合的手段可以把数据统一起来，使整个的权限数据可以互联互通**。

我们过去来讲历史数据不一定有，**今后的历史数据应该永远发展下去，永远保留下去；**过去有些东西会删掉，现在这些会不断地积累下来；过去的数据会滞后，现在可以动态的实时分享，业务也可以联系起来，综合业务决策不是单路的决策。谢谢大家。

---

# 大数据价值体现在AI、BI、CI、DI

无人机送货、阿法狗下棋、小冰和你谈场恋爱……人工智能领域的成果，一直是企业在大数据运用能力上的主要外在体现，但在亚马逊原首席科学家安德雷斯?韦思岸(Andreas Weigend)看来，大数据能为企业做的，还远不止如此。

以韦思岸之见，大数据对于企业的价值，更全面地来说可以体现在AI、BI、CI和DI，即**人工智能(Artificial Intelligence)**、**商业智能(Business Intelligence)**、**客户智能(Customer Intelligence)**和**数据智能(Digital Intelligence)**这四个方面。

在《大数据和我们》(Data for the People)一书中文版发布之际，作者韦思岸接受了记者的采访。

## AI：人工智能(Artificial Intelligence)

当前，极力开发人工智能的适用领域，成为了企业界的热门话题，甚至连企业CEO等职位可否被替代，都频频被纳入讨论之中。韦思岸对此的观点则是：“**机器应该只负责完成比人类更擅长的任务**”。

人工智能的概念其实早已被提出，而上世纪70年代、90年代的两次“人工智能寒冬”之所以会出现，是因为彼时大数据发展尚不成熟，人工智能难以完成规模化的深度学习。等到近年来大数据行业取得突破性进展，人工智能领域才不断迎来突破。

所以，==人工智能的主要优势，在于记忆与运算大数据，并从大数据中发掘深层次信息==。

《大数据和我们》中有一部分内容就阐述了博世公司的典型案例。

通过车载摄像头，博世的自动泊车系统可以记录并测量停车位的位置分布、空间大小、距离远近等大数据，并把它们上传至卫星定位系统，通过把海量大数据带入建模得出完成停车的行驶线路。而博世最近公布的、预计于2018年面市的Home Zone Park Assist服务，更是可以为汽车预存最多10条泊车路线，让人工智能在大数据的助力下为用户实现自动泊车。

也正因如此，能获取可观数据量的公司，往往更可能在这一领域取得成果。韦思岸认为，包括阿里巴巴、腾讯等在内的一些中国公司的优势，正在于此。

尤其是在近几年，每年有超过6.5亿人登录阿里巴巴旗下网站购物，而微信的用户也突破了8亿，这使得阿里巴巴、腾讯跻身全球拥有最多大数据的几家公司之列，他们也完成了在相应领域的突破。例如，阿里巴巴就在2016年8月的云栖大会上，推出了其首款人工智能机器人ET，而腾讯也于2016年12月26日宣布，将向全球企业提供包括图片标签、名片OCR识别等在内的7项AI云服务。

## BI：商业智能(Business Intelligence)

与计算机的优势在于记忆、运算相对应，==人的优势则在于创新能力与决策能力==。

所以，“**数据驱动**”这个近年来开始流行的管理理念，在韦思岸看来是有失偏颇的，而“==驱动数据==”，才应该是让大数据应用到企业决策、管理等领域的理性路径。两者的区别是，**前者是以大数据统御人类的决策与判断，而后者是让大数据处于人的掌控之中**。事实上，大数据本身是非常粗略的，数据样本有可能非结构化，甚至可能掺杂了欺诈数据。

把大数据置于其擅长范围以内，**用大数据来构建辅助企业决策的预知系统(anticipatory system)**，才是其助力企业提升商业智能的更合理选择。韦思岸也以具备“**大数据DNA**”这一比喻来形容这类企业。

韦思岸加入亚马逊也与此有关。韦思岸说，亚马逊创始人杰夫?贝佐斯(Jeff Bezos)早年就意识到大数据对于企业的重要性，因此邀请自己来一起为亚马逊制定大数据战略，让公司真正拥有大数据DNA。此后，亚马逊的商品推荐系统、第三方在线销售平台等创新性服务，不仅改善了顾客的购物体验，还让亚马逊自身能更科学地制定经营与市场战略。比如通过对大数据统计的总结，亚马逊就调整了自身的市场划分，把以往几十个细分市场的分类，演变为“**将单个顾客一分为十**”的全新分类。

更重要的是，具备大数据DNA的企业并不会惟大数据是从，而是**在决策时把它置于辅助性地位**。亚马逊计算机中心时区设置的不统一，曾让一些商品从浏览到购买的时间为负值，这也让亚马逊开展了自我纠正，重新基于其全球化经营战略设置了计算机时区等内部系统架构。

以韦思岸之见，亚马逊与其说是一家电商公司，不如说是一家科技公司。这也正是这家1995年才成立的公司能保持迅猛发展势头，并在2016年《财富》全球500强榜单中排名第44位的重要原因。

当然，《大数据和我们》一书也向我们展示，大数据DNA并不一定是科技公司的专利。在书中，全球规模最大基金公司桥水基金就于近期宣布，公司未来的员工招聘、绩效评定、日常管理等领域，将引入大数据辅助决策，桥水基金创始人雷伊?达里奥(Ray Dalio)也表示，相信这样能“有助于提高认识、改进决策过程并实现更好的成果”。

“==我们应当让人去做人擅长的事，让计算机去做计算机擅长的事==”，正如韦思岸所言，**人与计算机的深度协同，才是企业具备大数据DNA、能以商业智能取得领先的象征**。

## CI：客户智能(Customer Intelligence)

既然大数据是为人们决策提供辅助信息，那么，哪些信息相对不重要，哪些信息则相对更重要?“**我喜欢听到用户们通过大数据来发声**”，韦思岸把来源于经营第一线的用户数据，看作是更重要的大数据。

《大数据和我们》记录了韦思岸于20世纪90年代初在施乐公司的帕克研究中心工作时的情形。虽然当时已经诞生了超级计算机，但囿于数据量的缺乏，这位斯坦福大学博士仍只能通过大量假设来进行研究。

而现在，通过来源于客户的大数据，企业就能倾听到客户真实的心声，并以源自于客户方面的客户智能作为自身在行业内保持领先的基础。在韦思岸看来，其曾经提供过咨询服务的多家企业，如阿里巴巴、汉莎航空、摩根大通、GE等，都已非常注重客户数据对企业发展的意义。比如据韦思岸回忆，在与自己共同出席一次会议时，马云就曾表示“**call me Data Ma**”。

能真切听到客户通过大数据发出的心声，这只是第一步。客户数据能否转化为客户智能，关键还在于，企业经营决策的制定能否真正以客户需求为中心。

事实上，这也是体现企业领导者能否真正在企业内贯彻大数据DNA的一个分水岭。

例如，在当今的移动互联网时代，用户的一大诉求是希望企业能注重保护自己的数据隐私。但各类大规模用户资料泄露事件就表明，这一客户心声并非业内许多公司的真正关注点。苹果公司则是极少数的特例之一。2016年2月，蒂姆?库克(Tim Cook)能拒绝FBI关于在苹果设备预留后门的要求，让苹果注重客户隐私保护的声誉进一步提升，而一部分用户是非常愿意为此支付相应价值的。

此外，如果企业目前暂无能力获取海量客户数据，那么，通过数据服务商或中间商来查阅大数据，也是企业提升自身客户智能的合理选择。

比如，包括宝马、福特、MapQuest等在内的企业已经与微软旗下的Inrix开展了合作，后者是日均可分析超过1亿部智能手机地理位置数据的公司。再比如，餐饮、院线等行业内的企业可以通过Yelp、大众点评等网站获悉各类客户数据，以改善企业的服务与产品线。

## DI：数据智能(Digital Intelligence)

如果一家企业能够**在行业变革趋势洞察，企业内部决策制定，以及企业外部客户分析上充分运用大数据**，那么，这就是企业在数据智能方面的体现。对此，韦思岸用了“ABC客户行为模式”(ABC of Consumers’ Behavior)来予以概括。

- **A代表认可(Approval)**，表明企业在获取和运用大数据助力企业发展时，需尽量获得用户的肯定。

  亚马逊在建立用户点击与购买量的数据库时，并不保存每位客户的身份信息，而是只关注客户从一件产品到另一件产品的跳转轨迹。韦思岸认为这是亚马逊能获得不少客户认可的重要因素。

- **B代表归属感(Belongingness)**，这说明，具备数据智能竞争力的企业，都善于提升其用户黏性。《大数据和我们》中就列举了南非保险商探索健康公司的例子。探索健康公司与超市、商店共同推出的“活力”促销计划，为客户提供金钱奖励。若客户的支付记录显示他们购买了健康食物，他们就能凭此获得返现或保费折扣。

- **C则代表多重含义，比如对话(conversation)，比如交流(Communication)，又比如社区(Community)**。

  韦思岸也对界面新闻记者表示，他在与好友、2002年诺贝尔经济学奖得主丹尼尔?卡内曼(Daniel Kahneman)探讨后，两人都认为C最重要的含义是==连接(Connection)==。在行将来临的由人工智能、云计算、物联网主导的时代，平台化、生态化必然将成为企业的转型方向。由此，企业与平台合作各方的连接，企业与产业链各端的连接，都将深刻且持续地改变企业的发展轨迹。显然，这一任务的最好承担者正是大数据。

  能够像Facebook、Uber一样以大数据连接企业内外各方的企业，才是数据智能的真正代表。“那些敞开大门，让数据和信息畅通无阻连接的企业，将赢得更长远的未来”，韦思岸说。

韦思岸曾在联合国的一次演讲中，把大数据比喻为新时代的石油，他认为其是21世纪最重要的原材料。韦思岸对界面新闻记者说，在未来，企业运用大数据优化战略制定与日常管理，会是一件如同企业要用电一样常态化、普遍化的事情。

大数据能为企业带来的AI、BI、CI和DI之增长动能，将是身处万物互联化、万物智能化时代的企业所必须具备的DNA。

End.

转载请注明来自36大数据（36dsj.com)：[36大数据](http://www.36dsj.com/) » [亚马逊前首席科学家:大数据价值体现在AI、BI、CI、DI](http://www.36dsj.com/archives/74092)





























