---
layout: post
title: 人工智能、机器学习和深度学习的区别
lead: 一篇文章讲清楚人工智能、机器学习和深度学习的区别
date: 2016-10-14T00:00:00.000Z
categories: 人工智能
tagline: 机器学习
tags:
  - 机器学习
  - 神经网络
  - 深度学习
  - 人工智能
---

# [一篇文章讲清楚人工智能、机器学习和深度学习的区别](http://mp.weixin.qq.com/s?__biz=MzAxMzc2NDAxOQ==&mid=2650359244&idx=1&sn=49b92a64c94c59bc7bb5e0a59475c184&scene=21#wechat_redirect)

**机器学习，实现人工智能的方法；深度学习，实现机器学习的技术**。

有人说，人工智能（AI）是未来，人工智能是科幻，人工智能也是我们日常生活中的一部分。这些评价可以说都是正确的，就看你指的是哪一种人工智能。

2016年早些时候，Google DeepMind的AlphaGo打败了韩国的围棋大师李世乭九段。在媒体描述DeepMind胜利的时候，将**人工智能**（AI）、**机器学习**（machine learning）和**深度学习**（deep learning）都用上了。这三者在AlphaGo击败李世乭的过程中都起了作用，但它们说的并不是一回事。

今天我们就用最简单的方法----同心圆，可视化地展现出它们三者的关系和应用。

> 译者：曲晓峰，香港理工大学人体生物特征识别研究中心博士生

> 个人科研主页： <http://www.quxiaofeng.me/research>

如下图，人工智能是最早出现的，也是最大、最外侧的同心圆；其次是机器学习，稍晚一点；最内侧，是深度学习，当今人工智能大爆炸的核心驱动。

![一篇文章讲清楚人工智能、机器学习和深度学习的区别](https://pic.36krcnd.com/avatar/201609/07070312/tzxgj7lv86ydistp.png!heading)

五十年代，人工智能曾一度被极为看好。之后，人工智能的一些较小的子集发展了起来。先是机器学习，然后是深度学习。深度学习又是机器学习的子集。深度学习造成了前所未有的巨大的影响。

## 从概念的提出到走向繁荣

1956年，几个计算机科学家相聚在达特茅斯会议（Dartmouth Conferences），提出了"人工智能"的概念。其后，人工智能就一直萦绕于人们的脑海之中，并在科研实验室中慢慢孵化。之后的几十年，人工智能一直在两极反转，或被称作人类文明耀眼未来的预言；或者被当成技术疯子的狂想扔到垃圾堆里。坦白说，直到2012年之前，这两种声音还在同时存在。

过去几年，尤其是2015年以来，人工智能开始大爆发。很大一部分是由于GPU的广泛应用，使得并行计算变得更快、更便宜、更有效。当然，无限拓展的存储能力和骤然爆发的数据洪流（大数据）的组合拳，也使得图像数据、文本数据、交易数据、映射数据全面海量爆发。

让我们慢慢梳理一下计算机科学家们是如何将人工智能从最早的一点点苗头，发展到能够支撑那些每天被数亿用户使用的应用的。

## 人工智能（Artificial Intelligence）----为机器赋予人的智能

![img](http://mmbiz.qpic.cn/mmbiz_jpg/ibaXaPIy7jV2zW4pQ1SwPbqATO1pP4Pkrobkp2YR4wROmnrvrickXrepkibPBI3u1D4DgvDo8rnEPc93cAm8xicNpw/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1) **成王**（King me）:能下国际跳棋的程序是早期人工智能的一个典型应用，在二十世纪五十年代曾掀起一阵风潮。（译者注：国际跳棋棋子到达底线位置后，可以成王，成王棋子可以向后移动）。

早在1956年夏天那次会议，人工智能的先驱们就梦想着用当时刚刚出现的计算机来构造复杂的、拥有与人类智慧同样本质特性的机器。这就是我们现在所说的**"强人工智能"**（General AI）。这个无所不能的机器，它有着我们所有的感知（甚至比人更多），我们所有的理性，可以像我们一样思考。

人们在电影里也总是看到这样的机器：友好的，像星球大战中的C-3PO；邪恶的，如终结者。强人工智能现在还只存在于电影和科幻小说中，原因不难理解，我们还没法实现它们，至少目前还不行。

我们目前能实现的，一般被称为**"弱人工智能"**（Narrow AI）。弱人工智能是能够与人一样，甚至比人更好地执行特定任务的技术。例如，Pinterest上的图像分类；或者Facebook的人脸识别。

这些是弱人工智能在实践中的例子。这些技术实现的是人类智能的一些具体的局部。但它们是如何实现的？这种智能是从何而来？这就带我们来到同心圆的里面一层，机器学习。

## 机器学习---- 一种实现人工智能的方法

![img](http://mmbiz.qpic.cn/mmbiz_jpg/ibaXaPIy7jV2zW4pQ1SwPbqATO1pP4PkrOoPz2DFgHiawWUm9wshwiaCPOvEib8G3fGCb4aua9B29YYKwKggKF9iapg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)

**健康食谱**（Spam free diet）：机器学习能够帮你过滤电子信箱里的（大部分）垃圾邮件。（译者注：英文中垃圾邮件的单词spam来源于二战中美国曾大量援助英国的午餐肉品牌SPAM。直到六十年代，英国的农业一直没有从二战的损失中恢复，因而从美国大量进口了这种廉价的罐头肉制品。据传闻不甚好吃且充斥市场。）

机器学习最基本的做法，是使用算法来解析数据、从中学习，然后对真实世界中的事件做出决策和预测。与传统的为解决特定任务、硬编码的软件程序不同，机器学习是用大量的数据来"训练"，通过各种算法从数据中学习如何完成任务。

机器学习直接来源于早期的人工智能领域。传统算法包括决策树学习、推导逻辑规划、聚类、强化学习和贝叶斯网络等等。众所周知，我们还没有实现强人工智能。早期机器学习方法甚至都无法实现弱人工智能。

机器学习最成功的应用领域是计算机视觉，虽然也还是需要大量的手工编码来完成工作。人们需要手工编写分类器、边缘检测滤波器，以便让程序能识别物体从哪里开始，到哪里结束；写形状检测程序来判断检测对象是不是有八条边；写分类器来识别字母"ST-O-P"。使用以上这些手工编写的分类器，人们总算可以开发算法来感知图像，判断图像是不是一个停止标志牌。

这个结果还算不错，但并不是那种能让人为之一振的成功。特别是遇到云雾天，标志牌变得不是那么清晰可见，又或者被树遮挡一部分，算法就难以成功了。这就是为什么前一段时间，计算机视觉的性能一直无法接近到人的能力。它太僵化，太容易受环境条件的干扰。

随着时间的推进，学习算法的发展改变了一切。

## 深度学习----一种实现机器学习的技术

![img](http://mmbiz.qpic.cn/mmbiz_jpg/ibaXaPIy7jV2zW4pQ1SwPbqATO1pP4Pkr3FY7pCxQSicrgyrNOeoiaDibJeCJp8xz9N0cktXEurC6b9SvTrUxTKCog/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1) **放猫**（Herding Cats）:从YouTube视频里面寻找猫的图片是深度学习杰出性能的首次展现。（译者注：herdingcats是英语习语，照顾一群喜欢自由，不喜欢驯服的猫，用来形容局面混乱，任务难以完成。）

**人工神经网络**（Artificial Neural Networks）是早期机器学习中的一个重要的算法，历经数十年风风雨雨。神经网络的原理是受我们大脑的生理结构----互相交叉相连的神经元启发。但与大脑中一个神经元可以连接一定距离内的任意神经元不同，人工神经网络具有离散的层、连接和数据传播的方向。

例如，我们可以把一幅图像切分成图像块，输入到神经网络的第一层。在第一层的每一个神经元都把数据传递到第二层。第二层的神经元也是完成类似的工作，把数据传递到第三层，以此类推，直到最后一层，然后生成结果。

每一个神经元都为它的输入分配权重，这个权重的正确与否与其执行的任务直接相关。最终的输出由这些权重加总来决定。

我们仍以停止（Stop）标志牌为例。将一个停止标志牌图像的所有元素都打碎，然后用神经元进行"检查"：八边形的外形、救火车般的红颜色、鲜明突出的字母、交通标志的典型尺寸和静止不动运动特性等等。神经网络的任务就是给出结论，它到底是不是一个停止标志牌。神经网络会根据所有权重，给出一个经过深思熟虑的猜测----"概率向量"。

这个例子里，系统可能会给出这样的结果：86%可能是一个停止标志牌；7%的可能是一个限速标志牌；5%的可能是一个风筝挂在树上等等。然后网络结构告知神经网络，它的结论是否正确。

即使是这个例子，也算是比较超前了。直到前不久，神经网络也还是为人工智能圈所淡忘。其实在人工智能出现的早期，神经网络就已经存在了，但神经网络对于"智能"的贡献微乎其微。主要问题是，即使是最基本的神经网络，也需要大量的运算。神经网络算法的运算需求难以得到满足。

不过，还是有一些虔诚的研究团队，以多伦多大学的Geoffrey Hinton为代表，坚持研究，实现了以超算为目标的并行算法的运行与概念证明。但也直到GPU得到广泛应用，这些努力才见到成效。

我们回过头来看这个停止标志识别的例子。神经网络是调制、训练出来的，时不时还是很容易出错的。它最需要的，就是训练。需要成百上千甚至几百万张图像来训练，直到神经元的输入的权值都被调制得十分精确，无论是否有雾，晴天还是雨天，每次都能得到正确的结果。

只有这个时候，我们才可以说神经网络成功地自学习到一个停止标志的样子；或者在Facebook的应用里，神经网络自学习了你妈妈的脸；又或者是2012年吴恩达（Andrew Ng）教授在Google实现了神经网络学习到猫的样子等等。

吴教授的突破在于，把这些神经网络从基础上显著地增大了。层数非常多，神经元也非常多，然后给系统输入海量的数据，来训练网络。在吴教授这里，数据是一千万YouTube视频中的图像。吴教授为**深度学习**（deep learning）加入了"深度"（deep）。这里的"深度"就是说神经网络中众多的层。

现在，经过深度学习训练的图像识别，在一些场景中甚至可以比人做得更好：从识别猫，到辨别血液中癌症的早期成分，到识别核磁共振成像中的肿瘤。Google的AlphaGo先是学会了如何下围棋，然后与它自己下棋训练。它训练自己神经网络的方法，就是不断地与自己下棋，反复地下，永不停歇。

## 深度学习，给人工智能以璀璨的未来

深度学习使得机器学习能够实现众多的应用，并拓展了人工智能的领域范围。深度学习摧枯拉朽般地实现了各种任务，使得似乎所有的机器辅助功能都变为可能。无人驾驶汽车，预防性医疗保健，甚至是更好的电影推荐，都近在眼前，或者即将实现。

人工智能就在现在，就在明天。有了深度学习，人工智能甚至可以达到我们畅想的科幻小说一般。你的C-3PO我拿走了，你有你的终结者就好了。

# [一篇文章讲清楚深度学习中「训练」和「推断」的区别](http://mp.weixin.qq.com/s?__biz=MzAxMzc2NDAxOQ==&mid=2650359468&idx=1&sn=3d897a7608e8d97fa03ed6ea85101179&scene=1&srcid=0912KhJ5P6tvY9UhorAa2P85#rd)

不久前，我们深入浅出地用[一篇文章讲清楚人工智能、机器学习和深度学习的区别](http://mp.weixin.qq.com/s?__biz=MzAxMzc2NDAxOQ==&mid=2650359244&idx=1&sn=49b92a64c94c59bc7bb5e0a59475c184&scene=21#wechat_redirect)，通过最简单的方法----同心圆，可视化地展现出它们三者的关系和应用。

今天，将门将为大家带来解释深度学习基本概念的第二篇----训练和推断的区别。文中，作者将二者比作了学校学习的不同阶段，梳理了从训练到推断的整个过程，包括二者在人工智能中所起到的作用。

"开学了"----正是形容正在"训练"阶段的深度神经网络最贴切的状态。神经网络和所有的学生一样，通过接受教育，来学习如何完成工作。

确切的说，训练**好的神经网络**，可以根据其所学，在数字化的世界中轻松地完成各种各样的工作，如：识别图像、识别记录口述的语言、检测血液中的疾病，或者推荐符合某人风格的一双鞋子等等。此时的神经网络，由于经过了完善的训练，可以快速高效地从新的数据中"推断"各种结论。在人工智能术语中，称之为**"推断"（Inference）**。

![img](http://mmbiz.qpic.cn/mmbiz_jpg/ibaXaPIy7jV3iapCMqJjzHPnBu9g01TaFvbBecbvuicwA5icNpx7Zfmr4QqcSgevO4pmfK5cIgrFzRzUX46Necm5Mg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)

> 推断（Inference），就是深度学习把从训练中学习到的能力应用到工作中去。

不难想象，没有训练就没法实现推断。我们人也是这样，通过学习来获取知识、提高能力。同样，我们显然并不需要非得拖着我们所有的老师，带着一堆塞满书的书架和一座红砖的校舍，才能读懂红楼梦（或者莎士比亚十四行诗）。深度神经网络推断的时候也是一样，完成推断任务，并不需要其训练时那样的海量资源。

下面，就让我们梳理下从训练到推断的整个过程，包括二者在人工智能中所起到的作用，详细讲清楚。

## 训练深度神经网络

我们可以把深度学习的训练想象成学校。这个学校训练网络以便让其能够在广阔的世界里面解决现实问题。

​ ![img](http://mmbiz.qpic.cn/mmbiz_jpg/ibaXaPIy7jV3iapCMqJjzHPnBu9g01TaFvsS4Kias3J8BGU4eQUzic1EEKKj52NJYialJx0lSu6uibZgXjuwOtJiaWrvQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)

同样，显然地，我们并不需要非得拖着我们所有的老师，带着一堆塞满书的书架和一座红砖的校舍，才能读懂红楼梦（或者莎士比亚十四行诗）。深度神经网络推断的时候也是一样，完成推断任务，并不需要其训练时那样的海量资源。

尽管目的都是获取知识，但一个神经网络的"教育"（训练）跟人还是不一样的。神经网络大体上以人类大脑的神经结构为基础，即一组互相连接的神经元。但与人脑并不完全相同。人脑神经元与周围一小圈范围内的所有神经元都是互相连接的，而人工神经网络是分层的、是在层与层之间互相连接的、网络中数据的传播是有向的。

训练神经网络的时候，训练数据被输入到网络的第一层。然后所有的神经元，都会根据任务执行的情况，根据其正确或者错误的程度如何，分配一个**权重**参数（权值）。

在图像识别网络中，第一层可能会寻找图像中的边缘。第二层可能会寻找这些边缘所组成的图形，如长方形或者圆形。第三层可能会寻找特定特征，如闪亮的眼睛或者远远鼻子。每一层都把图像传递到下一层，直到最后一层。而最终的输出由网络中所有的权值共同决定。

这里，神经网络的训练与人类的教育就不一样了。以识别图像中的猫为例，神经网络读入所有训练图像，根据权值，得出是否是猫的一个论断。网络训练所额外需要的，仅仅是这个论断是"正确"还是"错误"这样的反馈。

## 训练是运算密集的

如果算法告诉神经网络其论断错误，网络并不需要知道正确的答案是什么。但这个错误会回传到网络各层，让网络再猜一下，给出一个不同的论断。

每次给出论断时，网络都要考虑所有特性，在这个例子里面就是"猫"的所有特性，然后根据其检测到的特性调整网络中的权值，调高或者降低。然后再次给出论断，一次又一次，一次再一次，直到网络中的权值都调整到位，几乎每次都能够输出正确论断。那就是猫了。

![img](http://mmbiz.qpic.cn/mmbiz_jpg/ibaXaPIy7jV3iapCMqJjzHPnBu9g01TaFv6icicAgDibiaBI0ggM4sUClL0JOA5qqdEbaz8mEvhLf8GicqiaRAcDL4wbTg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)

> 训练会先教深度学习网络在一个有限的图像集里标出猫的图像，稍后，该网络就会在广阔的世界中检测猫。

现在，我们得到了数据结构和根据训练数据学习到的达到平衡的一整套的权值。这可是精心调配的精美机器。可问题是，这也是需要一直吞噬运算能力的巨兽。曾在 Google 和斯坦福磨砺人工智能、现在百度硅谷实验室的吴恩达教授说，百度训练一个中文语言识别模型不仅需要 **4TB** 的训练数据，在整个训练循环中，还需要两千亿亿次浮点运算能力（20 exaflops, 20 billion billion）。不知道有没有人想用智能手机试一下。

接下来，就是**推断**了。

## 恭喜！你的神经网络训练完成，可以进行推断了

精心调整权值之后的神经网络基本上就是个笨重、巨大的数据库。现在，原本为了教育这个笨家伙而投入的巨大资源，即相当于教育过程中的笔本、书籍、老师的白眼等，在完成现实任务时已经根本用不上了。呃，毕业似乎就是要扔掉这些东西？

为了充分利用训练的结果，完成现实社会的任务，我们需要的是一个能够保留学习到的能力，还能迅速应用到前所未见的数据上的，响应迅速的系统。这就是**推断**，根据真实世界中的少量数据，迅速地提供正确的答案（其实你也把它理解为预测，prediction）。

这可是计算机科学的全新领域。现在主要有两种方法来优化庞大笨拙的神经网络，以实现高速低延迟的应用。

## 如何应用推断？

![img](http://mmbiz.qpic.cn/mmbiz_jpg/ibaXaPIy7jV3iapCMqJjzHPnBu9g01TaFvDaianef6PKlLvVnHu9Vq5npHnw7OL4JAtyh0ESxLLy1IrFN33RtzFwA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)

> 想看看推断在真实世界中的使用效果？看看你的智能手机就可以了。

推断的应用效果？打开你的智能手机就可以了。推断用在深度学习的每一个场景，从语言识别到照片分类。

第一个方法，是查找神经网络中经过训练后并没有用到、也就是说尚未激活的部分。这些区域在应用中并不需要，所以可以被清洗掉。

第二个方法，则是把神经网络中的多个层融合为一个单独的计算步骤。

在数字图像上，压缩很常见。设计师可能绘制恢宏壮丽，百万像素宽和高的图像。但放上网的，却都是有损压缩图像的JPEG格式。人眼无法看出区别，几乎是一模一样，但分辨率确实降低了。推断也是同样的----我们可以达到几乎一样的预测、识别准确率，但模型确实是简化了、压缩了、针对运行的性能进行优化了。

这意味着所有人都在使用推断。我们的手机中语音助手使用推断。Google 的语言识别、图像搜索、垃圾邮件过滤等也都使用了推断。百度的语言识别、恶意程序检测和垃圾邮件过滤也都使用推断。Facebook 的图像识别和亚马逊及 Netflix 的推荐引擎也都依赖于推断。

**GPU，**由于它出色的并行运算能力，可以一次做很多件事情，因此它非常适合进行深度学习的训练和推断。使用 GPU 训练得到的深度学习系统，让计算机能够与人类一样，甚至有些时候比人类更好地检测模式和物体。

训练完成之后，神经网络部署于现场，以便推断分类数据或推导结果。在这里，GPU 及其并行运算能力同样可以为神经网络识别模式和物体所需的数以亿计的海量运算提供帮助。

我们将会看到这些模型逐渐地变得更加聪明、更加迅速、更加准确。训练会变得不那么烦人，而推导也会带来生活中方方面面的新应用。就像我们年轻时经常听到的"谆谆教诲"，似乎看来对"人工智能"也同样适用----"别傻了，在学校好好念书。"推断自然就在外面等着呢~
